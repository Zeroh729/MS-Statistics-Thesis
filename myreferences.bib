@article{Else2014,
author = {Else, Gerald F.},
doi = {10.4159/harvard.9780674288089.c24},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Giraldez - ddPCR for Absolute Quantification of Extracellular MicroRNAs in Plasma and Serum.pdf:pdf},
isbn = {9781493977789},
journal = {Aristotle's Poetics},
keywords = {absolute quantification,biofluids,digital pcr,microrna,plasma,qpcr,serum},
pages = {459--474},
title = {{Droplet Digital PCR for Absolute Quantification of Extracellular MicroRNAs in Plasma and Serum: Quantification of the Cancer Biomarker hsa-miR-141}},
volume = {1768},
year = {2014}
}
@book{Wittwer2018,
author = {Wittwer, Carl T. and Makrigiorgos, G. Mike},
booktitle = {Principles and Applications of Molecular Diagnostics},
doi = {10.1016/b978-0-12-816061-9.00004-7},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Wittwer - Nucleic Acid Techniques.pdf:pdf},
isbn = {9780128160619},
pages = {47--86},
publisher = {Elsevier Inc.},
title = {{Nucleic Acid Techniques}},
url = {http://dx.doi.org/10.1016/B978-0-12-816061-9.00004-7},
year = {2018}
}
@article{Huggett2015,
author = {Huggett, Jim F. and O'Grady, Justin and Bustin, Stephen},
doi = {10.1016/j.bdq.2015.01.001},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Huggett - qPCR, dPCR, NGS  A journey.pdf:pdf},
issn = {22147535},
journal = {Biomolecular Detection and Quantification},
keywords = {Digital PCR,MIQE,Next generation sequencing,QPCR,Reverse transcription},
number = {March 2007},
pages = {A1--A5},
title = {{QPCR, dPCR, NGS - A journey}},
volume = {3},
year = {2015}
}
@article{Mcadam2018,
author = {Mcadam, Alexander J},
doi = {10.1007/978-3-319-33900-9},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Mcadam - Real-Time and Digital PCR for Nucleic Acid Quantification.pdf:pdf},
isbn = {9783319339009},
journal = {Advanced Techniques in Diagnostic Microbiology},
pages = {377--387},
title = {{Advanced Techniques in Diagnostic Microbiology}},
year = {2018}
}
@article{Quan2018,
abstract = {Digital Polymerase Chain Reaction (dPCR) is a novel method for the absolute quantification of target nucleic acids. Quantification by dPCR hinges on the fact that the random distribution of molecules in many partitions follows a Poisson distribution. Each partition acts as an individual PCR microreactor and partitions containing amplified target sequences are detected by fluorescence. The proportion of PCR-positive partitions suffices to determine the concentration of the target sequence without a need for calibration. Advances in microfluidics enabled the current revolution of digital quantification by providing efficient partitioning methods. In this review, we compare the fundamental concepts behind the quantification of nucleic acids by dPCR and quantitative real-time PCR (qPCR). We detail the underlying statistics of dPCR and explain how it defines its precision and performance metrics. We review the different microfluidic digital PCR formats, present their underlying physical principles, and analyze the technological evolution of dPCR platforms. We present the novel multiplexing strategies enabled by dPCR and examine how isothermal amplification could be an alternative to PCR in digital assays. Finally, we determine whether the theoretical advantages of dPCR over qPCR hold true by perusing studies that directly compare assays implemented with both methods.},
author = {Quan, Phenix Lan and Sauzade, Martin and Brouzes, Eric},
doi = {10.3390/s18041271},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Quan - dPCR A Technology Review.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Absolute quantification,Arrays of microwells,DPCR,Digital PCR,Droplet microfluidics,Microfluidic chambers,Microfluidic technologies,Microfluidics,On-chip valves,Partitioning,QPCR,Quantitative real-time PCR,Real-time PCR},
number = {4},
title = {{DPCR: A technology review}},
volume = {18},
year = {2018}
}
@article{Trypsteen2015a,
abstract = {Digital PCR is rapidly gaining interest in the field of molecular biology for absolute quantification of nucleic acids. However, the first generation of platforms still needs careful validation and requires a specificmethodology for data analysis to distinguish negative from positive signals by defining a threshold value. The currently described methods to assess droplet digital PCR (ddPCR) are based on an underlying assumption that the fluorescent signal of droplets is normally distributed. We show that this normality assumption does not likely hold true for most ddPCR runs, resulting in an erroneous threshold. We suggest a methodology that does not make any assumptions about the distribution of the fluorescence readouts. A threshold is estimated by modelling the extreme values in the negative droplet population using extreme value theory. Furthermore, the method takes shifts in baseline fluorescence between samples into account. An R implementation of our method is available, allowing automated threshold determination for absolute ddPCR quantification using a single fluorescent reporter.},
author = {Trypsteen, Wim and Vynck, Matthijs and de Neve, Jan and Bonczkowski, Pawel and Kiselinova, Maja and Malatinkova, Eva and Vervisch, Karen and Thas, Olivier and Vandekerckhove, Linos and de Spiegelaere, Ward},
doi = {10.1007/s00216-015-8773-4},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Trypsteen - ddpcRquant - threshold determination for single channel droplet.pdf:pdf},
issn = {16182650},
journal = {Analytical and Bioanalytical Chemistry},
keywords = {Automation,Data analysis,Droplet digital PCR,Extreme value distribution,R software,Rain,Threshold determination},
number = {19},
pages = {5827--5834},
title = {{Ddpcrquant: Threshold determination for single channel droplet digital PCR experiments}},
volume = {407},
year = {2015}
}
@article{Cao2017,
abstract = {Since the invention of polymerase chain reaction (PCR) in 1985, PCR has played a significant role in molecular diagnostics for genetic diseases, pathogens, oncogenes and forensic identification. In the past three decades, PCR has evolved from end-point PCR, through real-time PCR, to its current version, which is the absolute quantitive digital PCR (dPCR). In this review, we first discuss the principles of all key steps of dPCR, i.e., sample dispersion, amplification, and quantification, covering commercialized apparatuses and other devices still under lab development. We highlight the advantages and disadvantages of different technologies based on these steps, and discuss the emerging biomedical applications of dPCR. Finally, we provide a glimpse of the existing challenges and future perspectives for dPCR.},
author = {Cao, Lei and Cui, Xingye and Hu, Jie and Li, Zedong and Choi, Jane Ru and Yang, Qingzhen and Lin, Min and {Ying Hui}, Li and Xu, Feng},
doi = {10.1016/j.bios.2016.09.082},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Cao - Advances in dPCR and its emerging biomedical applications.pdf:pdf},
issn = {18734235},
journal = {Biosensors and Bioelectronics},
keywords = {Absolute quantification,Beads,Deoxyribonucleic acid,Digital PCR,Droplet,Microfluidics,Microwell},
number = {November 2018},
pages = {459--474},
publisher = {Elsevier},
title = {{Advances in digital polymerase chain reaction (dPCR) and its emerging biomedical applications}},
url = {http://dx.doi.org/10.1016/j.bios.2016.09.082},
volume = {90},
year = {2017}
}
@article{Kulesa2015,
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Kulesa, Anthony and Krzywinski, Martin and Blainey, Paul and Altman, Naomi},
doi = {110.1016/j.bbi.2017.04.008},
eprint = {15334406},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Kulesa - Sampling distributions and the bootstrap.pdf:pdf},
isbn = {0000000000000},
issn = {1527-5418},
journal = {Nat Methods},
keywords = {bold,fmri,methods,resting-state},
number = {6},
pages = {477--478},
pmid = {24655651},
title = {{Sampling distributions and the bootstrap: The bootstrap can be used to assess uncertainty of sample estimates}},
volume = {12},
year = {2015}
}
@article{Jones2014,
abstract = {Droplet Digital PCR (ddPCR) represents a new and alternative platform to conventional quantitative-PCR (qPCR) for the quantitation of DNA templates. However, the proposed improvement in sensitivity and reproducibility offered by ddPCR is not yet fully proven, partly because the delineation between positive and negative responses is not always clear.Data are presented demonstrating the sensitivity of the ddPCR system to both reagent concentrations and choice of cut-off for defining positive and negative results. By implementing k-nearest clustering, cut-offs are produced that improve the accuracy of ddPCR where target DNA is present at low copy numbers, a key application of ddPCR. This approach is applied to human albumin and HIV-1 proviral DNA ddPCR quantitative protocols. This tool is coded in JavaScript and has been made available for free in a web browser at http://www.definetherain.org.uk. Optimisation of the analyses of raw ddPCR data using 'definetherain' indicates that low target number detection can be improved by its implementation. Further application to patient samples will help define the clinical utility of this approach. {\textcopyright} 2014.},
author = {Jones, Mathew and Williams, James and G{\"{a}}rtner, Kathleen and Phillips, Rodney and Hurst, Jacob and Frater, John},
doi = {10.1016/j.jviromet.2014.02.020},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Jones - Low Copy Target Detection by ddPCR (definetherain).pdf:pdf},
issn = {18790984},
journal = {Journal of Virological Methods},
keywords = {Droplet Digital PCR,HIV-1,K means clustering,Quantitative PCR},
pages = {46--53},
publisher = {Elsevier B.V.},
title = {{Low copy target detection by Droplet Digital PCR through application of a novel open access bioinformatic pipeline, 'definetherain'}},
url = {http://dx.doi.org/10.1016/j.jviromet.2014.02.020},
volume = {202},
year = {2014}
}
@article{Jacobs2017,
abstract = {Standard data analysis pipelines for digital PCR estimate the concentration of a target nucleic acid by digitizing the end-point fluorescence of the parallel micro-PCR reactions, using an automated hard threshold. While it is known that misclassification has a major impact on the concentration estimate and substantially reduces accuracy, the uncertainty of this classification is typically ignored. We introduce a model-based clustering method to estimate the probability that the target is present (absent) in a partition conditional on its observed fluorescence and the distributional shape in no-template control samples. This methodology acknowledges the inherent uncertainty of the classification and provides a natural measure of precision, both at individual partition level and at the level of the global concentration. We illustrate our method on genetically modified organism, inhibition, dynamic range, and mutation detection experiments. We show that our method provides concentration estimates of similar accuracy or better than the current standard, along with a more realistic measure of precision. The individual partition probabilities and diagnostic density plots further allow for some quality control. An R implementation of our method, called Umbrella, is available, providing a more objective and automated data analysis procedure for absolute dPCR quantification.},
author = {Jacobs, Bart K.M. and Goetghebeur, Els and Vandesompele, Jo and {De Ganck}, Ariane and Nijs, Nele and Beckers, Anneleen and Papazova, Nina and Roosens, Nancy H. and Clement, Lieven},
doi = {10.1021/acs.analchem.6b04208},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Jacobs - Model based classification for dPCR (Umbrella for rain).pdf:pdf},
issn = {15206882},
journal = {Analytical Chemistry},
number = {8},
pages = {4461--4467},
title = {{Model-Based Classification for Digital PCR: Your Umbrella for Rain}},
volume = {89},
year = {2017}
}
@article{Kiss2008,
abstract = {Limiting dilution PCR has become an increasingly useful technique for the detection and quantification of rare species in a population, but the limit of detection and accuracy of quantification are largely determined by the number of reactions that can be analyzed. Increased throughput may be achieved by reducing the reaction volume and increasing processivity. We have designed a high-throughput microfluidic chip that encapsulates PCR reagents in millions of picoliter droplets in a continuous oil flow. The oil stream conducts the droplets through alternating denaturation and annealing zones, resulting in rapid (55-s cycles) and efficient PCR amplification. Inclusion of fluorescent probes in the PCR reaction mix permits the amplification process to be monitored within individual droplets at specific locations within the microfluidic chip. We show that amplification of a 245-bp adenovirus product can be detected and quantified in 35 min at starting template concentrations as low as 1 template molecule/167 droplets (0.003 pg/$\mu$L). The frequencies of positive reactions over a range of template concentrations agree closely with the frequencies predicted by Poisson statistics, demonstrating both the accuracy and sensitivity of this platform for limiting dilution and digital PCR applications. {\textcopyright} 2008 American Chemical Society.},
author = {Kiss, Margaret Macris and Ortoleva-Donnelly, Lori and {Reginald Beer}, N. and Warner, Jason and Bailey, Christopher G. and Colston, Bill W. and Rothberg, Jonathon M. and Link, Darren R. and Leamon, John H.},
doi = {10.1021/ac801276c},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Kiss - High-Throughput Quantitative PCR in Picoliter Droplets.pdf:pdf},
issn = {00032700},
journal = {Analytical Chemistry},
number = {23},
pages = {8975--8981},
title = {{High-throughput quantitative polymerase chain reaction in picoliter droplets}},
volume = {80},
year = {2008}
}
@article{Bonald2019,
author = {Bonald, Thomas},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Papers - Expectation Maximization/Bonald - Expectation-Maximization for the Gaussian Mixture Model.pdf:pdf},
number = {January},
pages = {1--8},
title = {{Expectation-Maximization for the Gaussian Mixture Model Expectation-Maximization}},
year = {2019}
}
@article{Warren2007,
author = {Warren, Luigi A. and Weinstein, Joshua A. and Quake, Stephen R.},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Warren - Digital Array Response Curve.pdf:pdf},
title = {{The Digital Array Response Curve}},
year = {2007}
}
@article{Strain2013,
abstract = {Deoxyribonucleic acid (DNA) of the human immunodeficiency virus (HIV) provides the most sensitive measurement of residual infection in patients on effective combination antiretroviral therapy (cART). Droplet digital PCR (ddPCR) has recently been shown to provide highly accurate quantification of DNA copy number, but its application to quantification of HIV DNA, or other equally rare targets, has not been reported. This paper demonstrates and analyzes the application of ddPCR to measure the frequency of total HIV DNA (pol copies per million cells), and episomal 2-LTR (long terminal repeat) circles in cells isolated from infected patients. Analysis of over 300 clinical samples, including over 150 clinical samples assayed in triplicate by ddPCR and by real-time PCR (qPCR), demonstrates a significant increase in precision, with an average 5-fold decrease in the coefficient of variation of pol copy numbers and a {\textgreater}20-fold accuracy improvement for 2-LTR circles. Additional benefits of the ddPCR assay over qPCR include absolute quantification without reliance on an external standard and relative insensitivity to mismatches in primer and probe sequences. These features make digital PCR an attractive alternative for measurement of HIV DNA in clinical specimens. The improved sensitivity and precision of measurement of these rare events should facilitate measurements to characterize the latent HIV reservoir and interventions to eradicate it.},
author = {Strain, Matthew C. and Lada, Steven M. and Luong, Tiffany and Rought, Steffney E. and Gianella, Sara and Terry, Valeri H. and Spina, Celsa A. and Woelk, Christopher H. and Richman, Douglas D.},
doi = {10.1371/journal.pone.0055943},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Strain - Highly Precise Measurement of HIV DNA by ddPCR.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {4},
pages = {2--9},
title = {{Highly Precise Measurement of HIV DNA by Droplet Digital PCR}},
volume = {8},
year = {2013}
}
@article{Satyanarayana1984,
abstract = {A nonlocal theory of the Rayleigh-Taylor instability, which includes the effect of a transverse velocity shear, is presented. A two-fluid model is used to describe an inhomogeneous plasma under the influence of gravity and sheared equilibrium flow velocity and to derive a differential equation describing the generalized Rayleigh-Taylor instability. An extensive parametric study is made in the collisionless and collisional regimes, and the corresponding dispersion curves are presented. The results are applied to the equatorial F region to barium releases in the ionosphere.},
author = {Satyanarayana, P. and Ossakow, S. L. and Huba, J. D. and Guzdar, P. N.},
doi = {10.1029/JA089iA05p02945},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Pfaffl.pdf:pdf},
issn = {01480227},
journal = {Journal of Geophysical Research},
number = {A5},
pages = {2945--2954},
title = {{Rayleigh-Taylor Instability in the Presence of a Stratified Shear Layer.}},
volume = {89},
year = {1984}
}
@article{Whale2013,
abstract = {Digital PCR (dPCR) is a highly accurate molecular approach, capable of precise measurements, offering a number of unique opportunities. However, in its current format dPCR can be limited by the amount of sample that can be analysed and consequently additional considerations such as performing multiplex reactions or pre-amplification can be considered. This study investigated the impact of duplexing and pre-amplification on dPCR analysis by using three different assays targeting a model template (a portion of the Arabidopsis thaliana alcohol dehydrogenase gene). We also investigated the impact of different template types (linearised plasmid clone and more complex genomic DNA) on measurement precision using dPCR. We were able to demonstrate that duplex dPCR can provide a more precise measurement than uniplex dPCR, while applying pre-amplification or varying template type can significantly decrease the precision of dPCR. Furthermore, we also demonstrate that the pre-amplification step can introduce measurement bias that is not consistent between experiments for a sample or assay and so could not be compensated for during the analysis of this data set. We also describe a model for estimating the prevalence of molecular dropout and identify this as a source of dPCR imprecision. Our data have demonstrated that the precision afforded by dPCR at low sample concentration can exceed that of the same template post pre-amplification thereby negating the need for this additional step. Our findings also highlight the technical differences between different templates types containing the same sequence that must be considered if plasmid DNA is to be used to assess or control for more complex templates like genomic DNA. {\textcopyright} 2013 Whale et al.},
author = {Whale, Alexandra S. and Cowen, Simon and Foy, Carole A. and Huggett, Jim F.},
doi = {10.1371/journal.pone.0058177},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Whale - Accurate dPCR Analysis on Low Copy DNA Samples.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {3},
title = {{Methods for Applying Accurate Digital PCR Analysis on Low Copy DNA Samples}},
volume = {8},
year = {2013}
}
@article{Garriga2016,
abstract = {The growing capacity to process and store animal tracks has spurred the development of new methods to segment animal trajectories into elementary units of movement. Key challenges for movement trajectory segmentation are to (i) minimize the need of supervision, (ii) reduce computational costs, (iii) minimize the need of prior assumptions (e.g. simple parametrizations), and (iv) capture biologically meaningful semantics, useful across a broad range of species. We introduce the Expectation-Maximization binary Clustering (EMbC), a general purpose, unsupervised approach to multivariate data clustering. The EMbC is a variant of the Expectation-Maximization Clustering (EMC), a clustering algorithm based on the maximum likelihood estimation of a Gaussian mixture model. This is an iterative algorithm with a closed form step solution and hence a reasonable computational cost. The method looks for a good compromise between statistical soundness and ease and generality of use (by minimizing prior assumptions and favouring the semantic interpretation of the final clustering). Here we focus on the suitability of the EMbC algorithm for behavioural annotation of movement data. We show and discuss the EMbC outputs in both simulated trajectories and empirical movement trajectories including different species and different tracking methodologies. We use synthetic trajectories to assess the performance of EMbC compared to classic EMC and Hidden Markov Models. Empirical trajectories allow us to explore the robustness of the EMbC to data loss and data inaccuracies, and assess the relationship between EMbC output and expert label assignments. Additionally, we suggest a smoothing procedure to account for temporal correlations among labels, and a proper visualization of the output for movement trajectories. Our algorithm is available as an R-package with a set of complementary functions to ease the analysis.},
archivePrefix = {arXiv},
arxivId = {1503.04059},
author = {Garriga, Joan and Palmer, John R.B. and Oltra, Aitana and Bartumeus, Frederic},
doi = {10.1371/journal.pone.0151984},
eprint = {1503.04059},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Papers - Expectation Maximization/Garriga - Expectation-Maximization Binary Clustering for Behavioural Annotation.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {3},
pages = {1--26},
title = {{Expectation-maximization binary clustering for behavioural annotation}},
volume = {11},
year = {2016}
}
@article{Mcnicholas2016,
author = {Mcnicholas, Paul D},
doi = {10.1007/s0035},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Papers - Expectation Maximization/McNicholas - Model-Based Clustering.pdf:pdf},
keywords = {cluster,cluster analysis,mixture models,model-based clustering},
number = {November},
pages = {331--373},
title = {{Model-Based Clustering}},
volume = {373},
year = {2016}
}
@article{Pfaffl2007,
author = {Pfaffl, Michael W.},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Pfaffl - better.pdf:pdf},
isbn = {9780203967317},
journal = {Real-time PCR},
pages = {64--82},
title = {{Relative quantification}},
year = {2007}
}
@article{Dube2008,
author = {Dube, Simant and Qin, Jian and Ramakrishnan, Ramesh},
doi = {10.1371/journal.pone.0002876},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Dube - Mathematical Analysis of CVN using digital PCR.PDF:PDF},
number = {8},
pages = {1--9},
title = {{Mathematical Analysis of Copy Number Variation in a DNA Sample Using Digital PCR on a Nanofluidic Device}},
volume = {3},
year = {2008}
}
@article{KevinRange2012,
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {{Kevin Range}, and Darrin M. York Adam Moser},
doi = {10.1038/jid.2014.371},
eprint = {NIHMS150003},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Henrich - Low Level Detection and Quantification of HIV1 and 2LTR using ddPCR.pdf:pdf},
isbn = {6176321972},
issn = {15378276},
journal = {Bone},
keywords = {epiblast,gfp fusion,histone h2b-,icm,lineage specification,live imaging,mouse blastocyst,pdgfr $\alpha$,primitive endoderm},
number = {1},
pages = {1--7},
pmid = {1000000221},
title = {{Low-Level Detection and Quantitation of Cellular HIV-1 DNA and 2-LTR Circles Using Droplet Digital PCR}},
volume = {23},
year = {2012}
}
@article{Jacobs2014,
abstract = {Background: Digital polymerase chain reaction (dPCR) is an increasingly popular technology for detecting and quantifying target nucleic acids. Its advertised strength is high precision absolute quantification without needing reference curves. The standard data analytic approach follows a seemingly straightforward theoretical framework but ignores sources of variation in the data generating process. These stem from both technical and biological factors, where we distinguish features that are 1) hard-wired in the equipment, 2) user-dependent and 3) provided by manufacturers but may be adapted by the user. The impact of the corresponding variance components on the accuracy and precision of target concentration estimators presented in the literature is studied through simulation.Results: We reveal how system-specific technical factors influence accuracy as well as precision of concentration estimates. We find that a well-chosen sample dilution level and modifiable settings such as the fluorescence cut-off for target copy detection have a substantial impact on reliability and can be adapted to the sample analysed in ways that matter. User-dependent technical variation, including pipette inaccuracy and specific sources of sample heterogeneity, leads to a steep increase in uncertainty of estimated concentrations. Users can discover this through replicate experiments and derived variance estimation. Finally, the detection performance can be improved by optimizing the fluorescence intensity cut point as suboptimal thresholds reduce the accuracy of concentration estimates considerably.Conclusions: Like any other technology, dPCR is subject to variation induced by natural perturbations, systematic settings as well as user-dependent protocols. Corresponding uncertainty may be controlled with an adapted experimental design. Our findings point to modifiable key sources of uncertainty that form an important starting point for the development of guidelines on dPCR design and data analysis with correct precision bounds. Besides clever choices of sample dilution levels, experiment-specific tuning of machine settings can greatly improve results. Well-chosen data-driven fluorescence intensity thresholds in particular result in major improvements in target presence detection. We call on manufacturers to provide sufficiently detailed output data that allows users to maximize the potential of the method in their setting and obtain high precision and accuracy for their experiments.},
author = {Jacobs, Bart K.M. and Goetghebeur, Els and Clement, Lieven},
doi = {10.1186/1471-2105-15-283},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Jacobs - Impact of variance comonents in reliability of absolute quantification using dPCR.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Absolute nucleic acid quantification,Accuracy,CNV,Digital PCR,Experimental design,Polymerase chain reaction,Precision,Reliability,Variance component},
number = {1},
pages = {1--13},
title = {{Impact of variance components on reliability ofl absolute quantification using digital PCR}},
volume = {15},
year = {2014}
}
@article{Dreo2014,
abstract = {Here we report on the first assessment of droplet digital PCR (ddPCR) for detection and absolute quantification of two quarantine plant pathogenic bacteria that infect many species of the Rosaceae and Solanaceae families: Erwinia amylovora and Ralstonia solanacearum. An open-source R script was written for the ddPCR data analysis. Analysis of a set of samples with known health status aided the assessment and selection of different threshold settings (QuantaSoft analysis, definetherain pipeline and manual threshold), which led to optimal diagnostic specificity. The interpretation of the E. amylovora ddPCR was straightforward, and the analysis approach had little influence on the final results and the concentrations determined. The sensitivity and linear range were similar to those for real-time PCR (qPCR), for the analysis of both bacterial suspensions and plant material, making ddPCR a viable choice when both detection and quantification are desired. With the R. solanacearum ddPCR, the use of a high global threshold was necessary to exclude false-positive reactions that are sometimes observed in healthy plant material. ddPCR significantly improved the analytical sensitivity over that of qPCR, and improved the detection of low concentrations of R. solanacearum in potato tuber samples. Accurate and rapid absolute quantification of both of these bacteria in pure culture was achieved by direct ddPCR. Our data confirm the suitability of these ddPCR assays for routine detection and quantification of plant pathogens and for preparation of defined in-house reference materials with known target concentrations.},
author = {Dreo, Tanja and Pirc, Manca and Ram{\v{s}}ak, {\v{Z}}iva and Pav{\v{s}}i{\v{c}}, Jernej and Milavec, Mojca and {\v{Z}}el, Jana and Gruden, Kristina},
doi = {10.1007/s00216-014-8084-1},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Dreo - Optimising ddPCR for detection and quantification of bacteria.pdf:pdf},
issn = {16182650},
journal = {Analytical and Bioanalytical Chemistry},
keywords = {Bioanalyticalmethods,Droplet digital PCR,Molecular diagnostics,Plant pathogenic bacteria},
number = {26},
pages = {6513--6528},
title = {{Optimising droplet digital PCR analysis approaches for detection and quantification of bacteria: A case study of fire blight and potato brown rot}},
volume = {406},
year = {2014}
}
@article{Unit,
author = {Unit, Genomics and Protection, Consumer},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/(Supplementary Files) Lievens/S1 File.pdf:pdf},
pages = {2--4},
title = {{M EASURING DIGITAL PCR QUALITY : P ERFORMANCE P ARAMETERS AND THEIR O PTIMIZATION}}
}
@article{Unita,
author = {Unit, Genomics and Protection, Consumer},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/(Supplementary Files) Lievens/S5 File.pdf:pdf},
pages = {1--2},
title = {{M EASURING DIGITAL PCR QUALITY : P ERFORMANCE P ARAMETERS AND THEIR O PTIMIZATION}}
}
@article{Jacobs2017a,
abstract = {Standard data analysis pipelines for digital PCR estimate the concentration of a target nucleic acid by digitizing the end-point fluorescence of the parallel micro-PCR reactions, using an automated hard threshold. While it is known that misclassification has a major impact on the concentration estimate and substantially reduces accuracy, the uncertainty of this classification is typically ignored. We introduce a model-based clustering method to estimate the probability that the target is present (absent) in a partition conditional on its observed fluorescence and the distributional shape in no-template control samples. This methodology acknowledges the inherent uncertainty of the classification and provides a natural measure of precision, both at individual partition level and at the level of the global concentration. We illustrate our method on genetically modified organism, inhibition, dynamic range, and mutation detection experiments. We show that our method provides concentration estimates of similar accuracy or better than the current standard, along with a more realistic measure of precision. The individual partition probabilities and diagnostic density plots further allow for some quality control. An R implementation of our method, called Umbrella, is available, providing a more objective and automated data analysis procedure for absolute dPCR quantification.},
author = {Jacobs, Bart K.M. and Goetghebeur, Els and Vandesompele, Jo and {De Ganck}, Ariane and Nijs, Nele and Beckers, Anneleen and Papazova, Nina and Roosens, Nancy H. and Clement, Lieven},
doi = {10.1021/acs.analchem.6b04208},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/(Supplementary Files) Jacobs/Supplementary.pdf:pdf},
issn = {15206882},
journal = {Analytical Chemistry},
number = {8},
pages = {4461--4467},
title = {{Model-Based Classification for Digital PCR: Your Umbrella for Rain}},
volume = {89},
year = {2017}
}
@article{Trypsteen2015,
abstract = {Digital PCR is rapidly gaining interest in the field of molecular biology for absolute quantification of nucleic acids. However, the first generation of platforms still needs careful validation and requires a specificmethodology for data analysis to distinguish negative from positive signals by defining a threshold value. The currently described methods to assess droplet digital PCR (ddPCR) are based on an underlying assumption that the fluorescent signal of droplets is normally distributed. We show that this normality assumption does not likely hold true for most ddPCR runs, resulting in an erroneous threshold. We suggest a methodology that does not make any assumptions about the distribution of the fluorescence readouts. A threshold is estimated by modelling the extreme values in the negative droplet population using extreme value theory. Furthermore, the method takes shifts in baseline fluorescence between samples into account. An R implementation of our method is available, allowing automated threshold determination for absolute ddPCR quantification using a single fluorescent reporter.},
author = {Trypsteen, Wim and Vynck, Matthijs and de Neve, Jan and Bonczkowski, Pawel and Kiselinova, Maja and Malatinkova, Eva and Vervisch, Karen and Thas, Olivier and Vandekerckhove, Linos and de Spiegelaere, Ward},
doi = {10.1007/s00216-015-8773-4},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/(Supplementary Files) Trypsteen/S3 - Theshold Determination.pdf:pdf},
issn = {16182650},
journal = {Analytical and Bioanalytical Chemistry},
keywords = {Automation,Data analysis,Droplet digital PCR,Extreme value distribution,R software,Rain,Threshold determination},
number = {19},
pages = {5827--5834},
title = {{Ddpcrquant: Threshold determination for single channel droplet digital PCR experiments}},
volume = {407},
year = {2015}
}
@article{Tzonev,
author = {Tzonev, Svilen},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Tzonev - Fundamentals of Counting Statistics in Digital PCR.pdf:pdf},
isbn = {9781493977789},
keywords = {blank,counting,false negative,false positive,limit of,limit of detection,performance characteristics,poisson distribution,sensitivity,specificity,statistics,subsampling},
pages = {25--43},
title = {{Chapter 3 Fundamentals of Counting Statistics in Digital PCR : I Just}},
volume = {1768}
}
@article{Wilson2016,
abstract = {Background: Digital PCR (dPCR) is a technique for estimating the concentration of a target nucleic acid by loading a sample into a large number of partitions, amplifying the target and using a fluorescent marker to identify which partitions contain the target. The standard analysis uses only the proportion of partitions containing target to estimate the concentration and depends on the assumption that the initial distribution of molecules in partitions is Poisson. In this paper we describe a way to extend such analysis using the quantification cycle (Cq) data that may also be available, but rather than assuming the Poisson distribution the more general Conway-Maxwell-Poisson distribution is used instead. Results: A software package for the open source language R has been created for performing the analysis. This was used to validate the method by analysing Cq data from dPCR experiments involving 3 types of DNA (attenuated, virulent and plasmid) at 3 concentrations. Results indicate some deviation from the Poisson distribution, which is strongest for the virulent DNA sample. Theoretical calculations indicate that the deviation from the Poisson distribution results in a bias of around 5 {\%} for the analysed data if the standard analysis is used, but that it could be larger for higher concentrations. Compared to the estimates of subsequent efficiency, the estimates of 1st cycle efficiency are much lower for the virulent DNA, moderately lower for the attenuated DNA and close for the plasmid DNA. Further method validation using simulated data gave results closer to the true values and with lower standard deviations than the standard method, for concentrations up to approximately 2.5 copies/partition. Conclusions: The Cq-based method is effective at estimating DNA concentration and is not seriously affected by data issues such as outliers and moderately non-linear trends. The data analysis suggests that the Poisson assumption of the standard approach does lead to a bias that is fairly small, though more research is needed. Estimates of the 1st cycle efficiency being lower than estimates of the subsequent efficiency may indicate samples that are mixtures of single-stranded and double-stranded DNA. The model can reduce or eliminate the resulting bias.},
author = {Wilson, Philip J. and Ellison, Stephen L.R.},
doi = {10.1186/s12859-016-1275-3},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Wilson - Extending digital PCR analysis by modelling quantification cycle data.pdf:pdf},
isbn = {1285901612753},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Amplification efficiency,Bayesian,CMP distribution,Conway-Maxwell-Poisson distribution,MCMC,SsDNA},
number = {1},
pages = {1--10},
publisher = {BMC Bioinformatics},
title = {{Extending digital PCR analysis by modelling quantification cycle data}},
url = {http://dx.doi.org/10.1186/s12859-016-1275-3},
volume = {17},
year = {2016}
}
@article{Lievens2016,
abstract = {Digital PCR is rapidly being adopted in the field of DNA-based food analysis. The direct, absolute quantification it offers makes it an attractive technology for routine analysis of food and feed samples for their composition, possible GMO content, and compliance with labelling requirements. However, assessing the performance of dPCR assays is not yet well established. This article introduces three straightforward parameters based on statistical principles that allow users to evaluate if their assays are robust. In addition, we present post-run evaluation criteria to check if quantification was accurate. Finally, we evaluate the usefulness of Poisson confidence intervals and present an alternative strategy to better capture the variability in the analytical chain.},
author = {Lievens, A. and Jacchia, S. and Kagkli, D. and Savini, C. and Querci, M.},
doi = {10.1371/journal.pone.0153317},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Lievens - Measuring Digital PCR Quality Performance Parameters and Their Optimization.PDF:PDF},
issn = {19326203},
journal = {PloS one},
number = {5},
pages = {e0153317},
title = {{Measuring Digital PCR Quality: Performance Parameters and Their Optimization}},
volume = {11},
year = {2016}
}
@article{Gou2018,
abstract = {Digital polymerase chain reaction (dPCR) circumventing the external calibration and potentially providing absolute quantification of nucleic acids has become an increasingly popular manifestation of PCR in biological researches. However, currently reported or commercial dPCR devices are not suitable for applications in laboratories or zones with limited infrastructures, due to low function integration, cost-inefficiency, or weak mobility. Herein, in order to enable accurate DNA quantitative analysis in such situations, we have developed a smartphone-based mobile dPCR device integrated with thermal cycling control, on-chip dPCR, data acquisition, and result analysis. All the function units are automatically controlled using a customized Android software. The device is approximately 90 mm × 90 mm × 100 mm in size and about 500 g in weight, only costing about 320 dollars except the smartphone. Coupled with the self-priming dPCR chip previously developed by our lab, the device is able to accurately quantify down to 10 copies of the human 18 S ribosomal DNA fragment inserted in a plasmid. Comparing to the commercial QuantStudio™ 3D dPCR platform, our device achieves a comparable analytical accuracy. Besides, our device is capable of detecting single molecule of cancer biomarker gene CD147 in a low number of HepG2 cells. Therefore, our dPCR device as a low-cost, potable, and robust tool for highly accurate DNA quantitative analysis has a great potential in Point-of-care (POC) applications.},
author = {Gou, Tong and Hu, Jiumei and Wu, Wenshuai and Ding, Xiong and Zhou, Shufang and Fang, Weibo and Mu, Ying},
doi = {10.1016/j.bios.2018.08.030},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}}THESIS/Papers/Guo - Smartphone-based mobile digital PCR device for DNA quantitative analysis.pdf:pdf},
issn = {18734235},
journal = {Biosensors and Bioelectronics},
keywords = {Cancer biomarker gene,Digital PCR,Microfluidic chip,Point-of-care,Resource-limited settings,Smartphone},
number = {August},
pages = {144--152},
publisher = {Elsevier B.V.},
title = {{Smartphone-based mobile digital PCR device for DNA quantitative analysis with high accuracy}},
url = {https://doi.org/10.1016/j.bios.2018.08.030},
volume = {120},
year = {2018}
}
@book{Fallis2013,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Fallis, A.G},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fallis - 2013 - 済無No Title No Title.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{済無No Title No Title}},
volume = {53},
year = {2013}
}
@article{Hilbel2008,
author = {Hilbel, Thomas and Helms, Thomas M. and Mikus, Gerd and Katus, Hugo A. and Zugck, Christian},
doi = {10.1007/s00399-008-0017-2},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hilbel et al. - 2008 - Telemetrie Szenarien im klinischen umfeld.pdf:pdf},
isbn = {0039900800},
issn = {09387412},
journal = {Herzschrittmachertherapie und Elektrophysiologie},
keywords = {Cardiac monitoring,Diagnostic telemetry,ECG,Hospital monitoring,Multi-band,Patient monitoring systems,Physiologic data,Telemetry,Wireless bedside monitoring,Wireless monitoring},
number = {3},
pages = {146--154},
title = {{Telemetrie: Szenarien im klinischen umfeld}},
volume = {19},
year = {2008}
}
@article{Kennedy2006,
abstract = {Holter technology has endured for more than 40 years, and proven to be a valuable adjunctive noninvasive diagnostic technology to record the ambulatory or long-term electrocardiogram in the study of living creatures. During this span of time, many scientists, physicians, and innovators contributed to the development and evolution of Holter technology. This essay seeks to document a view of the history and evolution of the technology during that time, and concomitantly give recognition to the scientists, physicians, and engineers who contributed so greatly. {\textcopyright}2006, Blackwell Publishing, Inc.},
author = {Kennedy, Harold L.},
doi = {10.1111/j.1542-474X.2006.00067.x},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kennedy - 2006 - The history, science, and innovation of Holter technology.pdf:pdf},
issn = {1082720X},
journal = {Annals of Noninvasive Electrocardiology},
keywords = {Bruce Del Mar,Holter technology,Jeffrey Holter},
number = {1},
pages = {85--94},
title = {{The history, science, and innovation of Holter technology}},
volume = {11},
year = {2006}
}
@article{Giavarina2015,
abstract = {In a contemporary clinical laboratory it is very common to have to assess the agreement between two quantitative methods of measurement. The correct statistical approach to assess this degree of agreement is not obvious. Correlation and regression studies are frequently proposed. However, correlation studies the relationship between one variable and another, not the differences, and it is not recommended as a method for assessing the comparability between methods.  In 1983 Altman and Bland (B{\&}A) proposed an alternative analysis, based on the quantification of the agreement between two quantitative measurements by studying the mean difference and constructing limits of agreement.  The B{\&}A plot analysis is a simple way to evaluate a bias between the mean differences, and to estimate an agreement interval, within which 95{\%} of the differences of the second method, compared to the first one, fall. Data can be analyzed both as unit differences plot and as percentage differences plot.  The B{\&}A plot method only defines the intervals of agreements, it does not say whether those limits are acceptable or not. Acceptable limits must be defined a priori, based on clinical necessity, biological considerations or other goals.  The aim of this article is to provide guidance on the use and interpretation of Bland Altman analysis in method comparison studies.},
author = {Giavarina, Davide},
doi = {10.11613/BM.2015.015},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Giavarina - 2015 - Understanding Bland Altman analysis.pdf:pdf},
issn = {13300962},
journal = {Biochemia Medica},
keywords = {Agreement analysis,Bland-Altman,Correlation of data,Laboratory research,Method comparison},
number = {2},
pages = {141--151},
title = {{Understanding Bland Altman analysis}},
volume = {25},
year = {2015}
}
@article{Niskanen2004,
abstract = {A computer program for advanced heart rate variability (HRV) analysis is presented. The program calculates all the commonly used time- and frequency-domain measures of HRV as well as the nonlinear Poincar{\'{e}} plot. In frequency-domain analysis parametric and nonparametric spectrum estimates are calculated. The program generates an informative printable report sheet which can be exported to various file formats including the portable document format (PDF). Results can also be saved as an ASCII file from which they can be imported to a spreadsheet program such as the Microsoft{\textregistered} Excel{\textregistered}. Together with a modern heart rate monitor capable of recording RR intervals this freely distributed program forms a complete low-cost HRV measuring and analysis system. {\textcopyright} 2004 Elsevier Ireland Ltd. All rights reserved.},
author = {Niskanen, Juha Pekka and Tarvainen, Mika P. and Ranta-Aho, Perttu O. and Karjalainen, Pasi A.},
doi = {10.1016/j.cmpb.2004.03.004},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Niskanen et al. - 2004 - Software for advanced HRV analysis.pdf:pdf},
issn = {01692607},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {Analysis software,Computer program,HRV,Heart rate variability},
number = {1},
pages = {73--81},
title = {{Software for advanced HRV analysis}},
volume = {76},
year = {2004}
}
@article{Tarvainen2014,
abstract = {Kubios HRV is an advanced and easy to use software for heart rate variability (HRV) analysis. The software supports several input data formats for electrocardiogram (ECG) data and beat-to-beat RR interval data. It includes an adaptive QRS detection algorithm and tools for artifact correction, trend removal and analysis sample selection. The software computes all the commonly used time-domain and frequency-domain HRV parameters and several nonlinear parameters. There are several adjustable analysis settings through which the analysis methods can be optimized for different data. The ECG derived respiratory frequency is also computed, which is important for reliable interpretation of the analysis results. The analysis results can be saved as an ASCII text file (easy to import into MS Excel or SPSS), Matlab MAT-file, or as a PDF report. The software is easy to use through its compact graphical user interface. The software is available free of charge for Windows and Linux operating systems at http://kubios.uef.fi. {\textcopyright} 2013 Elsevier Ireland Ltd.},
author = {Tarvainen, Mika P. and Niskanen, Juha Pekka and Lipponen, Jukka A. and Ranta-aho, Perttu O. and Karjalainen, Pasi A.},
doi = {10.1016/j.cmpb.2013.07.024},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tarvainen et al. - 2014 - Kubios HRV - Heart rate variability analysis software.pdf:pdf},
issn = {01692607},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {Analysis software,Computer program,HRV,Heart rate variability,Matlab},
number = {1},
pages = {210--220},
publisher = {Elsevier Ireland Ltd},
title = {{Kubios HRV - Heart rate variability analysis software}},
url = {http://dx.doi.org/10.1016/j.cmpb.2013.07.024},
volume = {113},
year = {2014}
}
@article{Gulizia2017,
abstract = {The electrocardiogram (ECG) signal can be derived from different sources. These include systems for surface ECG, Holter monitoring, ergometric stress tests, and telemetry systems and bedside monitoring of vital parameters, which are useful for rhythm and ST-segment analysis and ECG screening of electrical sudden cardiac death predictors. A precise ECG diagnosis is based upon correct recording, elaboration, and presentation of the signal. Several sources of artefacts and potential external causes may influence the quality of the original ECG waveforms. Other factors that may affect the quality of the information presented depend upon the technical solutions employed to improve the signal. The choice of the instrumentations and solutions used to offer a high-quality ECG signal are, therefore, of paramount importance. Some requirements are reported in detail in scientific statements and recommendations. The aim of this consensus document is to give scientific reference for the choice of systems able to offer high quality ECG signal acquisition, processing, and presentation suitable for clinical use. {\textcopyright} The Author 2017. Published on behalf of the European Society of Cardiology.},
author = {Gulizia, Michele Massimo and Casolo, Giancarlo and Zuin, Guerrino and Morichelli, Loredana and Calcagnini, Giovanni and Ventimiglia, Vincenzo and Censi, Federica and Caldarola, Pasquale and Russo, Giancarmine and Leogrande, Lorenzo and {Franco Gensini}, Gian},
doi = {10.1093/eurheartj/sux031},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gulizia et al. - 2017 - ANMCOAIICSIT Consensus Information Document Definition, precision, and suitability of electrocardiographic signa.pdf:pdf},
issn = {15542815},
journal = {European Heart Journal, Supplement},
keywords = {ECG monitoring,ECG signals,Electrocardiogram,Ergometry,Holter ECG,Telemetry},
pages = {D190--D211},
title = {{ANMCO/AIIC/SIT Consensus Information Document: Definition, precision, and suitability of electrocardiographic signals of electrocardiographs, ergometry, Holter electrocardiogram, telemetry, and bedside monitoring systems}},
volume = {19},
year = {2017}
}
@article{Tsevas2010,
author = {Tsevas, Spyros and Member, Student and Iakovidis, Dimitris K},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsevas, Member, Iakovidis - 2010 - Dynamic Time Warping Fusion for the Retrieval of Similar Patient Cases Represented by Multimodal Time.pdf:pdf},
isbn = {9781424465613},
title = {{Dynamic Time Warping Fusion for the Retrieval of Similar Patient Cases Represented by Multimodal Time-Series Medical Data}},
year = {2010}
}
@article{Mason2007,
abstract = {... Recommendations for the standardization and interpretation of the electrocardiogram : Part I: The electrocardiogram and its technology : A Scientific Statement from the American Heart Association Electrocardiography and Arrhythmias Committee, Council on Clinical Cardiology ...},
author = {Mason, Jay W. and Hancock, E. William and Gettes, Leonard S.},
doi = {10.1161/circulationaha.106.180201},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mason, Hancock, Gettes - 2007 - Recommendations for the Standardization and Interpretation of the Electrocardiogram.pdf:pdf},
issn = {0009-7322},
journal = {Circulation},
keywords = {aha scientific statements},
number = {10},
pages = {1325--1332},
title = {{Recommendations for the Standardization and Interpretation of the Electrocardiogram}},
volume = {115},
year = {2007}
}
@article{Ratanamahatana2004,
abstract = {The Dynamic Time Warping (DTW) distance measure is a technique that has long been known in speech recognition community. It allows a non-linear mapping of one signal to another by minimizing the distance between the two. A decade ago, DTW was introduced into Data Mining community as a utility for various tasks for time series problems including classification, clustering, and anomaly detection. The technique has flourished, particularly in the last three years, and has been applied to a variety of problems in various disciplines. In spite of DTW's great success, there are still several persistent “myths” about it. These myths have caused confusion and led to much wasted research effort. In this work, we will dispel these myths with the most comprehensive set of time series experiments ever conducted},
author = {Ratanamahatana, Ca and Keogh, E},
doi = {10.1097/01.CCM.0000279204.24648.44},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ratanamahatana, Keogh - 2004 - Everything you know about dynamic time warping is wrong.pdf:pdf},
isbn = {978-0-89871-593-4},
issn = {00903493},
journal = {Third Workshop on Mining Temporal and Sequential Data},
keywords = {data mining,dynamic time warping,experimentation},
number = {June},
pages = {22--25},
pmid = {15513920},
title = {{Everything you know about dynamic time warping is wrong}},
url = {http://spoken-number-recognition.googlecode.com/svn/trunk/docs/Dynamic time warping/DTW{\_}myths.pdf},
year = {2004}
}
@article{Thesis2016,
author = {Thesis, Master and Luzianin, Student Ivan},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Thesis, Luzianin - 2016 - Changes Measurement in Biological Signals Based on Dynamic Time Warping Procedure on the Example of Repolariza.pdf:pdf},
number = {June},
title = {{Changes Measurement in Biological Signals Based on Dynamic Time Warping Procedure on the Example of Repolarization Part of HeartbeatCycle}},
year = {2016}
}
@article{Marques,
author = {Marques, Francisco},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Marques - Unknown - ECG Biometrics A Dissimilarity Representation Approach.pdf:pdf},
pages = {1--10},
title = {{ECG Biometrics : A Dissimilarity Representation Approach}}
}
@article{Luzianin2016,
abstract = {The problem of similarity measurement of biological signals is considered on this article. The dynamic time warping algorithm is used as a possible solution. A short overview of this algorithm and its modifications are given. Testing procedure for different modifications of DTW, which are based on artificial test signals, are presented.},
annote = {Goal: Analyze specific changes in biological
signals.

The aim of algorithm is a warping of time axis using stretching and shrinking in such way that the test signal matches the reference one as good as possible},
author = {Luzianin, Ivan and Krause, Bernd},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Luzianin, Krause - 2016 - Similarity Measurement of Biological Signals Using Dynamic Time Warping Algorithm.pdf:pdf},
journal = {Proceedings of the 4th International Conference on Applied Innovations in IT},
keywords = {artificial signals,biological signal,dynamic time warping,ecg,testing methods},
number = {March},
pages = {51--56},
title = {{Similarity Measurement of Biological Signals Using Dynamic Time Warping Algorithm}},
year = {2016}
}
@article{Shahriari2018,
abstract = {IEEE Objective: We developed an image-based electrocardiographic (ECG) quality assessment technique that mimics how clinicians annotate ECG signal quality. Methods: We adopted the Structural Similarity Measure (SSIM) to compare images of two ECG records that are obtained from displaying ECGs in a standard scale. Then a subset of representative ECG images from the training set was selected as templates through a clustering method. SSIM between each image and all the templates were used as the feature vector for the linear discriminant analysis (LDA) classifier. We also employed three commonly used ECG signal quality index (SQI) measures: baseSQI, kSQI, and sSQI to compare with the proposed image quality index (IQI) approach. We used 1926 annotated ECG, recorded from patient monitors, and associated with six different ECG arrhythmia alarm types which were obtained previously from an ECG Alarm Study at the University of California, San Francisco (UCSF). In addition, we applied the templates from the UCSF database to test the SSIM approach on the publicly available PhysioNet Challenge 2011 data. Results: For the UCSF database, the proposed IQI algorithm achieved an accuracy of 93.1{\%} and outperformed all the SQI metrics, baseSQI, kSQI, and sSQI, with accuracies of 85.7{\%}, 63.7{\%}, and 73.8{\%} respectively. Moreover, evaluation of our algorithm on the PhysioNet data showed an accuracy of 82.5{\%}. Conclusion: The proposed algorithm showed better performance for assessing ECG signal quality than traditional signal processing methods. Significance: A more accurate assessment of ECG signal quality can lead to a more robust ECG-based diagnosis of cardiovascular conditions.},
author = {Shahriari, Yalda and Fidler, Richard and Pelter, Michele M. and Bai, Yong and Villaroman, Andrea and Hu, Xiao},
doi = {10.1109/TBME.2017.2717876},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shahriari et al. - 2018 - Electrocardiogram Signal Quality Assessment Based on Structural Image Similarity Metric.pdf:pdf},
issn = {15582531},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {Alarm fatigue,cluster analysis,electrocardiogram (ECG),image quality index (IQI),intensive care unit (ICU),structural similarity index measure (SSIM)},
number = {4},
pages = {748--753},
title = {{Electrocardiogram Signal Quality Assessment Based on Structural Image Similarity Metric}},
volume = {65},
year = {2018}
}
@article{Zhao2018,
abstract = {Dynamic Time Warping (DTW) is an algorithm to align temporal sequences with possible local non-linear distortions, and has been widely applied to audio, video and graphics data alignments. DTW is essentially a point-to-point matching method under some boundary and temporal consistency constraints. Although DTW obtains a global optimal solution, it does not necessarily achieve locally sensible matchings. Concretely, two temporal points with entirely dissimilar local structures may be matched by DTW. To address this problem, we propose an improved alignment algorithm, named shape Dynamic Time Warping (shapeDTW), which enhances DTW by taking point-wise local structural information into consideration. shapeDTW is inherently a DTW algorithm, but additionally attempts to pair locally similar structures and to avoid matching points with distinct neighborhood structures. We apply shapeDTW to align audio signal pairs having ground-truth alignments, as well as artificially simulated pairs of aligned sequences, and obtain quantitatively much lower alignment errors than DTW and its two variants. When shapeDTW is used as a distance measure in a nearest neighbor classifier (NN-shapeDTW) to classify time series, it beats DTW on 64 out of 84 UCR time series datasets, with significantly improved classification accuracies. By using a properly designed local structure descriptor, shapeDTW improves accuracies by more than 10{\%} on 18 datasets. To the best of our knowledge, shapeDTW is the first distance measure under the nearest neighbor classifier scheme to significantly outperform DTW, which had been widely recognized as the best distance measure to date. Our code is publicly accessible at: https://github.com/jiapingz/shapeDTW.},
archivePrefix = {arXiv},
arxivId = {arXiv:1606.01601v1},
author = {Zhao, Jiaping and Itti, Laurent},
doi = {10.1016/j.patcog.2017.09.020},
eprint = {arXiv:1606.01601v1},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Itti - 2018 - shapeDTW Shape Dynamic Time Warping.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Dynamic Time Warping,Sequence alignment,Time series classification},
number = {c},
pages = {171--184},
title = {{shapeDTW: Shape Dynamic Time Warping}},
volume = {74},
year = {2018}
}
@article{Lichtenauer2008,
author = {Lichtenauer, Jeroen F and Hendriks, Emile A and Reinders, Marcel J T},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lichtenauer, Hendriks, Reinders - 2008 - Sign Language Recognition by Combining Statistical DTW and Independent Classification.pdf:pdf},
number = {11},
pages = {2040--2046},
title = {{Sign Language Recognition by Combining Statistical DTW and Independent Classification}},
volume = {30},
year = {2008}
}
@article{Fang2009,
abstract = {Dynamic Time Warping (DTW) and Hidden Markov Model (HMM) are two well-studied non-linear sequence alignment ( or, pattern matching) algorithm. The research trend transited from DTW to HMM in approximately 1988-1990, since DTW is deterministic and lack of the power to model stochastic signals. In this report, I make a comprehensive literature study into this transition, and show that DTW and stochastic DTW, HMM are actually sharing the same idea of DP (dynamic programming). Some experiments are also performed to address this problem.},
author = {Fang, Chunsheng},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang - 2009 - From Dynamic Time Warping ( DTW ) to Hidden Markov Model ( HMM ).pdf:pdf},
journal = {Final project report for ECE742 Stochastic Decision, March 2009},
pages = {1--7},
title = {{From Dynamic Time Warping ( DTW ) to Hidden Markov Model ( HMM )}},
url = {http://cs.uc.edu/{~}fangcg/course/FromDTWtoHMM{\_}ChunshengFang.pdf},
year = {2009}
}
@article{Bahlmann2004,
abstract = {Hse, Heloise, and A. Richard Newton. "Sketched symbol recognition using zernike moments." In on, vol. 1, pp. 367-370. IEEE, 2004.},
author = {Bahlmann, Claus and Burkhardt, Hans},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahlmann, Burkhardt - 2004 - Recognition System frog on hand and Cluster Generative Statistical Dynamic Time Warping.pdf:pdf},
journal = {Pattern Analysis and Machine Intelligence},
number = {3},
pages = {299--310},
title = {{Recognition System frog on hand and Cluster Generative Statistical Dynamic Time Warping}},
volume = {26},
year = {2004}
}
@article{Lo2018,
abstract = {Background Remote cardiac rhythm monitoring and recording, using hand-carried electrocardiogram (ECG) device had been widely used in telemedicine. The feasibility and accuracy analysis on the data recorded by a new miniature ECG system-on-chip (SoC) system has not been explored before. Methods This study evaluated the accuracy of the ECG recordings captured by CardioChip - a single-channeled, low-powered, miniature ECG SoC designed for mobile applications; comparing against Philips Pagewriter Trim III - a Food and Drug Administration certified, widely-used standard 12-lead ECG recording device, within Mackay Memorial Hospital in Taiwan. Results Total of 111 participants, age ranging from 39 to 87years old [mean age: 61.2 ± 13.4, 57 male (51.3{\%})] were enrolled. Two experienced cardiologists rated and scored the ECG morphology to be the same between the two devices, while CardioChip ECG was more sensitive to baseline noise. R-peak amplitudes measured both devices using single lead information (CardioChip ECG vs. Lead 1 in standard 12-lead ECG) showed statistical consistency. Offline analysis of signal correlation coefficients and coherence showed good correlation with both over 0.94 in average (0.94 ± 0.04 and 0.95 ± 0.04, respectively), high agreement between raters (94{\%} agreement) for detecting abnormal cardiac rhythm with excellent R-peak amplitude (r = 0.98, p {\textless} 0.001) and PR interval (r = 0.91, p {\textless} 0.001) correlations, indicating excellent correlation between ECG recordings derived from two different modalities. Conclusions The results suggested that CardioChip ECG is comparable to medical industry standard ECG. The future implementation of wearable ECG device embedded with miniature ECG system-on-chip (SoC) system is ready for clinical use, which will potentially enhance efficacy on identifying subjects with suspected cardiac arrhythmias.},
author = {Lo, Chi In and Chang, Sheng Shiung and Tsai, Jui Peng and Kuo, Jen Yuan and Chen, Ying Ju and Huang, Ming Yuan and Lee, Chao Hsiung and Sung, Kuo Tzu and Hung, Chung Lieh and Hou, Charles Jia Yin and Lai, Edward and Yeh, Hung I. and Chang, Wen Ling and Chang, Wen Han},
doi = {10.6515/ACS.201803_34(2).20170919A},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lo et al. - 2018 - Evaluation of the accuracy of ECG captured by CardioChip through comparison of lead I recording to a standard 12-lead.pdf:pdf},
isbn = {8862253192},
issn = {10116842},
journal = {Acta Cardiologica Sinica},
keywords = {Hand-carry electrocardiogram (ECG) device,R-peak amplitude,System-on-chip (SoC) system,Telemedicine,Wearable device},
number = {2},
pages = {144--151},
title = {{Evaluation of the accuracy of ECG captured by CardioChip through comparison of lead I recording to a standard 12-lead ECG recording device}},
volume = {34},
year = {2018}
}
@article{Sarantopoulou2019,
author = {Sarantopoulou, Dimitra and Nayak, Soumyashant and Brooks, Thomas G and Lahens, Nicholas F},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Comparative evaluation of full-length isoform quantification from RNA-seq.pdf:pdf},
pages = {1--31},
title = {{Comparative evaluation of full-length isoform quantification from Keywords}},
year = {2019}
}
@book{Slosarek2019,
author = {Slosarek, Tamara and B, Milena Kraus and Schapranow, Matthieu-p and Boettinger, Erwin},
doi = {10.1007/978-3-030-17938-0},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Qualitative Comparison of Selected Indel Detection Methods for RNA-Seq Data.pdf:pdf},
isbn = {9783030179380},
keywords = {RNA-Seq,Variant calling,Indels,indels,rna-seq,variant calling},
pages = {166--177},
publisher = {Springer International Publishing},
title = {{Qualitative Comparison of Selected Indel Detection Methods for RNA-Seq Data}},
url = {http://dx.doi.org/10.1007/978-3-030-17938-0{\_}16},
year = {2019}
}
@article{Engstrom2013,
abstract = {High-throughput RNA sequencing is an increasingly accessible method for studying gene structure and activity on a genome-wide scale. A critical step in RNA-seq data analysis is the alignment of partial transcript reads to a reference genome sequence. To assess the performance of current mapping software, we invited developers of RNA-seq aligners to process four large human and mouse RNA-seq data sets. In total, we compared 26 mapping protocols based on 11 programs and pipelines and found major performance differences between methods on numerous benchmarks, including alignment yield, basewise accuracy, mismatch and gap placement, exon junction discovery and suitability of alignments for transcript reconstruction. We observed concordant results on real and simulated RNA-seq data, confirming the relevance of the metrics employed. Future developments in RNA-seq alignment methods would benefit from improved placement of multimapped reads, balanced utilization of existing gene annotation and a reduced false discovery rate for splice junctions.},
author = {Engstr{\"{o}}m, P{\"{a}}r G. and Steijger, Tamara and Sipos, Botond and Grant, Gregory R. and Kahles, Andr{\'{e}} and R{\"{a}}tsch, Gunnar and Goldman, Nick and Hubbard, Tim J. and Harrow, Jennifer and Guig{\'{o}}, Roderic and Bertone, Paul and Alioto, Tyler and Behr, Jonas and Bohnert, Regina and Campagna, Davide and Davis, Carrie A. and Dobin, Alexander and Gingeras, Thomas R. and Jean, G{\'{e}}raldine and Kosarev, Peter and Li, Sheng and Liu, Jinze and Mason, Christopher E. and Molodtsov, Vladimir and Ning, Zemin and Ponstingl, Hannes and Prins, Jan F. and Ribeca, Paolo and Seledtsov, Igor and Solovyev, Victor and Valle, Giorgio and Vitulo, Nicola and Wang, Kai and Wu, Thomas D. and Zeller, Georg},
doi = {10.1038/nmeth.2722},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Systematic evaluation of spliced alignment programs for RNA-seq data.pdf:pdf},
issn = {15487091},
journal = {Nature Methods},
number = {12},
pages = {1185--1191},
title = {{Systematic evaluation of spliced alignment programs for RNA-seq data}},
volume = {10},
year = {2013}
}
@article{Medina2016,
abstract = {{\textcopyright} The Author 2016. Published by Oxford University Press on behalf of Kazusa DNA Research Institute. As sequencing technologies progress, the amount of data produced grows exponentially, shifting the bottleneck of discovery towards the data analysis phase. In particular, currently available mapping solutions for RNA-seq leave room for improvement in terms of sensitivity and performance, hindering an efficient analysis of transcriptomes by massive sequencing. Here, we present an innovative approach that combines re-engineering, optimization and parallelization. This solution results in a significant increase of mapping sensitivity over a wide range of read lengths and substantial shorter runtimes when compared with current RNA-seq mapping methods available.},
author = {Medina, I. and T{\'{a}}rraga, J. and Mart{\'{i}}nez, H. and Barrachina, S. and Castillo, M. I. and Paschall, J. and Salavert-Torres, J. and Blanquer-Espert, I. and Hern{\'{a}}ndez-Garc{\'{i}}a, V. and Quintana-Ort{\'{i}}, E. S. and Dopazo, J.},
doi = {10.1093/dnares/dsv039},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Highly sensitive and ultrafast read mapping for RNA-seq analysis.pdf:pdf},
issn = {17561663},
journal = {DNA Research},
keywords = {Burrows-Wheeler Transform,RNA-seq,high-performance computing,mapping},
number = {2},
pages = {93--100},
title = {{Highly sensitive and ultrafast read mapping for RNA-seq analysis}},
volume = {23},
year = {2016}
}
@article{Griebel2012,
abstract = {High-throughput sequencing of cDNA libraries constructed from cellular RNA complements (RNA-Seq) naturally provides a digital quantitative measurement for every expressed RNA molecule. Nature, impact and mutual interference of biases in different experimental setups are, however, still poorly understood-mostly due to the lack of data from intermediate protocol steps. We analysed multiple RNA-Seq experiments, involving different sample preparation protocols and sequencing platforms: we broke them down into their common--and currently indispensable--technical components (reverse transcription, fragmentation, adapter ligation, PCR amplification, gel segregation and sequencing), investigating how such different steps influence abundance and distribution of the sequenced reads. For each of those steps, we developed universally applicable models, which can be parameterised by empirical attributes of any experimental protocol. Our models are implemented in a computer simulation pipeline called the Flux Simulator, and we show that read distributions generated by different combinations of these models reproduce well corresponding evidence obtained from the corresponding experimental setups. We further demonstrate that our in silico RNA-Seq provides insights about hidden precursors that determine the final configuration of reads along gene bodies; enhancing or compensatory effects that explain apparently controversial observations can be observed. Moreover, our simulations identify hitherto unreported sources of systematic bias from RNA hydrolysis, a fragmentation technique currently employed by most RNA-Seq protocols.},
author = {Griebel, Thasso and Zacher, Benedikt and Ribeca, Paolo and Raineri, Emanuele and Lacroix, Vincent and Guig{\'{o}}, Roderic and Sammeth, Michael},
doi = {10.1093/nar/gks666},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Modelling and simulating generic RNA-Seq experiments with the flux simulator.pdf:pdf},
issn = {03051048},
journal = {Nucleic Acids Research},
number = {20},
pages = {10073--10083},
title = {{Modelling and simulating generic RNA-Seq experiments with the flux simulator}},
volume = {40},
year = {2012}
}
@article{Serra2014,
abstract = {Time series are ubiquitous, and a measure to assess their similarity is a core part of many computational systems. In particular, the similarity measure is the most essential ingredient of time series clustering and classification systems. Because of this importance, countless approaches to estimate time series similarity have been proposed. However, there is a lack of comparative studies using empirical, rigorous, quantitative, and large-scale assessment strategies. In this article, we provide an extensive evaluation of similarity measures for time series classification following the aforementioned principles. We consider 7 different measures coming from alternative measure 'families', and 45 publicly-available time series data sets coming from a wide variety of scientific domains. We focus on out-of-sample classification accuracy, but in-sample accuracies and parameter choices are also discussed. Our work is based on rigorous evaluation methodologies and includes the use of powerful statistical significance tests to derive meaningful conclusions. The obtained results show the equivalence, in terms of accuracy, of a number of measures, but with one single candidate outperforming the rest. Such findings, together with the followed methodology, invite researchers on the field to adopt a more consistent evaluation criteria and a more informed decision regarding the baseline measures to which new developments should be compared. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1401.3973v1},
author = {Serr{\`{a}}, Joan and Arcos, Josep Ll},
doi = {10.1016/j.knosys.2014.04.035},
eprint = {arXiv:1401.3973v1},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Serr{\`{a}}, Arcos - 2014 - An empirical evaluation of similarity measures for time series classification(2).pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Classification,Clustering,Evaluation,Similarity measures,Time series},
pages = {305--314},
title = {{An empirical evaluation of similarity measures for time series classification}},
volume = {67},
year = {2014}
}
@article{Georgiou2018,
abstract = {Background: A growing number of wearable devices claim to provide accurate, cheap and easily applicable heart rate variability (HRV) indices. This is mainly accomplished by using wearable photoplethysmography (PPG) and/or electrocar-diography (ECG), through simple and non-invasive techniques, as a substitute of the gold standard RR interval estimation through electrocardiogram. Although the agreement between pulse rate variability (PRV) and HRV has been evaluated in the literature, the reported results are still inconclusive especially when using wearable devices. Aim: The purpose of this systematic review is to investigate if wearable devices provide a reliable and precise measurement of classic HRV parameters in rest as well as during exercise. Materials and methods: A search strategy was implemented to retrieve relevant articles from MEDLINE and SCOPUS databases, as well as, through internet search. The 308 articles retrieved were reviewed for further evaluation according to the predetermined inclusion/exclusion criteria. Results: Eighteen studies were included. Sixteen of them integrated ECG-HRV technology and two of them PPG-PRV technology. All of them examined wear-able devices accuracy in RV detection during rest, while only eight of them during exercise. The correlation between classic ECG derived HRV and the wearable RV ranged from very good to excellent during rest, yet it declined progressively as exercise level increased. Conclusions: Wearable devices may provide a promising alternative solution for measuring RV. However, more robust studies in non-stationary conditions are needed using appropriate methodology in terms of number of subjects involved, acquisition and analysis techniques implied. BACKGROUND},
author = {Georgiou, Konstantinos and Larentzakis, Andreas V. and Khamis, Nehal N. and Alsuhaibani, Ghadah I. and Alaska, Yasser A. and Giallafos, Elias J.},
doi = {10.2478/folmed-2018-0012},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Georgiou et al. - 2018 - Can Wearable Devices Accurately Measure Heart Rate Variability A Systematic Review(2).pdf:pdf},
issn = {02048043},
journal = {Folia medica},
keywords = {heart rate,heart rate variability,photoplethysmography,wearable},
number = {1},
pages = {7--20},
title = {{Can Wearable Devices Accurately Measure Heart Rate Variability? A Systematic Review}},
volume = {60},
year = {2018}
}
@article{Kennedy2007,
abstract = {A new measure of similarity, suitable for both signal processing and image processing applications, is presented. The measure of similarity ( Z{\textless}sub{\textgreater}M{\textless}/sub{\textgreater} ) is an F-distributed test statistic that quantifies the degree of alignment, correlation or coincidence between two or more (time-or space-dependent) waveforms. The test statistic may be used to automate detection, classification, localisation, association and registration operations. When used to estimate time-of-arrival differences, which is typically done using cross correlation or beam formation, the technique provides an efficient means of: maintaining a low and constant false-alarm rate, detecting weak signals in noise and reducing angular errors. The method is applied to the problem of acoustic source detection and localisation. Real data are used to compare the method with cross correlation and normalised cross correlation. The new method yields prominent and narrow peaks, at the true source locations, with false peaks due to misalignment, misassociation, and background noise, suppressed. When processing continuous data streams, the test statistic is computed efficiently in the time domain.},
author = {Kennedy, Hugh L.},
doi = {10.1109/IDC.2007.374535},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kennedy - 2007 - A new statistical measure of signal similarity.pdf:pdf},
isbn = {1424409020},
journal = {Conference Proceedings of 2007 Information, Decision and Control, IDC},
number = {March 2007},
pages = {112--117},
title = {{A new statistical measure of signal similarity}},
year = {2007}
}
@article{ESLING2012,
abstract = {Modern technologies have allowed for the amassment of data at a rate never encountered before. Organizations are now able to routinely collect and process massive volumes of data. A plethora of regularly collected information can be ordered using an appropriate time interval. The data would thus be developed into a time series. Time series data mining methodology identifies commonalities between sets of time-ordered data. Time series data mining detects similar time series using a technique known as dynamic time warping (DTW). This research provides a practical application of time series data mining. A real-world data set was provided to the authors by dunnhumby. A time series data mining analysis is performed using retail grocery store chain data and results are provided.},
annote = {search in google later:
1. similarity measure to measure signal to noise ratio

Applications of similarity measure
- 1. Querying
- 2. Clustering
- 3. Classification
- 4. Segmentation
- 5. Prediction
- 6. Anomaly Detection
- 7. Motif Discovery},
author = {ESLING, PHILIPPE and AGON, CARLOS},
doi = {10.4018/ijban.2014100104},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/ESLING, AGON - 2012 - Time Series Data Mining.pdf:pdf},
issn = {2334-4547},
journal = {ACM Computing Surveys,},
number = {4},
pages = {51--68},
title = {{Time Series Data Mining}},
volume = {1},
year = {2012}
}
@article{Hassanpour2011,
annote = {- Figure 1 lists possible translatations involved in a signal

- The novel method is flexible in 
1. amplitude-scale
2. amplitude-shift
3. time-shift, phase-delay, and time-scale 
4. different lengths by re-sampling (makes them equal length)

- ORL is flexible in
1. time-shift or phase-delay
2. amplitude-shift (DC offset)
3. amplitude-scale

- Linear regression is flexible in:
1. amplitude-scale
2. offset-shift
But can't compare:
1. different lengths
2. time-shifts
3. time-scale},
author = {Hassanpour, Hamid and Darvishi, Ali and Khalili, Atena},
doi = {10.1080/00207217.2011.589740},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassanpour, Darvishi, Khalili - 2011 - A regression-based approach for measuring similarity in discrete signals(2).pdf:pdf},
issn = {00207217},
journal = {International Journal of Electronics},
keywords = {amplitude-scale,amplitude-shift,regression analysis,similarity measure,time series,time-scale,time-shift},
number = {9},
pages = {1141--1156},
title = {{A regression-based approach for measuring similarity in discrete signals}},
volume = {98},
year = {2011}
}
@article{Serra2014a,
abstract = {Time series are ubiquitous, and a measure to assess their similarity is a core part of many computational systems. In particular, the similarity measure is the most essential ingredient of time series clustering and classification systems. Because of this importance, countless approaches to estimate time series similarity have been proposed. However, there is a lack of comparative studies using empirical, rigorous, quantitative, and large-scale assessment strategies. In this article, we provide an extensive evaluation of similarity measures for time series classification following the aforementioned principles. We consider 7 different measures coming from alternative measure 'families', and 45 publicly-available time series data sets coming from a wide variety of scientific domains. We focus on out-of-sample classification accuracy, but in-sample accuracies and parameter choices are also discussed. Our work is based on rigorous evaluation methodologies and includes the use of powerful statistical significance tests to derive meaningful conclusions. The obtained results show the equivalence, in terms of accuracy, of a number of measures, but with one single candidate outperforming the rest. Such findings, together with the followed methodology, invite researchers on the field to adopt a more consistent evaluation criteria and a more informed decision regarding the baseline measures to which new developments should be compared. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1401.3973v1},
author = {Serr{\`{a}}, Joan and Arcos, Josep Ll},
doi = {10.1016/j.knosys.2014.04.035},
eprint = {arXiv:1401.3973v1},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Serr{\`{a}}, Arcos - 2014 - An empirical evaluation of similarity measures for time series classification.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Classification,Clustering,Evaluation,Similarity measures,Time series},
pages = {305--314},
title = {{An empirical evaluation of similarity measures for time series classification}},
volume = {67},
year = {2014}
}
@article{Laborde2017,
abstract = {{\textcopyright} 2017 Laborde, Mosley and Thayer. Psychophysiological research integrating heart rate variability (HRV) has increased during the last two decades, particularly given the fact that HRV is able to index cardiac vagal tone. Cardiac vagal tone, which represents the contribution of the parasympathetic nervous system to cardiac regulation, is acknowledged to be linked with many phenomena relevant for psychophysiological research, including self-regulation at the cognitive, emotional, social, and health levels. The ease of HRV collection and measurement coupled with the fact it is relatively affordable, non-invasive and pain free makes it widely accessible to many researchers. This ease of access should not obscure the difficulty of interpretation of HRV findings that can be easily misconstrued, however, this can be controlled to some extent through correct methodological processes. Standards of measurement were developed two decades ago by a Task Force within HRV research, and recent reviews updated several aspects of the Task Force paper. However, many methodological aspects related to HRV in psychophysiological research have to be considered if one aims to be able to draw sound conclusions, which makes it difficult to interpret findings and to compare results across laboratories. Those methodological issues have mainly been discussed in separate outlets, making difficult to get a grasp on them, and thus this paper aims to address this issue. It will help to provide psychophysiological researchers with recommendations and practical advice concerning experimental designs, data analysis, and data reporting. This will ensure that researchers starting a project with HRV and cardiac vagal tone are well informed regarding methodological considerations in order for their findings to contribute to knowledge advancement in their field.},
author = {Laborde, Sylvain and Mosley, Emma and Thayer, Julian F.},
doi = {10.3389/fpsyg.2017.00213},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Laborde, Mosley, Thayer - 2017 - Heart rate variability and cardiac vagal tone in psychophysiological research - Recommendations for exp.pdf:pdf},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Cardiac vagal control,Heart rate variability,Parasympathetic activity,Parasympathetic nervous system,Vagal activity,Vagal tone},
number = {FEB},
pages = {1--18},
title = {{Heart rate variability and cardiac vagal tone in psychophysiological research - Recommendations for experiment planning, data analysis, and data reporting}},
volume = {8},
year = {2017}
}
@article{Menghini2019,
author = {Menghini, Luca and Gianfranchi, Evelyn and Cellini, Nicola and Patron, Elisabetta and Tagliabue, Mariaelena and Sarlo, Michela},
doi = {10.1111/psyp.13441},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Menghini et al. - 2019 - Stressing the accuracy Wrist‐worn wearable sensor validation over different conditions.pdf:pdf},
issn = {0048-5772},
journal = {Psychophysiology},
keywords = {autonomic,heart rate,heart rate variability,skin conductance,stress,wearable sensor},
number = {April},
pages = {1--15},
title = {{Stressing the accuracy: Wrist‐worn wearable sensor validation over different conditions}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/psyp.13441},
year = {2019}
}
@article{Quintana2017,
abstract = {{\textcopyright} 2016 Society for Psychophysiological Research The calculation of heart rate variability (HRV) is a popular tool used to investigate differences in cardiac autonomic control between population samples. When interpreting effect sizes to quantify the magnitude of group differences, researchers typically use Cohen's guidelines of small (0.2), medium (0.5), and large (0.8) effects. However, these guidelines were originally proposed as a fallback for when the effect size distribution (ESD) was unknown. Despite the availability of effect sizes from hundreds of HRV studies, researchers still largely rely on Cohen's guidelines to interpret effect sizes and to perform power analyses to calculate required sample sizes for future research. This article describes an ESD analysis of 297 HRV effect sizes from between-group/case-control studies, revealing that the 25th, 50th, and 75th effect size percentiles correspond with effect sizes of 0.26, 0.51, and 0.88, respectively. The analyses suggest that Cohen's guidelines may underestimate the magnitude of small and large effect sizes and that HRV studies are generally underpowered. Therefore, to better reflect the observed ESD, effect sizes of 0.25, 0.5, and 0.9 should be interpreted as small, medium, and large effects (after rounding to the closest 0.05). Based on power calculations using the ESD, suggested sample sizes are also provided for planning suitably powered studies that are more likely to replicate. Researchers are encouraged to use the ESD data set or their own collected data sets in tandem with the provided analysis script to perform custom ESD and power analyses relevant to their specific research area.},
author = {Quintana, Daniel S.},
doi = {10.1111/psyp.12798},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Quintana - 2017 - Statistical considerations for reporting and planning heart rate variability case-control studies.pdf:pdf;:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Quintana - 2017 - Statistical considerations for reporting and planning heart rate variability case-control studies(2).pdf:pdf},
issn = {14698986},
journal = {Psychophysiology},
keywords = {Effect size,Heart rate variability,Sample size,Statistical power},
number = {3},
pages = {344--349},
title = {{Statistical considerations for reporting and planning heart rate variability case-control studies}},
volume = {54},
year = {2017}
}
@article{Flatt2013,
abstract = {The purpose of this investigation was to cross-validate the ithlete TM heart rate variability smart phone application with an electrocardiograph for determining ultra-short-term root mean square of successive R-R intervals. The root mean square of successive R-R intervals was simultaneously determined via electrocardiograph and ithlete TM at rest in twenty five healthy participants. There were no significant differences between the electrocardiograph and ithlete TM derived root mean square of successive R-R interval values (p {\textgreater} 0.05) and the correlation was near perfect (r = 0.99, p {\textless} 0.001). In addition, the ithlete TM revealed a Standard Error of the Estimate of 1.47 and Bland Altman plot showed that the limits of agreement ranged from 2.57 below to 2.63 above the constant error of -0.03. In conclusion, the ithlete TM appeared to provide a suitably accurate measure of root mean square of successive R-R intervals when compared to the electrocardiograph measures obtained in the laboratory within the current sample of healthy adult participants. The current study lays groundwork for future research determining the efficacy of ithlete TM for reflecting athletic training status over a chronic conditioning period.},
author = {Flatt, Andrew A. and Esco, Michael R.},
doi = {10.2478/hukin-2013-0071},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Flatt, Esco - 2013 - Validity of the ithletetm smart phone application for determining ultra-short-term heart rate variability.pdf:pdf},
issn = {18997562},
journal = {Journal of Human Kinetics},
keywords = {Athlete Monitoring,HRV,Mobile Device,Parasympathetic},
number = {1},
pages = {85--92},
title = {{Validity of the ithletetm smart phone application for determining ultra-short-term heart rate variability}},
volume = {39},
year = {2013}
}
@article{Gamelin2008,
abstract = {Intervals between two consecutive cardiac beats (R-R intervals) and the subsequent analysis of heart rate variability (HRV) obtained simultaneously from the Polar S810 heart rate monitor (HRM) and an electrocardiogram (ECG) in a supine position were compared in twelve children (age 9.6 +/- 0.9 years) before and after protocol correction. R-R intervals were significantly different between the ECG and the HRM uncorrected and corrected signal (p {\textless} 0.001, effect size [ES] = 0.005, and 0.005, respectively). However, the bias (95 {\%} confidence interval) was 0.80 (- 124.76 - 123.16) ms and 0.80 (- 12.76 - 11.16) ms, respectively. HRV parameters derived from both signals were not different (p {\textgreater} 0.05) and well correlated (r {\textgreater} 0.99, p {\textless} 0.05), except SD2 (p {\textless} 0.05, ES = 0.000; r = 0.99). These data support the validity of the Polar S810 HRM to measure R-R intervals and make the subsequent HRV analysis in a supine position in children.},
annote = {Need for a better similarity measure:

- to allow the comparison between the ECG and the uncorrected HRM data, an ECG R-R interval of 0ms was inserted when a type 5 error was present. On the contrary, a Polar R-R interval of 0 ms was inserted when a type 4 error was present.
- An error due to the HRM acquisition was considered when the difference between ECG and HRM interval exceeded 20 ms},
author = {Gamelin, Fran{\c{c}}ois Xavier and Baquet, G. and Berthoin, S. and Bosquet, L.},
doi = {10.1055/s-2007-964995},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gamelin et al. - 2008 - Validity of the polar S810 to measure R-R intervals in children.pdf:pdf},
issn = {01724622},
journal = {International Journal of Sports Medicine},
keywords = {Frequency domain analysis,Heart rate variability,Poincar{\'{e}} graph analysis,Time domain analysis},
number = {2},
pages = {134--138},
title = {{Validity of the polar S810 to measure R-R intervals in children}},
volume = {29},
year = {2008}
}
@article{Jansen2015,
abstract = {Few studies have included subjects with the propensity to reach old age in good health, with the aim to disentangle mechanisms contributing to staying healthier for longer. The hypothalamic-pituitary-thyroid (HPT) axis maintains circulating levels of thyroid stimulating hormone (TSH) and thyroid hormone (TH) in an inverse relationship. Greater longevity has been associated with higher TSH and lower TH levels, but mechanisms underlying TSH/TH differences and longevity remain unknown. The HPT axis plays a pivotal role in growth, development and energy metabolism. We report that offspring of nonagenarians with at least one nonagenarian sibling have increased TSH secretion but similar bioactivity of TSH and similar TH levels compared to controls. Healthy offspring and spousal controls had similar resting metabolic rate and core body temperature. We propose that pleiotropic effects of the HPT axis may favour longevity without altering energy metabolism.},
author = {Jansen, S. W. and Akintola, A. A. and Roelfsema, F. and {Van Der Spoel}, E. and Cobbaert, C. M. and Ballieux, B. E. and Egri, P. and Kvarta-Papp, Z. and Gereben, B. and Fekete, C. and Slagboom, P. E. and {Van Der Grond}, J. and Demeneix, B. A. and Pijl, H. and Westendorp, R. G.J. and {Van Heemst}, D.},
doi = {10.1038/srep11525},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jansen et al. - 2015 - Human longevity is characterised by high thyroid stimulating hormone secretion without altered energy metabolism.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {June},
pages = {1--11},
publisher = {Nature Publishing Group},
title = {{Human longevity is characterised by high thyroid stimulating hormone secretion without altered energy metabolism}},
url = {http://dx.doi.org/10.1038/srep11525},
volume = {5},
year = {2015}
}
@article{Giles2016,
abstract = {Purpose: This study was conducted to compare R–R intervals and the subsequent analysis of heart rate variability (HRV) obtained from the Polar S810 heart rate monitor (HRM) (Polar Electro Oy) with an electrocardiogram (ECG) (Physiotrace, Estaris, Lille, France) during an orthostatic test. Methods: A total of 18 healthy men (age: 27.1 T 1.9 yr; height: 1.82 T 0.06 m; mass 77.1 T 7.7 kg) performed an active orthostatic test during which R–R intervals were simultaneously recorded with the HRM and the ECG recorder The two signals were synchronized and corrected before a time domain analysis, the fast Fourier transform (FFT) and a Poincare ´ plot analysis. Bias and limits of agreement (LoA), effect size (ES), and correlation coefficients were calculated. Results: R–R intervals were significantly different in the supine and standing position between the ECG and the HRM uncorrected and corrected signal (P G 0.05, ES = 0.000 and 0.006, respectively). The bias T LoA, however, were 0.9 T 12 ms. HRV parameters derived from both signals in both positions were not different (P {\textgreater} 0.05) and well correlated (r {\textgreater} 0.97, P G 0.05), except root mean square of difference (RMSSD) and SD1 in standing position (P G 0.05, ES = 0.052 and 0.057; r = 0.99 and 0.98, respectively). Conclusion: Narrow LoA, good correlations, and small effect sizes support the validity of the Polar S810 HRM to measure R–R intervals and make the subsequent HRV analysis in supine position. Caution must be taken in standing position for the parameters sensitive to the short-term variability (i.e., RMSSD and SD1).},
author = {Giles, David and Draper, Nick and Neil, William},
doi = {10.1007/s00421-015-3303-9},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Giles, Draper, Neil - 2016 - Validity of the Polar V800 heart rate monitor to measure RR intervals at rest.pdf:pdf},
issn = {14396319},
journal = {European Journal of Applied Physiology},
keywords = {Frequency domain analysis,Heart rate variability,Non-linear analysis,Polar V800,Time domain analysis},
number = {3},
pages = {563--571},
publisher = {Springer Berlin Heidelberg},
title = {{Validity of the Polar V800 heart rate monitor to measure RR intervals at rest}},
volume = {116},
year = {2016}
}
@article{Nunan2009,
abstract = {Purpose: To assess the validity and the reliability of short-term resting heart-rate variability (HRV) measures obtained using the Polar S810 heart-rate monitor and accompanying software. Methods: Measures of HRV were obtained from 5-min R to R wave (RR) interval data for 19 males and 14 females during 10 min of quiet rest on three separate occasions at 1-wk intervals using the Polar S8.10. Criterion measures of HRV were obtained simultaneously using the CardioPerfect (CP; Medical Graphics Corporation, St Paul, MN) 12-lead ECG module. Measures of validity of the Polar S810 were estimated by regression analysis, and measures of reliability of both. devices were estimated by analysis of change scores. Measures of the SD of normal-to-normal intervals (SDNN), the root mean square of successive differences (RMSSD), and the low-frequency (LF) and the high-frequency (HF) spectral power and their ratio (LF/HF) were analyzed after log transformation, whereas mean RR and LF and HF in normalized units were analyzed without transformation. Results: There were marginal differences between the Polar and the CP mean measures of HRV, and the uncertainty in the differences was small. The Polar S810 demonstrated high correlations (0.85-0.99) with CP for all measures of HRV indicating good to near-perfect validity. Except for the low- and the high-frequency normalized units, Polar S810 did not add any substantial technical error to the within-subject variability in the repeated measurements of HRV. Conclusion: HRV measures obtained with the Polar S810 and accompanying software have no appreciable bias or additional random error in comparison with criterion measures, but the measures are inherently unreliable over a 1-wk interval. Reliability of HRV from longer (e.g., 10 min) and/or consecutive 5-min RR recordings needs to be investigated with the Polar and criterion instruments. Copyright {\textcopyright} 2008 by the American College of Sports Medicine.},
author = {Nunan, David and Gay, Donovan and Jakovljevic, Djordje G. and Hodges, Lynette D. and Sandercock, Gavin R.H. and Brodie, David A.},
doi = {10.1249/MSS.0b013e318184a4b1},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nunan et al. - 2009 - Validity and reliability of short-term heart-rate variability from the Polar S810.pdf:pdf},
issn = {01959131},
journal = {Medicine and Science in Sports and Exercise},
keywords = {Concurrent validity,Noise,Overtrained,Reproducibility,Technical error},
number = {1},
pages = {243--250},
title = {{Validity and reliability of short-term heart-rate variability from the Polar S810}},
volume = {41},
year = {2009}
}
@article{Escalona2017,
annote = {does not discuss RNA sequencing (RNAseq) simulation},
author = {Escalona, Merly and Rocha, Sara and Posada, David},
doi = {10.1038/nrg.2016.57.A},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/A comparison of tools for the simulation of genomic nextgeneration sequencing data.pdf:pdf},
journal = {Nature Reviews Genetics},
number = {8},
pages = {459--469},
title = {{A comparison of tools for the simulation of genomic next- generation sequencing data}},
volume = {17},
year = {2017}
}
@article{,
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/PBSIM -  PacBio reads simulator—toward accurate genome assembly (Supplementary).pdf:pdf},
pages = {1--14},
title = {{PBSIM: PacBio reads simulator - Toward accurate genome assembly (Supplementary)}}
}
@article{Grant2011,
abstract = {MOTIVATION: A critical task in high-throughput sequencing is aligning millions of short reads to a reference genome. Alignment is especially complicated for RNA sequencing (RNA-Seq) because of RNA splicing. A number of RNA-Seq algorithms are available, and claim to align reads with high accuracy and efficiency while detecting splice junctions. RNA-Seq data are discrete in nature; therefore, with reasonable gene models and comparative metrics RNA-Seq data can be simulated to sufficient accuracy to enable meaningful benchmarking of alignment algorithms. The exercise to rigorously compare all viable published RNA-Seq algorithms has not been performed previously.$\backslash$n$\backslash$nRESULTS: We developed an RNA-Seq simulator that models the main impediments to RNA alignment, including alternative splicing, insertions, deletions, substitutions, sequencing errors and intron signal. We used this simulator to measure the accuracy and robustness of available algorithms at the base and junction levels. Additionally, we used reverse transcription-polymerase chain reaction (RT-PCR) and Sanger sequencing to validate the ability of the algorithms to detect novel transcript features such as novel exons and alternative splicing in RNA-Seq data from mouse retina. A pipeline based on BLAT was developed to explore the performance of established tools for this problem, and to compare it to the recently developed methods. This pipeline, the RNA-Seq Unified Mapper (RUM), performs comparably to the best current aligners and provides an advantageous combination of accuracy, speed and usability.$\backslash$n$\backslash$nAVAILABILITY: The RUM pipeline is distributed via the Amazon Cloud and for computing clusters using the Sun Grid Engine (http://cbil.upenn.edu/RUM).$\backslash$n$\backslash$nCONTACT: ggrant@pcbi.upenn.edu; epierce@mail.med.upenn.edu$\backslash$n$\backslash$nSUPPLEMENTARY INFORMATION: The RNA-Seq sequence reads described in the article are deposited at GEO, accession GSE26248.},
annote = {BEER},
author = {Grant, Gregory R. and Farkas, Michael H. and Pizarro, Angel D. and Lahens, Nicholas F. and Schug, Jonathan and Brunk, Brian P. and Stoeckert, Christian J. and Hogenesch, John B. and Pierce, Eric A.},
doi = {10.1093/bioinformatics/btr427},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Comparative analysis of RNA-Seq alignment algorithms and the RNA-Seq unified mapper (RUM).pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
number = {18},
pages = {2518--2528},
title = {{Comparative analysis of RNA-Seq alignment algorithms and the RNA-Seq unified mapper (RUM)}},
volume = {27},
year = {2011}
}
@article{,
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Introduction to RNA-Seq and what it can do.pdf:pdf},
title = {{Introduction to RNA-Seq and what we can do with it}}
}
@article{Ono2013,
abstract = {Motivation: PacBio sequencers produce two types of characteristic reads (continuous long reads: long and high error rate and circular consensus sequencing: short and low error rate), both of which could be useful for de novo assembly of genomes. Currently, there is no available simulator that targets the specific generation of PacBio libraries.Results: Our analysis of 13 PacBio datasets showed characteristic features of PacBio reads (e.g. the read length of PacBio reads follows a log-normal distribution). We have developed a read simulator, PBSIM, that captures these features using either a model-based or sampling-based method. Using PBSIM, we conducted several hybrid error correction and assembly tests for PacBio reads, suggesting that a continuous long reads coverage depth of at least 15 in combination with a circular consensus sequencing coverage depth of at least 30 achieved extensive assembly results. {\textcopyright} The Author(s) 2012. Published by Oxford University Press.},
author = {Ono, Yukiteru and Asai, Kiyoshi and Hamada, Michiaki},
doi = {10.1093/bioinformatics/bts649},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/PBSIM -  PacBio reads simulator—toward accurate genome assembly.pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
number = {1},
pages = {119--121},
title = {{PBSIM: PacBio reads simulator - Toward accurate genome assembly}},
volume = {29},
year = {2013}
}
@article{GiacomoBaruzzo15KatharinaEHayer25EunJiKim2BarbaraDiCamillo1GarretAFitzGerald23andGregoryRGrant22016,
abstract = {Reliance on glutamine has long been considered to be a hallmark of cancer cell metabolism. However, some recent studies have challenged this notion in vivo, prompting a need for further clarification of the role of glutamine metabolism in cancer. We find that there is ample evidence of an essential role for glutamine in tumors, and that a variety of factors, including tissue type, the underlying cancer genetics, the tumor microenvironment, and other variables such as diet and host physiology collectively influence the role of glutamine in cancer. Thus the requirements for glutamine in cancer are overall highly heterogeneous. In this review we discuss the implications both for basic science and for targeting glutamine metabolism in cancer therapy.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {{Giacomo Baruzzo1, 5, Katharina E Hayer2, 5, Eun Ji Kim2, Barbara Di Camillo1, Garret A FitzGerald2, 3, and Gregory R Grant2}, 4},
doi = {10.7205/MILMED-D-14-00168.Long-chain},
eprint = {15334406},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Simulation-based comprehensive benchmarking of RNA-seq aligners.pdf:pdf},
isbn = {1530752558},
issn = {1527-5418},
journal = {Science},
keywords = {antifungal,are problematic for critically,cancer cells undergo a,cancer metabolism,glutaminase,glutamine metabolism,ifis,ill patients,immunosuppression,invasive fungal infection,invasive fungal infections,metabolic reprogramming in cancer,order to maintain bioenergetics,pharmacokinetics,pharmacology,posaconazole,reprogramming of metabolism in,tca cycle anaplerosis,triazole,with increased},
number = {11 0},
pages = {95--105},
pmid = {28299348},
title = {{Simulation-based comprehensive benchmarking of RNA-seq aligners}},
url = {https://www.sciencedirect.com/science/article/pii/S2405803317300225},
volume = {179},
year = {2016}
}
@article{Xu2013,
author = {Xu, Xiao and Williams, Jennie and Denoya, Paula and Li, Ellen and Antoniou, Eric and McCombie, W R. and Zhang, Yuanhao and Wu, Song and Zhu, Wei and Davidson, Nicholas O.},
doi = {10.1186/1471-2105-14-S9-S1},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Parallel comparison of Illumina RNA-Seq and Affymetrix microarray platforms on transcriptomic profiles generated from 5-aza-deoxy-cytidine treated HT-29 colon cancer cells and simulated datasets.pdf:pdf},
issn = {1471-2105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Azacitidine,Colonic Neoplasms,Gene Expression Profiling,HT29 Cells,Humans,Methodology Article,Neoplasm,Oligonucleotide Array Sequence Analysis,RNA,Regression Analysis,Sensitivity and Specificity,Sequence Analysis},
number = {SUPPL9},
pages = {1--14},
title = {{Parallel comparison of Illumina RNA-Seq and Affymetrix microarray platforms on transcriptomic profiles generated from 5-aza-deoxy-cytidine treated HT-29 colon cancer cells and simulated datasets}},
volume = {14},
year = {2013}
}
@article{Krizanovic2018,
abstract = {{\textcopyright} The Author 2017. Published by Oxford University Press. All rights reserved. Motivation High-throughput sequencing has transformed the study of gene expression levels through RNA-seq, a technique that is now routinely used by various fields, such as genetic research or diagnostics. The advent of third generation sequencing technologies providing significantly longer reads opens up new possibilities. However, the high error rates common to these technologies set new bioinformatics challenges for the gapped alignment of reads to their genomic origin. In this study, we have explored how currently available RNA-seq splice-aware alignment tools cope with increased read lengths and error rates. All tested tools were initially developed for short NGS reads, but some have claimed support for long Pacific Biosciences (PacBio) or even Oxford Nanopore Technologies (ONT) MinION reads. Results The tools were tested on synthetic and real datasets from two technologies (PacBio and ONT MinION). Alignment quality and resource usage were compared across different aligners. The effect of error correction of long reads was explored, both using self-correction and correction with an external short reads dataset. A tool was developed for evaluating RNA-seq alignment results. This tool can be used to compare the alignment of simulated reads to their genomic origin, or to compare the alignment of real reads to a set of annotated transcripts. Our tests show that while some RNA-seq aligners were unable to cope with long error-prone reads, others produced overall good results. We further show that alignment accuracy can be improved using error-corrected reads.},
author = {Kri{\v{z}}anovi{\'{c}}, Kre{\v{s}}imir and Echchiki, Amina and Roux, Julien and {\v{S}}iki{\'{c}}, Mile},
doi = {10.1093/bioinformatics/btx668},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Evaluation of tools for long read RNA-seq splice-aware alignment.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
number = {5},
pages = {748--754},
title = {{Evaluation of tools for long read RNA-seq splice-aware alignment}},
volume = {34},
year = {2018}
}
@article{Zhang2019,
abstract = {Third-generation sequencing platforms, such as PacBio sequencing, have been developed rapidly in recent years. PacBio sequencing generates much longer reads than the second-generation sequencing (or the next generation sequencing, NGS) technologies and it has unique sequencing error patterns. An effective read simulator is essential to evaluate and promote the development of new bioinformatics tools for PacBio sequencing data analysis. We developed a new PacBio Sequencing Simulator (PaSS). It can learn sequence patterns from PacBio sequencing data currently available. In addition to the distribution of read lengths and error rates, we included a context-specific sequencing error model. Compared to existing PacBio sequencing simulators such as PBSIM, LongISLND and NPBSS, PaSS performed better in many aspects. Assembly tests also suggest that reads simulated by PaSS are the most similar to experimental sequencing data. PaSS is an effective sequence simulator for PacBio sequencing. It will facilitate the evaluation and development of new analysis tools for the third-generation sequencing data.},
author = {Zhang, Wenmin and Jia, Ben and Wei, Chaochun},
doi = {10.1186/s12859-019-2901-7},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/PaSS - A Sequencing Simulator for PacBio.pdf:pdf},
journal = {BMC Bioinformatics},
keywords = {Third generation sequencing,Next generation sequen,next generation sequencing,pacbio sequencing,sequence pattern,sequencing error,sequencing simulator,third generation sequencing},
number = {1},
pages = {1--7},
publisher = {BMC Bioinformatics},
title = {{PaSS: a sequencing simulator for PacBio sequencing}},
volume = {20},
year = {2019}
}
@article{Chandramohan2013,
abstract = {RNA-Seq, a deep sequencing technique, promises to be a potential successor to microarraysfor studying the transcriptome. One of many aspects of transcriptomics that are of interest to researchers is gene expression estimation. With rapid development in RNA-Seq, there are numerous tools available to estimate gene expression, each producing different results. However, we do not know which of these tools produces the most accurate gene expression estimates. In this study we have addressed this issue using Cufflinks, IsoEM, HTSeq, and RSEM to quantify RNA-Seq expression profiles. Comparing results of these quantification tools, we observe that RNA-Seq relative expression estimates correlate with RT-qPCR measurements in the range of 0.85 to 0.89, with HTSeq exhibiting the highest correlation. But, in terms of root-mean-square deviation of RNA-Seq relative expression estimates from RT-qPCR measurements, we find HTSeq to produce the greatest deviation. Therefore, we conclude that, though Cufflinks, RSEM, and IsoEM might not correlate as well as HTSeq with RT-qPCR measurements, they may produce expression values with higher accuracy.},
author = {Chandramohan, Raghu and Wu, Po Yen and Phan, John H. and Wang, May D.},
doi = {10.1109/EMBC.2013.6609583},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Benchmarking RNA-Seq Quantification Tools.pdf:pdf},
isbn = {9781457702167},
issn = {1557170X},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
pages = {647--650},
publisher = {IEEE},
title = {{Benchmarking RNA-Seq quantification tools}},
year = {2013}
}
@article{Vanderlei2008,
author = {Vanderlei, L C M and Silva, R A and Pastre, C M and Azevedo, F M and Godoy, M F},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vanderlei et al. - 2008 - Comparison of the Polar S810i monitor and the ECG for the analysis of heart rate variability in the time and f.pdf:pdf},
keywords = {00931,08-dfp,2007,2008,accepted september 3,autonomic nervous system,ecg,exercise,heart rate variability,polar s810i monitor,publication supported by fundunesp,received september 10,spectral analysis},
pages = {854--859},
title = {{Comparison of the Polar S810i monitor and the ECG for the analysis of heart rate variability in the time and frequency domains}},
volume = {41},
year = {2008}
}
@article{Malinsky2016,
author = {Malinsky, Milan and Simpson, Jared T and Durbin, Richard},
doi = {10.1093/bioinformatics/xxxxx},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/SiLiCO - A Simulator of Long Read Sequencing in PacBio and Oxford Nanopore.pdf:pdf},
pages = {1--6},
title = {{SiLiCO: A Simulator of Long Read Sequencing in PacBio and Oxford Nanopore}},
year = {2016}
}
@article{Weber2019,
abstract = {In computational biology and other sciences, researchers are frequently faced with a choice between several computational methods for performing data analyses. Benchmarking studies aim to rigorously compare the performance of different methods using well-characterized benchmark datasets, to determine the strengths of each method or to provide recommendations regarding the best choice of method for an analysis. However, benchmarking studies must be carefully designed and implemented to provide accurate and unbiased results. Here, we summarize key practical guidelines and recommendations for performing high-quality benchmarking analyses, based on our own experiences in computational biology.},
annote = {no simulator mentioned},
author = {Weber, Lukas M. and Saelens, Wouter and Cannoodt, Robrecht and Soneson, Charlotte and Hapfelmeier, Alexander and Gardner, Paul P. and Boulesteix, Anne Laure and Saeys, Yvan and Robinson, Mark D.},
doi = {10.1186/s13059-019-1738-8},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Essential guidelines for computational method benchmarking..pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
number = {1},
pages = {1--12},
publisher = {Genome Biology},
title = {{Essential guidelines for computational method benchmarking}},
volume = {20},
year = {2019}
}
@article{Hassanpour2011a,
author = {Hassanpour, Hamid and Darvishi, Ali and Khalili, Atena},
doi = {10.1080/00207217.2011.589740},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassanpour, Darvishi, Khalili - 2011 - A regression-based approach for measuring similarity in discrete signals.pdf:pdf},
issn = {00207217},
journal = {International Journal of Electronics},
keywords = {amplitude-scale,amplitude-shift,regression analysis,similarity measure,time series,time-scale,time-shift},
number = {9},
pages = {1141--1156},
title = {{A regression-based approach for measuring similarity in discrete signals}},
volume = {98},
year = {2011}
}
@article{Zhao2018a,
abstract = {For both the acquisition of mobile electrocardiogram(ECG) devices and early warning and diagnosis of clinical work, high-quality ECG signals is particularly important. We describe an effective system which could be deployed as a stand-alone signal quality assessment algorithm for vetting the quality of ECG signals. The proposed ECG quality assessment method is based on the simple heuristic fusion and fuzzy comprehensive evaluation of the SQIs. This method includes two modules, i.e., the quantification and extraction of Signal Quality Indexes (SQIs) for different features, intelligent assessment and classification. First, simple heuristic fusion is executed to extract SQIs and determine the following SQIs: R peak detection match qSQI, QRS wave power spectrum distribution pSQI, kurtosis kSQI and baseline relative power basSQI. Then, combined with Cauchy distribution, rectangular distribution and trapezoidal distribution, the membership function of SQIs was quantified, and the fuzzy vector was established. The bounded operator was selected for fuzzy synthesis, and the weighted membership function was used to perform the assessment and classification. The performance of the proposed method was tested on the database from Physionet ECG database, with an accuracy (Acc) of 97.67{\%}, sensitivity (Se) of 96.33{\%} and specificity (Sp) of 98.33{\%} on the training set. Testing against the test datasets resulted in scores of 94.67{\%}, 90.33{\%} and 93.00{\%}, respectively. There's no gold standard exists for determining the quality of ECGs. However, the proposed algorithm discriminates between high- and poor-quality ECGs, which could aid in ECG acquisition for mobile ECG devices, early clinical diagnosis and early warning.},
author = {Zhao, Zhidong and Zhang, Yefei},
doi = {10.3389/fphys.2018.00727},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Zhang - 2018 - SQI quality evaluation mechanism of single-lead ECG signal based on simple heuristic fusion and fuzzy comprehensive.pdf:pdf},
issn = {1664042X},
journal = {Frontiers in Physiology},
keywords = {Electrocardiogram(ECG),Fuzzy comprehensive evaluation,Heuristic fusion,Quality assessment,Signal quality indexes (SQIs)},
number = {JUN},
pages = {1--13},
title = {{SQI quality evaluation mechanism of single-lead ECG signal based on simple heuristic fusion and fuzzy comprehensive evaluation}},
volume = {9},
year = {2018}
}
@article{Hayer2015,
abstract = {MOTIVATION: Because of the advantages of RNA sequencing (RNA-Seq) over microarrays, it is gaining widespread popularity for highly parallel gene expression analysis. For example, RNA-Seq is expected to be able to provide accurate identification and quantification of full-length splice forms. A number of informatics packages have been developed for this purpose, but short reads make it a difficult problem in principle. Sequencing error and polymorphisms add further complications. It has become necessary to perform studies to determine which algorithms perform best and which if any algorithms perform adequately. However, there is a dearth of independent and unbiased benchmarking studies. Here we take an approach using both simulated and experimental benchmark data to evaluate their accuracy. RESULTS: We conclude that most methods are inaccurate even using idealized data, and that no method is highly accurate once multiple splice forms, polymorphisms, intron signal, sequencing errors, alignment errors, annotation errors, and other complicating factors are present. These results point to the pressing need for further algorithm development. AVAILABILITY: Simulated data sets and other supporting information can be found at http://bioinf.itmat.upenn.edu/BEERS/bp2 CONTACT: hayer@upenn.edu.},
author = {Hayer, Katharina E. and Pizarro, Angel and Lahens, Nicholas F. and Hogenesch, John B. and Grant, Gregory R.},
doi = {10.1093/bioinformatics/btv488},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Benchmark analysis of algorithms for determining and quantifying full-length mRNA splice forms from RNA-seq data.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
number = {24},
pages = {3938--3945},
title = {{Benchmark analysis of algorithms for determining and quantifying full-length mRNA splice forms from RNA-seq data}},
volume = {31},
year = {2015}
}
@article{Jin2017,
abstract = {{\textcopyright} 2017 The Author(s). Background: Deconvolution is a mathematical process of resolving an observed function into its constituent elements. In the field of biomedical research, deconvolution analysis is applied to obtain single cell-type or tissue specific signatures from a mixed signal and most of them follow the linearity assumption. Although recent development of next generation sequencing technology suggests RNA-seq as a fast and accurate method for obtaining transcriptomic profiles, few studies have been conducted to investigate best RNA-seq quantification methods that yield the optimum linear space for deconvolution analysis. Results: Using a benchmark RNA-seq dataset, we investigated the linearity of abundance estimated from seven most popular RNA-seq quantification methods both at the gene and isoform levels. Linearity is evaluated through parameter estimation, concordance analysis and residual analysis based on a multiple linear regression model. Results show that count data gives poor parameter estimations, large intercepts and high inter-sample variability; while TPM value from Kallisto and Salmon shows high linearity in all analyses. Conclusions: Salmon and Kallisto TPM data gives the best fit to the linear model studied. This suggests that TPM values estimated from Salmon and Kallisto are the ideal RNA-seq measurements for deconvolution studies.},
author = {Jin, Haijing and Wan, Ying Wooi and Liu, Zhandong},
doi = {10.1186/s12859-017-1526-y},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Comprehensive evaluation of RNA-seq quantification methods for linearity.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Deconvolution,Linearity,RNA-seq},
number = {Suppl 4},
pages = {6--9},
publisher = {BMC Bioinformatics},
title = {{Comprehensive evaluation of RNA-seq quantification methods for linearity}},
volume = {18},
year = {2017}
}
@article{Krizanovic2018a,
abstract = {{\textcopyright} The Author 2017. Published by Oxford University Press. All rights reserved. Motivation High-throughput sequencing has transformed the study of gene expression levels through RNA-seq, a technique that is now routinely used by various fields, such as genetic research or diagnostics. The advent of third generation sequencing technologies providing significantly longer reads opens up new possibilities. However, the high error rates common to these technologies set new bioinformatics challenges for the gapped alignment of reads to their genomic origin. In this study, we have explored how currently available RNA-seq splice-aware alignment tools cope with increased read lengths and error rates. All tested tools were initially developed for short NGS reads, but some have claimed support for long Pacific Biosciences (PacBio) or even Oxford Nanopore Technologies (ONT) MinION reads. Results The tools were tested on synthetic and real datasets from two technologies (PacBio and ONT MinION). Alignment quality and resource usage were compared across different aligners. The effect of error correction of long reads was explored, both using self-correction and correction with an external short reads dataset. A tool was developed for evaluating RNA-seq alignment results. This tool can be used to compare the alignment of simulated reads to their genomic origin, or to compare the alignment of real reads to a set of annotated transcripts. Our tests show that while some RNA-seq aligners were unable to cope with long error-prone reads, others produced overall good results. We further show that alignment accuracy can be improved using error-corrected reads.},
author = {Kri{\v{z}}anovi{\'{c}}, Kre{\v{s}}imir and Echchiki, Amina and Roux, Julien and {\v{S}}iki{\'{c}}, Mile},
doi = {10.1093/bioinformatics/btx668},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/{\~{}} RA Bioinf Stuff/Papers/Evaluation of tools for long read RNA-seq splice-aware alignment (Supplementary Notes).pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
number = {5},
pages = {748--754},
title = {{Evaluation of tools for long read RNA-seq splice-aware alignment (Supplement)}},
volume = {34},
year = {2018}
}
@article{Bunn2017,
abstract = {Wearable physical activity trackers are a popular and useful method to collect biometric information at rest and during exercise. The purpose of this systematic review was to summarize recent findings of wearable devices for biometric information related to steps, heart rate, and caloric expenditure for several devices that hold a large portion of the market share. Searches were conducted in both PubMed and SPORTdiscus. Filters included: humans, within the last 5 years, English, full-text, and adult 19+ years. Manuscripts were retained if they included an exercise component of 5-min or greater and had 20 or more participants. A total of 10 articles were retained for this review. Overall, wearable devices tend to underestimate energy expenditure compared to criterion laboratory measures, however at higher intensities of activity energy expenditure is underestimated. All wrist and forearm devices had a tendency to underestimate heart rate, and this error was generally greater at higher exercise intensities and those that included greater arm movement. Heart rate measurement was also typically better at rest and while exercising on a cycle ergometer compared to exercise on a treadmill or elliptical machine. Step count was underestimated at slower walking speeds and in free-living conditions, but improved accuracy at faster speeds. The majority of the studies reviewed in the present manuscript employed different methods to assess validity and reliability of wearable technology, making it difficult to compare devices. Standardized protocols would provide guidance for researchers to evaluate research-grade devices as well as commercial devices used by the lay public.},
annote = {Systematic Study (only 2 wearable ECG devices)
- Gillinov
- Wallen},
author = {Bunn, Jennifer A and Navalta, James W and Fountaine, Charles J and Reece, Joel D},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bunn et al. - 2017 - Current State of Commercial Wearable Technology in Physical Activity Monitoring 2015-2017.pdf:pdf},
issn = {1939-795X},
journal = {International journal of exercise science},
keywords = {energy,exercise and fitness trackers,expenditure estimation,heart rate,step count,systematic review,validity,wearable devices},
number = {7},
pages = {503--515},
pmid = {29541338},
title = {{Current State of Commercial Wearable Technology in Physical Activity Monitoring 2015-2017.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/29541338{\%}0Ahttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5841672},
volume = {11},
year = {2017}
}
@article{Jo2016,
abstract = {The purpose of this study was to examine the validity of HR measurements by two commercial-use activity trackers in comparison to ECG. Twenty-four healthy participants underwent the same 77-minute protocol during a single visit. Each participant completed an initial rest period of 15 minutes followed by 5 minute periods of each of the following activities: 60W and 120W cycling, walking, jogging, running, resisted arm raises, resisted lunges, and isometric plank. In between each exercise task was a 5-minute rest period. Each subject wore a Basis Peak (BPk) on one wrist and a Fitbit Charge HR (FB) on the opposite wrist. Criterion measurement of HR was administered by 12-lead ECG. Time synced data from each device and ECG were concurrently and electronically acquired throughout the entire 77-minute protocol. When examining data in aggregate, there was a strong correlation between BPk and ECG for HR (r = 0.92, p {\textless} 0.001) with a mean bias of -2.5 bpm (95{\%} LoA 19.3, -24.4). The FB demonstrated a moderately strong correlation with ECG for HR (r = 0.83, p {\textless} 0.001) with an average mean bias of -8.8 bpm (95{\%} LoA 24.2, -41.8). During physical efforts eliciting ECG HR {\textgreater} 116 bpm, the BPk demonstrated an r = 0.77 and mean bias = -4.9 bpm (95{\%} LoA 21.3, -31.0) while the FB demonstrated an r = 0.58 and mean bias = -12.7 bpm (95{\%} LoA 28.6, -54.0). The BPk satisfied validity criteria for HR monitors, however showed a marginal decline in accuracy with increasing physical effort (ECG HR {\textgreater} 116 bpm). The FB failed to satisfy validity criteria and demonstrated a substantial decrease in accuracy during higher exercise intensities.},
annote = {PPG},
author = {Jo, Edward and Lewis, Kiana and Directo, Dean and Kim, Michael June Young and Dolezal, Brett A.},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jo et al. - 2016 - Validation of biofeedback wearables for photoplethysmographic heart rate tracking.pdf:pdf},
issn = {13032968},
journal = {Journal of Sports Science and Medicine},
keywords = {Biosensor,Biotechnology,Cardiovascular,Fitness,Photoplethysmography},
number = {3},
pages = {540--547},
title = {{Validation of biofeedback wearables for photoplethysmographic heart rate tracking}},
volume = {15},
year = {2016}
}
@article{Gillinov2017,
abstract = {Purpose: Athletes and members of the public increasingly rely on wearable HR monitors to guide physical activity and training. The accuracy of newer, optically based monitors is unconfirmed. We sought to assess the accuracy of five optically based HR monitors during various types of aerobic exercise. Methods: Fifty healthy adult volunteers (mean T SD age = 38 T 12 yr, 54{\%} female) completed exercise protocols on a treadmill, a stationary bicycle, and an elliptical trainer (Tarm movement). Each participant underwent HR monitoring with an electrocardiogaphic chest strap monitor (Polar H7), forearm monitor (Scosche Rhythm+), and two randomly assigned wrist-worn HR monitors (Apple Watch, Fitbit Blaze, Garmin Forerunner 235, and TomTom Spark Cardio), one on each wrist. For each exercise type, HR was recorded at rest, light, moderate, and vigorous intensity. Agreement between HR measurements was assessed using Lin"s concordance correlation coefficient (r c). Results: Across all exercise conditions, the chest strap monitor (Polar H7) had the best agreement with ECG (r c = 0.996) followed by the Apple Watch (r c = 0.92), the TomTom Spark (r c = 0.83), and the Garmin Forerunner (r c = 0.81). Scosche Rhythm+ and Fitbit Blaze were less accurate (r c = 0.75 and r c = 0.67, respectively). On treadmill, all devices performed well (r c = 0.88-0.93) except the Fitbit Blaze (r c = 0.76). While bicycling, only the Garmin, Apple Watch, and Scosche Rhythm+ had acceptable agreement (r c 9 0.80). On the elliptical trainer without arm levers, only the Apple Watch was accurate (r c = 0.94). None of the devices was accurate during elliptical trainer use with arm levers (all r c G 0.80). Conclusion: The accuracy of wearable, optically based HR monitors varies with exercise type and is greatest on the treadmill and lowest on elliptical trainer. Electrode-containing chest monitors should be used when accurate HR measurement is imperative.},
author = {Gillinov, Stephen and Etiwy, Muhammad and Wang, Robert and Blackburn, Gordon and Phelan, Dermot and Gillinov, A. Marc and Houghtaling, Penny and Javadikasgari, Hoda and Desai, Milind Y.},
doi = {10.1249/MSS.0000000000001284},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gillinov et al. - 2017 - Variable accuracy of wearable heart rate monitors during aerobic exercise.pdf:pdf},
isbn = {0000000000},
issn = {15300315},
journal = {Medicine and Science in Sports and Exercise},
keywords = {Accuracy,Randomized trial,Wearable heart rate monitors},
number = {8},
pages = {1697--1703},
title = {{Variable accuracy of wearable heart rate monitors during aerobic exercise}},
volume = {49},
year = {2017}
}
@article{Darvishi2015,
author = {Darvishi, Ali and Hassanpour, Hamide},
doi = {10.5829/idosi.ije.2015.28.12c.05},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Darvishi, Hassanpour - 2015 - A Geometric View of Similarity Measures in Data Mining.pdf:pdf},
issn = {10252495},
journal = {International Journal of Engineering},
keywords = {Data Mining, Feature Extraction, Similarity Measur},
number = {12 (C)},
title = {{A Geometric View of Similarity Measures in Data Mining}},
volume = {28},
year = {2015}
}
@article{Preejith2016,
abstract = {We classify digits of real-world house numbers using convolutional neural networks (ConvNets). ConvNets are hierarchical feature learning neural networks whose structure is biologically inspired. Unlike many popular vision approaches that are hand-designed, ConvNets can automatically learn a unique set of features optimized for a given task. We augmented the traditional ConvNet architecture by learning multi-stage features and by using Lp pooling and establish a new state-of-the-art of 94.85{\%} accuracy on the SVHN dataset (45.2{\%} error improvement). Furthermore, we analyze the benefits of different pooling methods and multi-stage features in ConvNets. The source code and a tutorial are available at eblearn.sf.net.},
annote = {[GET THE SIGNAL PROCESSING]
Arrhytmia Detection
Simulated Data (no participants)},
author = {Preejith, S. P. and Dhinesh, R. and Joseph, Jayaraj and Sivaprakasam, Mohanasankar},
doi = {10.1109/EMBC.2016.7590779},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Preejith et al. - 2016 - Wearable ECG platform for continuous cardiac monitoring.pdf:pdf},
isbn = {9781457702204},
issn = {1557170X},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
pages = {623--626},
publisher = {IEEE},
title = {{Wearable ECG platform for continuous cardiac monitoring}},
volume = {2016-Octob},
year = {2016}
}
@article{Bai2018,
abstract = {{\textcopyright} 2017, The International Biometric Society. Recent advances of wearable computing technology have allowed continuous health monitoring in large observational studies and clinical trials. Examples of data collected by wearable devices include minute-by-minute physical activity proxies measured by accelerometers or heart rate. The analysis of data generated by wearable devices has so far been quite limited to crude summaries, for example, the mean activity count over the day. To better utilize the full data and account for the dynamics of activity level in the time domain, we introduce a two-stage regression model for the minute-by-minute physical activity proxy data. The model allows for both time-varying parameters and time-invariant parameters, which helps capture both the transition dynamics between active/inactive periods (Stage 1) and the activity intensity dynamics during active periods (Stage 2). The approach extends methods developed for zero-inflated Poisson data to account for the high-dimensionality and time-dependence of the high density data generated by wearable devices. Methods are motivated by and applied to the Baltimore Longitudinal Study of Aging.},
author = {Bai, Jiawei and Sun, Yifei and Schrack, Jennifer A. and Crainiceanu, Ciprian M. and Wang, Mei Cheng},
doi = {10.1111/biom.12781},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bai et al. - 2018 - A two-stage model for wearable device data.pdf:pdf},
issn = {15410420},
journal = {Biometrics},
keywords = {Accelerometer,Actigraphy,Actiheart,Physical activity,Semi-parametric,Two-stage model},
number = {2},
pages = {744--752},
title = {{A two-stage model for wearable device data}},
volume = {74},
year = {2018}
}
@article{Majumder2017,
abstract = {{\textcopyright} 2017 by the authors; licensee MDPI, Basel, Switzerland.Life expectancy in most countries has been increasing continually over the several few decades thanks to significant improvements in medicine, public health, as well as personal and environmental hygiene. However, increased life expectancy combined with falling birth rates are expected to engender a large aging demographic in the near future that would impose significant burdens on the socio-economic structure of these countries. Therefore, it is essential to develop cost-effective, easy-to-use systems for the sake of elderly healthcare and well-being. Remote health monitoring, based on non-invasive and wearable sensors, actuators and modern communication and information technologies offers an efficient and cost-effective solution that allows the elderly to continue to live in their comfortable home environment instead of expensive healthcare facilities. These systems will also allow healthcare personnel to monitor important physiological signs of their patients in real time, assess health conditions and provide feedback from distant facilities. In this paper, we have presented and compared several low-cost and non-invasive health and activity monitoring systems that were reported in recent years. A survey on textile-based sensors that can potentially be used in wearable systems is also presented. Finally, compatibility of several communication technologies as well as future perspectives and research challenges in remote monitoring systems will be discussed.},
annote = {- Other characteristics of wearable ECG can be extracted in Section 2.1 (highlighted in blue)},
author = {Majumder, Sumit and Mondal, Tapas and Deen, M. Jamal},
doi = {10.3390/s17010130},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Majumder, Mondal, Deen - 2017 - Wearable sensors for remote health monitoring.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Ambulatory monitoring,Body sensor network,Remote health monitoring,Smart textile,Vital sign monitoring,Wearable sensors},
number = {1},
title = {{Wearable sensors for remote health monitoring}},
volume = {17},
year = {2017}
}
@article{Tsukada2019,
annote = {- Interesting observation : Gender Difference (p1208)},
author = {Tsukada, Yayoi Tetsuou and Tokita, Miwa and Murata, Hiroshige and Hirasawa, Yasuhiro and Yodogawa, Kenji and ki Iwasaki, Yu and Asai, Kuniya and Shimizu, Wataru and Kasai, Nahoko and Nakashima, Hiroshi and Tsukada, Shingo},
doi = {10.1007/s00380-019-01347-8},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsukada et al. - 2019 - Validation of wearable textile electrodes for ECG monitoring.pdf:pdf},
isbn = {0038001901347},
issn = {16152573},
journal = {Heart and Vessels},
keywords = {Reusable,Textile electrode,Holter monitoring,Wearable devic,Washable,Wearable device},
number = {7},
pages = {1203--1211},
publisher = {Springer Japan},
title = {{Validation of wearable textile electrodes for ECG monitoring}},
url = {https://doi.org/10.1007/s00380-019-01347-8},
volume = {34},
year = {2019}
}
@book{Crouch2017,
abstract = {Interest in the use of electric vehicles (EVs) for road transport is increasing. Potential benefits for the UK include business opportunities and, in the longer term, carbon emissions savings and a reduced dependence on oil. This POSTnote focuses on the extent to which EVs could reduce carbon emissions and examines issues that would surround widespread uptake.},
author = {Crouch, Dell A.},
booktitle = {Handbook of Automotive Power Electronics and Motor Drives},
doi = {10.1201/9781420028157},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Crouch - 2017 - Battery technology for automotive applications.pdf:pdf},
isbn = {9781420028157},
keywords = {Health monitoring,Physiological p,Wearable devices,health monitoring,measurement accuracy,metrological characteristics,physiological parameters,wearable devices},
pages = {677--688},
publisher = {Springer International Publishing},
title = {{Battery technology for automotive applications}},
url = {http://dx.doi.org/10.1007/978-3-030-04324-7{\_}47},
year = {2017}
}
@article{Dolezal2014,
abstract = {Firefighters are subject to extreme environments and high physical demands when performing duty-related tasks. Recently, physiological status monitors (PSM) have been embedded into a compression shirt to enable firefighters to measure, visualize, log, and transmit vital metrics such as heart rate (HR) to aid in cardiovascular risk identification and mitigation, thereby attempting to improve the health, fitness, and safety of this population. The purpose of this study was to validate HR recorded by the PSM-embedded compression shirt against a criterion standard laboratory ECG-derived HR when worn concurrently with structural firefighting personal protective equipment (PPE) during four simulated firefighting activities. Ten healthy, college-age men (mean ± SD: age: 21 ± 1 yr; body mass: 91 ± 10 kg; body mass index: 26.9 ± 3.1 kg/m(2)) completed four tasks that are routinely performed during firefighting operations: outdoor fast-paced walking (FW), treadmill walking (TW), searching/crawling (SC), and ascending/descending stairs (AD). They wore the PSM-embedded compression shirt under structural firefighting PPE. HR was recorded concurrently by the PSM-embedded compression shirt and a portable metabolic measurement system accompanied with a standard 12-lead electrocardiograph that was used to provide criterion measures of HR. For all four tasks combined there was very high correlation of PSM and ECG HR (r {\textgreater} 0.99; SEE 0.84 /min) with a mean difference (bias) of -0.02 /min and limits of agreement of -0.07 to 0.02 /min. For individual tasks, the correlations were also high (r-values = 0.99; SEE 0.81-0.89). The mean bias (limits of agreement) was: FW 0.03 (-0.09 to 0.14); TW 0.04 (-0.05 to 0.12); SC -0.01 (-0.12 to 0.10); AD -0.13 (-0.21 to -0.04) /min. These findings demonstrate that the PSM-embedded compression shirt provides a valid measure of HR during simulated firefighting activities when compared with a standard 12-lead ECG.},
annote = {[X] Specific to Firefighting (Sample too small)},
author = {Dolezal, Brett A. and Boland, D. M. and Carney, J. and Abrazado, M. and Smith, D. L. and Cooper, C. B.},
doi = {10.1080/15459624.2014.925114},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dolezal et al. - 2014 - Validation of heart rate derived from a physiological status monitor-embedded compression shirt against criterio.pdf:pdf},
issn = {15459632},
journal = {Journal of Occupational and Environmental Hygiene},
keywords = {Heart rate,PSM,Remote monitoring},
number = {12},
pages = {833--839},
title = {{Validation of heart rate derived from a physiological status monitor-embedded compression shirt against criterion ECG}},
volume = {11},
year = {2014}
}
@article{Wallen2016,
abstract = {? 2016 Wallen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Background: Wrist-worn monitors claim to provide accurate measures of heart rate and energy expenditure. People wishing to lose weight use these devices to monitor energy balance, however the accuracy of these devices to measure such parameters has not been established. Aim: To determine the accuracy of four wrist-worn devices (Apple Watch, Fitbit Charge HR, Samsung Gear S and Mio Alpha) to measure heart rate and energy expenditure at rest and during exercise. Methods: Twenty-two healthy volunteers (50{\%} female; aged 24 ? 5.6 years) completed ?1-hr protocols involving supine and seated rest, walking and running on a treadmill and cycling on an ergometer. Data from the devices collected during the protocol were compared with reference methods: electrocardiography (heart rate) and indirect calorimetry (energy expenditure). Results: None of the devices performed significantly better overall, however heart rate was consistently more accurate than energy expenditure across all four devices. Correlations between the devices and reference methods were moderate to strong for heart rate (0.67-0.95 [0.35 to 0.98]) and weak to strong for energy expenditure (0.16-0.86 [-0.25 to 0.95]). All devices underestimated both outcomes compared to reference methods. The percentage error for heart rate was small across the devices (range: 1-9{\%}) but greater for energy expenditure (9-43{\%}). Similarly, limits of agreement were considerably narrower for heart rate (ranging from -27.3 to 13.1 bpm) than energy expenditure (ranging from -266.7 to 65.7 kcals) across devices. Conclusion: These devices accurately measure heart rate. However, estimates of energy expenditure are poor and would have implications for people using these devices for weight loss.},
annote = {Read / Copied to Notion
[X] - Methods and Participants},
author = {Wallen, Matthew P. and Gomersall, Sjaan R. and Keating, Shelley E. and Wisl{\o}ff, Ulrik and Coombes, Jeff S.},
doi = {10.1371/journal.pone.0154420},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wallen et al. - 2016 - Accuracy of heart rate watches Implications for weight management.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {5},
pages = {1--9},
title = {{Accuracy of heart rate watches: Implications for weight management}},
volume = {11},
year = {2016}
}
@article{Torfs2014,
abstract = {Background Detection of intermittent atrial fibrillation (AF) is done using a 24-h Holter. Holter recordings are powerful but lack the comfort and have limited recording times resulting in under diagnosing of intermittent AF.
Objective Within this work we evaluated and compared a novel miniaturized three-channel ECG monitoring patch versus a 24-h Holter system. Methods Both patients with a chronic AF rhythm (n = 5) as well as patients with an AF rhythm that underwent electrical reconversion (n = 5) were equipped with both a 24-h Holter and ECG patch.
Results Alignment of raw data of both ECG systems allowed cross-correlation analysis. Overall good correlations of up to 85{\%} were obtained. RR-interval analysis of both systems resulted in very high correlations of 99{\%} and higher. AF analysis showed correct identification of AF on both ECG systems.
Conclusions The performance of our ECG patch matches that of the 24-h Holter and could provide a suitable tool for long-term monitoring applications.},
annote = {AF Detection},
author = {Torfs, Tom and Smeets, Christophe J.P. and Geng, Di and Berset, Torfinn and {Van Der Auwera}, Jo and Vandervoort, Pieter and Grieten, Lars},
doi = {10.1016/j.jelectrocard.2014.08.012},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Torfs et al. - 2014 - Clinical validation of a low-power and wearable ECG patch for long term full-disclosure monitoring.pdf:pdf},
issn = {15328430},
journal = {Journal of Electrocardiology},
keywords = {ECG Holter,ECG patch,Full disclosure,Low power},
number = {6},
pages = {881--889},
publisher = {Elsevier Inc.},
title = {{Clinical validation of a low-power and wearable ECG patch for long term full-disclosure monitoring}},
url = {http://dx.doi.org/10.1016/j.jelectrocard.2014.08.012},
volume = {47},
year = {2014}
}
@article{Li2019,
abstract = {BACKGROUND Mobile phone apps capable of monitoring arrhythmias and heart rate (HR) are increasingly used for screening, diagnosis, and monitoring of HR and rhythm disorders such as atrial fibrillation (AF). These apps involve either the use of (1) photoplethysmographic recording or (2) a handheld external electrocardiographic recording device attached to the mobile phone or wristband. OBJECTIVE This review seeks to explore the current state of mobile phone apps in cardiac rhythmology while highlighting shortcomings for further research. METHODS We conducted a narrative review of the use of mobile phone devices by searching PubMed and EMBASE from their inception to October 2018. Potentially relevant papers were then compared against a checklist for relevance and reviewed independently for inclusion, with focus on 4 allocated topics of (1) mobile phone monitoring, (2) AF, (3) HR, and (4) HR variability (HRV). RESULTS The findings of this narrative review suggest that there is a role for mobile phone apps in the diagnosis, monitoring, and screening for arrhythmias and HR. Photoplethysmography and handheld electrocardiograph recorders are the 2 main techniques adopted in monitoring HR, HRV, and AF. CONCLUSIONS A number of studies have demonstrated high accuracy of a number of different mobile devices for the detection of AF. However, further studies are warranted to validate their use for large scale AF screening.},
annote = {AF Detection},
author = {Li, Ka Hou Christien and White, Francesca Anne and Tipoe, Timothy and Liu, Tong and Wong, Martin C.S. and Jesuthasan, Aaron and Baranchuk, Adrian and Tse, Gary and Yan, Bryan P.},
doi = {10.2196/11606},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2019 - The current state of mobile phone apps for monitoring heart rate, heart rate variability, and atrial fibrillation Nar.pdf:pdf},
issn = {14388871},
journal = {Journal of Medical Internet Research},
keywords = {Arrhythmia,Atrial fibrillation,Electrocardiography,Heart rate,Mobile health,Mobile phone apps,Photoplethysmography},
number = {2},
title = {{The current state of mobile phone apps for monitoring heart rate, heart rate variability, and atrial fibrillation: Narrative review}},
volume = {21},
year = {2019}
}
@article{Billeci2018,
abstract = {{\textcopyright} 2017 IEEE Computer Society. All rights reserved. Aims: Atrial fibrillation (AF) is one of the principal cause of mortality in elderly, thus its detection is extremely clinically relevant. The aim of this study was to classify short, single lead, ECG recordings, as atrial fibrillation, normal sinus rhythm, other type of rhythms or noisy signal. Methods: First, we extracted, both from the ECG signals and from the RR interval series, about fifty features characterizing these four classes. Then, we applied the stepwise linear discriminant analysis for dimensionality reduction selecting a subset of thirty discriminating features. A Least Squares Support Vector Machine (LS-SVM) classifier using these features was tuned and trained on the dataset of the Physionet/Computing in Cardiology Challenge 2017. Results: The LS-SVM classifier provided, on the hidden test set of the Challenge, an official final score F1= 0.81, obtaining the twelfth place in the ranking of results with only 2 cents from the best (0.83). Conclusions: This approach seems promising in particular in detecting atrial fibrillation. Further work is needed to improve the discrimination of other rhythms and noisy signals.},
author = {Billeci, Lucia and Chiarugi, Franco and Costi, Magda and Lombardi, David and Varanini, Maurizio},
doi = {10.22489/cinc.2017.344-144},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Billeci et al. - 2018 - Detection of AF and Other Rhythms Using RR Variability and ECG Spectrum Measures.pdf:pdf},
journal = {2017 Computing in Cardiology Conference (CinC)},
pages = {1--4},
title = {{Detection of AF and Other Rhythms Using RR Variability and ECG Spectrum Measures}},
volume = {44},
year = {2018}
}
@article{Bouillod2015,
abstract = {The aim of this study was to assess the accuracy of the Suunto Memory Belt (SMB) heart rate (HR) recorder compared with that of a standard electrocardiogram system (ECG) and compared the heart rate variability (HRV) analyses conducted with each dataset. Heart rate was simultaneously recorded using ECG and SMB in fifteen participants [mean (SD) age 27.3 (13.9) years, height 177.4 (10.2) cm and body mass 66.8 (15.3) kg] during an orthostatic tilt test. The two datasets were analysed to compare the number and type of R-R interval artefacts and indices from HRV (RMSSD, pNN50, HF, LF, SD1, and SD2). For artefact detection, 16,742 R-R intervals were analysed during all recordings. Only 18 artefacts, 9 type 1 (long R-R interval) and 9 type 2 (short R-R interval), were identified with the SMB. Bland-Altman analysis indicated excellent accuracy for the SMB, with limits of agreement of -2.00 and +1.94 ms. Further, the reference and SMB systems were strongly correlated. The similarity between each device indicated that the SMB could reliably record R-R intervals. ABSTRACT FROM AUTHOR},
annote = {Interpreting Effect Size of paired RRI difference

As proposed by Cohen (1998), the difference was considered small when ES ≤ 0.2, moderate when ES ≤ 0.5 and large when ES {\textgreater} 0.8.},
author = {Bouillod, Anthony and Cassirame, Johan and Bousson, Jean Marc and Jr, Yoshimasa Sagawa and Tordi, Nicolas},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouillod et al. - 2015 - Accuracy of the Suunto system for heart rate variability analysis during a tilt-test.pdf:pdf},
issn = {14158426},
journal = {Brazilian Journal of Kineanthropometry {\&} Human Performance},
keywords = {*ELECTROCARDIOGRAPHY,*HEART beat,Estudos de valida{\c{c}}{\~{a}}o,Fisiologia,Frequ{\^{e}}ncia card{\'{i}}aca,Heart rate,MEDICAL artifacts,MEDICAL equipment reliability,Physiology,TILT-table test,Validation studies},
number = {4},
pages = {409--417},
title = {{Accuracy of the Suunto system for heart rate variability analysis during a tilt-test}},
url = {http://ezproxy.library.ubc.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=sph{\&}AN=108490458{\&}site=ehost-live{\&}scope=site},
volume = {17},
year = {2015}
}
@article{Vandenberk,
annote = {PPG},
author = {Vandenberk, Thijs and Stans, Jelle and Schelvergem, Gertjan Van and Pelckmans, Caroline},
doi = {10.2196/mhealth.7254},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberk et al. - Unknown - Clinical Validation of Heart Rate Apps Mixed-Methods Evaluation Study Corresponding Author.pdf:pdf},
pages = {1--15},
title = {{Clinical Validation of Heart Rate Apps : Mixed-Methods Evaluation Study Corresponding Author :}},
volume = {5}
}
@article{Vuorinen2019,
annote = {Read / Copied to Notion
[ ] - Abstract
[ ] - Conclusion
[ ] - Introduction
[X] - Sampling Units
[X] - Sampling Activities
[X] - Metrics
[X] - Data Removal
[X] - Signal Processing
[X] - Data Ethics},
author = {Vuorinen, Tiina and Noponen, Kai and Vehkaoja, Antti and Onnia, Timo and Laakso, Eeva and Lepp{\"{a}}nen, Susanna and Mansikkam{\"{a}}ki, Kirsi and Sepp{\"{a}}nen, Tapio and M{\"{a}}ntysalo, Matti},
doi = {10.1002/admt.201900246},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vuorinen et al. - 2019 - Validation of Printed, Skin-Mounted Multilead Electrode for ECG Measurements.pdf:pdf},
issn = {2365709X},
journal = {Advanced Materials Technologies},
keywords = {electrocardiography,epidermal electronics,screen printing,stretchable electronics},
pages = {1--8},
title = {{Validation of Printed, Skin-Mounted Multilead Electrode for ECG Measurements}},
volume = {1900246},
year = {2019}
}
@article{Faust2018,
abstract = {Atrial Fibrillation (AF), either permanent or intermittent (paroxysnal AF), increases the risk of cardioembolic stroke. Accurate diagnosis of AF is obligatory for initiation of effective treatment to prevent stroke. Long term cardiac monitoring improves the likelihood of diagnosing paroxysmal AF. We used a deep learning system to detect AF beats in Heart Rate (HR) signals. The data was partitioned with a sliding window of 100 beats. The resulting signal blocks were directly fed into a deep Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM). The system was validated and tested with data from the MIT-BIH Atrial Fibrillation Database. It achieved 98.51{\%} accuracy with 10-fold cross-validation (20 subjects) and 99.77{\%} with blindfold validation (3 subjects). The proposed system structure is straight forward, because there is no need for information reduction through feature extraction. All the complexity resides in the deep learning system, which gets the entire information from a signal block. This setup leads to the robust performance for unknown data, as measured with the blind fold validation. The proposed Computer-Aided Diagnosis (CAD) system can be used for long-term monitoring of the human heart. To the best of our knowledge, the proposed system is the first to incorporate deep learning for AF beat detection.},
author = {Faust, Oliver and Shenfield, Alex and Kareem, Murtadha and San, Tan Ru and Fujita, Hamido and Acharya, U. Rajendra},
doi = {10.1016/j.compbiomed.2018.07.001},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Faust et al. - 2018 - Automated detection of atrial fibrillation using long short-term memory network with RR interval signals.pdf:pdf},
issn = {18790534},
journal = {Computers in Biology and Medicine},
keywords = {Atrial fibrillation,Deep learning,Heart rate,Recurrent neural network},
number = {May},
pages = {327--335},
title = {{Automated detection of atrial fibrillation using long short-term memory network with RR interval signals}},
volume = {102},
year = {2018}
}
@article{Tsitoglou2018,
abstract = { Background: Heart rate variability (HRV) is an autonomic nervous system marker that provides reliable information for both disease prevention and diagnosis; it is also used in sport settings. We examined the validity of the Polar RS800CX heart rate monitor during rest, moderate cycling, and recovery in considering the total of 24 HRV indices.  Method: A total of 32 healthy males (age=24.78±6.87 years, body mass index=24.48±3.13 kg/m 2 ) completed a session comprised by three 20-minute time periods of resting, cycling at 60{\%} of maximal heart rate, and recovery using a Polar RS800CX and an electrocardiogram (ECG) monitors. The HRV indices included time-domain, frequency-domain, Poincar{\'{e}} plot and recurrence plot. Bland–Altman plot analysis was used to estimate agreement between Polar RS800CX and ECG.  Results: We detected significant associations (r{\textgreater}0.75, p{\textless}0.05) in all HRV indices, while five out of 24 HRV indices displayed significant mean differences (p{\textless}0.05) between Polar RS800CX and ECG during the resting period. However, for the exercise and recovery periods, we found significant mean differences (p{\textless}0.05) in 16/24 and 22/24 HRV indices between the two monitors, respectively.  Conclusion: It is concluded that Polar RS800CX is a valid tool for monitoring HRV in individuals at resting conditions, but it displays inconsistency when used during exercise at 60{\%} of maximal heart rate and recovery periods. },
author = {Tsitoglou, Kyriakos I. and Koutedakis, Yiannis and Dinas, Petros C.},
doi = {10.12688/f1000research.16130.1},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsitoglou, Koutedakis, Dinas - 2018 - Validation of the Polar RS800CX for assessing heart rate variability during rest, moderate cycling.pdf:pdf},
journal = {F1000Research},
keywords = {ecg,electrocardiogram,heart rate,hr,hrv,polar rs800cx},
pages = {1501},
title = {{Validation of the Polar RS800CX for assessing heart rate variability during rest, moderate cycling and post-exercise recovery}},
volume = {7},
year = {2018}
}
@article{Akintola2016,
author = {Akintola, Abimbola A and Pol, Vera Van De and Bimmel, Daniel and Maan, Arie C},
doi = {10.3389/fphys.2016.00391},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Akintola et al. - 2016 - Comparative Analysis of the Equivital EQ02 Lifemonitor with Holter Ambulatory ECG Device for Continuous Measure.pdf:pdf},
journal = {Frontiers in Physiology},
keywords = {ECG,Equivital-EQ02,Holter electrocardiogram,rem},
number = {September},
pages = {1--14},
title = {{Comparative Analysis of the Equivital EQ02 Lifemonitor with Holter Ambulatory ECG Device for Continuous Measurement of ECG , Heart Rate , and Heart Rate Variability : A Validation Study for Precision and Accuracy}},
volume = {7},
year = {2016}
}
@article{Delgado-Gonzalo2015,
abstract = {{\textcopyright} 2015 IEEE.PulseOn is a wrist-worn optical heart rate (HR) monitor based on photoplethysmography. It utilizes multi-wavelength technology and optimized sensor geometry to monitor blood flow at different depths of skin tissue, and it dynamically adapts to an optimal measurement depth in different conditions. Movement artefacts are reduced by adaptive movement-cancellation algorithms and optimized mechanics, which stabilize the sensor-to-skin contact. In this paper, we evaluated the accuracy and reliability of PulseOn technology against ECG-derived HR in laboratory conditions during a wide range of physical activities and also during outdoor sports. In addition, we compared the performance to another on-the-shelf wrist-worn consumer product Mio LINK{\textregistered}. The results showed PulseOn reliability ({\%} of time with error {\textless}10bpm) of 94.5{\%} with accuracy (100{\%} - mean absolute percentage error) 96.6{\%} as compared to ECG (vs 86.6{\%} and 94.4{\%} for Mio LINK{\textregistered}, correspondingly) during laboratory protocol. Similar or better reliability and accuracy was seen during normal outdoor sports activities. The results show that PulseOn provides reliability and accuracy similar to traditional chest strap ECG HR monitors during cardiovascular exercise.},
annote = {PPG},
author = {Delgado-Gonzalo, Ricard and Parak, Jakub and Tarniceriu, Adrian and Renevey, Philippe and Bertschi, Mattia and Korhonen, Ilkka},
doi = {10.1109/EMBC.2015.7318391},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Delgado-Gonzalo et al. - 2015 - Evaluation of accuracy and reliability of PulseOn optical heart rate monitoring device.pdf:pdf},
isbn = {9781424492718},
issn = {1557170X},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
keywords = {Wearable systems,Integrated sensor systems,Portabl},
pages = {430--433},
title = {{Evaluation of accuracy and reliability of PulseOn optical heart rate monitoring device}},
volume = {2015-Novem},
year = {2015}
}
@article{Georgiou2018a,
abstract = {Background: A growing number of wearable devices claim to provide accurate, cheap and easily applicable heart rate variability (HRV) indices. This is mainly accomplished by using wearable photoplethysmography (PPG) and/or electrocar-diography (ECG), through simple and non-invasive techniques, as a substitute of the gold standard RR interval estimation through electrocardiogram. Although the agreement between pulse rate variability (PRV) and HRV has been evaluated in the literature, the reported results are still inconclusive especially when using wearable devices. Aim: The purpose of this systematic review is to investigate if wearable devices provide a reliable and precise measurement of classic HRV parameters in rest as well as during exercise. Materials and methods: A search strategy was implemented to retrieve relevant articles from MEDLINE and SCOPUS databases, as well as, through internet search. The 308 articles retrieved were reviewed for further evaluation according to the predetermined inclusion/exclusion criteria. Results: Eighteen studies were included. Sixteen of them integrated ECG-HRV technology and two of them PPG-PRV technology. All of them examined wear-able devices accuracy in RV detection during rest, while only eight of them during exercise. The correlation between classic ECG derived HRV and the wearable RV ranged from very good to excellent during rest, yet it declined progressively as exercise level increased. Conclusions: Wearable devices may provide a promising alternative solution for measuring RV. However, more robust studies in non-stationary conditions are needed using appropriate methodology in terms of number of subjects involved, acquisition and analysis techniques implied. BACKGROUND},
annote = {[X] - Relevant Papers have already been extracted},
author = {Georgiou, Konstantinos and Larentzakis, Andreas V. and Khamis, Nehal N. and Alsuhaibani, Ghadah I. and Alaska, Yasser A. and Giallafos, Elias J.},
doi = {10.2478/folmed-2018-0012},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Georgiou et al. - 2018 - Can Wearable Devices Accurately Measure Heart Rate Variability A Systematic Review.pdf:pdf},
issn = {02048043},
journal = {Folia medica},
keywords = {heart rate,heart rate variability,photoplethysmography,wearable},
number = {1},
pages = {7--20},
title = {{Can Wearable Devices Accurately Measure Heart Rate Variability? A Systematic Review}},
volume = {60},
year = {2018}
}
@article{Xia2018,
abstract = {Background Atrial fibrillation (AF) is the most common cardiac arrhythmia. The incidence of AF increases with age, causing high risks of stroke and increased morbidity and mortality. Efficient and accurate diagnosis of AF based on the ECG is valuable in clinical settings and remains challenging. In this paper, we proposed a novel method with high reliability and accuracy for AF detection via deep learning. Method The short-term Fourier transform (STFT) and stationary wavelet transform (SWT) were used to analyze ECG segments to obtain two-dimensional (2-D) matrix input suitable for deep convolutional neural networks. Then, two different deep convolutional neural network models corresponding to STFT output and SWT output were developed. Our new method did not require detection of P or R peaks, nor feature designs for classification, in contrast to existing algorithms. Finally, the performances of the two models were evaluated and compared with those of existing algorithms. Results Our proposed method demonstrated favorable performances on ECG segments as short as 5 s. The deep convolutional neural network using input generated by STFT, presented a sensitivity of 98.34{\%}, specificity of 98.24{\%} and accuracy of 98.29{\%}. For the deep convolutional neural network using input generated by SWT, a sensitivity of 98.79{\%}, specificity of 97.87{\%} and accuracy of 98.63{\%} was achieved. Conclusion The proposed method using deep convolutional neural networks shows high sensitivity, specificity and accuracy, and, therefore, is a valuable tool for AF detection.},
author = {Xia, Yong and Wulan, Naren and Wang, Kuanquan and Zhang, Henggui},
doi = {10.1016/j.compbiomed.2017.12.007},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xia et al. - 2018 - Detecting atrial fibrillation by deep convolutional neural networks.pdf:pdf},
issn = {18790534},
journal = {Computers in Biology and Medicine},
keywords = {Atrial fibrillation,Deep convolutional neural networks,Short-term Fourier transform,Stationary wavelet transform},
number = {July 2017},
pages = {84--92},
publisher = {Elsevier Ltd},
title = {{Detecting atrial fibrillation by deep convolutional neural networks}},
url = {https://doi.org/10.1016/j.compbiomed.2017.12.007},
volume = {93},
year = {2018}
}
@article{Andersen2019,
abstract = {Goal: To develop a robust and real-time approach for automatic detection of atrial fibrillation (AF) in long-term electrocardiogram (ECG) recordings using deep learning (DL). Method: An end-to-end model combining the Convolutional- and Recurrent-Neural Networks (CNN and RNN) was proposed to extract high level features from segments of RR intervals (RRIs) in order to classify them as AF or normal sinus rhythm (NSR). Results: The model was trained and validated on three different databases including a total of 89 subjects. It achieved a sensitivity and specificity of 98.98{\%} and 96.95{\%}, respectively, validated through a 5-fold cross-validation. Additionally, the proposed model was found to be computationally efficient and it was capable of analyzing 24 h of ECG recordings in less than one second. The proposed algorithm was also tested on the unseen datasets to examine its robustness in detecting AF for new recordings which resulted in 98.96{\%} and 86.04{\%} for specificity and sensitivity, respectively. Conclusion: Compared to the state-of-the-art models evaluated on standard benchmark ECG datasets, the proposed model produced better performance in detecting AF. Additionally, since the model learns features directly from the data, it avoids the need for clever/cumbersome feature engineering.},
author = {Andersen, Rasmus S. and Peimankar, Abdolrahman and Puthusserypady, Sadasivan},
doi = {10.1016/j.eswa.2018.08.011},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Andersen, Peimankar, Puthusserypady - 2019 - A deep learning approach for real-time detection of atrial fibrillation.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Atrial fibrillation,Convolutional neural networks (CNNs),Deep learning,Electrocardiogram (ECG),Long short-term memory (LSTM),Recurrent neural networks (RNNs)},
pages = {465--473},
publisher = {Elsevier Ltd},
title = {{A deep learning approach for real-time detection of atrial fibrillation}},
url = {https://doi.org/10.1016/j.eswa.2018.08.011},
volume = {115},
year = {2019}
}
@article{Villar2015,
abstract = {We tested the validity of the Hexoskin wearable vest to monitor heart rate (HR), breathing rate (BR), tidal volume ( VT), minute ventilation, and hip motion intensity (HMI) in comparison with laboratory standard devices during lying, sitting, standing, and walking. Twenty healthy young volunteers participated in this study. First, participants walked 6 min on a treadmill at speeds of 1, 3, and 4.5 km/h followed by increasing treadmill grades until 80{\%} of their predicted maximal heart rate. Second, lying, sitting, and standing tasks were performed (5 min each) followed by 6 min of treadmill walking at 80{\%} of their ventilatory threshold. Analysis of each individual's mean values under each resting or exercise condition by the 2 measurement systems revealed low coefficient of variation and high intraclass correlation values for HR, BR, and HMI. The Bland-Altman results from HR, BR, and HMI indicated no deviation of the mean value from zero and relatively small variability about the mean. VT and minute ventilation were provided in arbitrary units by the Hexoskin device; however, relative magnitude of change from Hexoskin closely tracked the laboratory standard method. Hexoskin presented low variability, good agreement, and consistency. The Hexoskin wearable vest was a valid and consistent tool to monitor activities typical of daily living such as different body positions (lying, sitting, and standing) and various walking speeds. ABSTRACT FROM AUTHOR},
annote = {[X] - Participants},
author = {Villar, Rodrigo and Beltrame, Thomas and Hughson, Richard L.},
doi = {10.1139/apnm-2015-0140},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Villar, Beltrame, Hughson - 2015 - Validation of the Hexoskin wearable vest during lying, sitting, standing, and walking activities.pdf:pdf},
issn = {1715-5312},
journal = {Applied Physiology, Nutrition, and Metabolism},
keywords = {altman plots,bland,br,breathing rate,coefficient of variation,de l,de la fr{\'{e}}quence,du d{\'{e}}bit ventilatoire et,du gilet portable hexoskin,du volume courant,heart rate,hip-motion intensity,hmi,hr,intensit{\'{e}} de mouvement de,intraclass correlation,la fr{\'{e}}quence cardiaque,la hanche,on v{\'{e}}rifie la validit{\'{e}},pour le monitorage de,respiratoire,r{\'{e}}sum{\'{e}},v t,ventilation,wearable device},
number = {10},
pages = {1019--1024},
title = {{Validation of the Hexoskin wearable vest during lying, sitting, standing, and walking activities}},
volume = {40},
year = {2015}
}
@article{Zhou2015,
abstract = {{\textcopyright} 2015 Zhou et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Atrial fibrillation (AF), the most frequent cause of cardioembolic stroke, is increasing in prevalence as the population ages, and presents with a broad spectrum of symptoms and severity. The early identification of AF is an essential part for preventing the possibility of blood clotting and stroke. In this work, a real-time algorithm is proposed for accurately screening AF episodes in electrocardiograms. This method adopts heart rate sequence, and it involves the application of symbolic dynamics and Shannon entropy. Using novel recursive algorithms, a low-computational complexity can be obtained. Four publicly-accessible sets of clinical data (Long-Term AF, MIT-BIH AF, MIT-BIH Arrhythmia, and MIT-BIH Normal Sinus Rhythm Databases) were used for assessment. The first database was selected as a training set; the receiver operating characteristic (ROC) curve was performed, and the best performance was achieved at the threshold of 0.639: the sensitivity (Se), specificity (Sp), positive predictive value (PPV) and overall accuracy (ACC) were 96.14{\%}, 95.73{\%}, 97.03{\%} and 95.97{\%}, respectively. The other three databases were used for independent testing. Using the obtained decision-making threshold (i.e., 0.639), for the second set, the obtained parameters were 97.37{\%}, 98.44{\%}, 97.89{\%} and 97.99{\%}, respectively; for the third database, these parameters were 97.83{\%}, 87.41{\%}, 47.67{\%} and 88.51{\%}, respectively; the Sp was 99.68{\%} for the fourth set. The latest methods were also employed for comparison. Collectively, results presented in this study indicate that the combination of symbolic dynamics and Shannon entropy yields a potent AF detector, and suggest this method could be of practical use in both clinical and out-of-clinical settings.},
author = {Zhou, Xiaolin and Ding, Hongxia and Wu, Wanqing and Zhang, Yuanting},
doi = {10.1371/journal.pone.0136544},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2015 - A real-time Atrial fibrillation detection algorithm based on the instantaneous state of heart rate.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {9},
pages = {1--16},
title = {{A real-time Atrial fibrillation detection algorithm based on the instantaneous state of heart rate}},
volume = {10},
year = {2015}
}
@article{Taggar2016,
abstract = {BACKGROUND Pulse palpation has been recommended as the first step of screening to detect atrial fibrillation. We aimed to determine and compare the accuracy of different methods for detecting pulse irregularities caused by atrial fibrillation. METHODS We systematically searched MEDLINE, EMBASE, CINAHL and LILACS until 16 March 2015. Two reviewers identified eligible studies, extracted data and appraised quality using the QUADAS-2 instrument. Meta-analysis, using the bivariate hierarchical random effects method, determined average operating points for sensitivities, specificities, positive and negative likelihood ratios (PLR, NLR); we constructed summary receiver operating characteristic plots. RESULTS Twenty-one studies investigated 39 interventions (n = 15,129 pulse assessments) for detecting atrial fibrillation. Compared to 12-lead electrocardiography (ECG) diagnosed atrial fibrillation, blood pressure monitors (BPMs; seven interventions) and non-12-lead ECGs (20 interventions) had the greatest accuracy for detecting pulse irregularities attributable to atrial fibrillation (BPM: sensitivity 0.98 (95{\%} confidence interval (CI) 0.92-1.00), specificity 0.92 (95{\%} CI 0.88-0.95), PLR 12.1 (95{\%} CI 8.2-17.8) and NLR 0.02 (95{\%} CI 0.00-0.09); non-12-lead ECG: sensitivity 0.91 (95{\%} CI 0.86-0.94), specificity 0.95 (95{\%} CI 0.92-0.97), PLR 20.1 (95{\%} CI 12-33.7), NLR 0.09 (95{\%} CI 0.06-0.14)). There were similar findings for smartphone applications (six interventions) although these studies were small in size. The sensitivity and specificity of pulse palpation (six interventions) were 0.92 (95{\%} CI 0.85-0.96) and 0.82 (95{\%} CI 0.76-0.88), respectively (PLR 5.2 (95{\%} CI 3.8-7.2), NLR 0.1 (95{\%} CI 0.05-0.18)). CONCLUSIONS BPMs and non-12-lead ECG were most accurate for detecting pulse irregularities caused by atrial fibrillation; other technologies may therefore be pragmatic alternatives to pulse palpation for the first step of atrial fibrillation screening.},
author = {Taggar, Jaspal S. and Coleman, Tim and Lewis, Sarah and Heneghan, Carl and Jones, Matthew},
doi = {10.1177/2047487315611347},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Taggar et al. - 2016 - Accuracy of methods for detecting an irregular pulse and suspected atrial fibrillation A systematic review and me.pdf:pdf},
isbn = {2047487315},
issn = {20474881},
journal = {European Journal of Preventive Cardiology},
keywords = {Atrial fibrillation,diagnostic accuracy,irregular pulse,screening},
number = {12},
pages = {1330--1338},
title = {{Accuracy of methods for detecting an irregular pulse and suspected atrial fibrillation: A systematic review and meta-analysis}},
volume = {23},
year = {2016}
}
@article{Lian2011,
abstract = {Implantable loop recorders have been developed for long-term monitoring of cardiac arrhythmia, but their accuracy for atrial fibrillation (AF) detection is unsatisfactory. We sought to develop and evaluate a simple method for detecting AF using RR intervals. The new AF detection algorithm is based on a map that plots RR intervals versus change of RR intervals (RdR). The map is divided by a grid with 25-ms resolution in 2 axes and nonempty cells are counted to classify AF and non-AF episodes. We evaluated the performance of the method using 4 PhysioNet databases: MIT-BIH AF database, MIT-BIH arrhythmia database, MIT-BIH normal sinus rhythm (NSR) database, and NSR RR interval database (total 145 patients, 1,826 hours NSR, 96 hours AF, and 11 hours other rhythms). Each record is divided into consecutive windows containing 32, 64, or 128 RR intervals. AF detection is performed for each window and classification results are compared to annotations. A window is labeled true AF if {\textgreater}1/2 of cycles in the window are annotated as AF or non-AF otherwise. The RdR map shows signature patterns corresponding to various heart rhythms. Optimal nonempty cell cut-off threshold for AF detection was determined by receiver operating characteristic curve analysis, which yields excellent sensitivity and specificity for window sizes 32 (94.4{\%} and 92.6{\%}, respectively), 64 (95.8{\%} and 94.3{\%}), and 128 (95.9{\%} and 95.4{\%}). In conclusion, a single metric derived from the RdR map can achieve robust AF detection within as few as 32 heart beats. {\textcopyright} 2011 Elsevier Inc. All rights reserved.},
author = {Lian, Jie and Wang, Lian and Muessig, Dirk},
doi = {10.1016/j.amjcard.2011.01.028},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lian, Wang, Muessig - 2011 - A simple method to detect atrial fibrillation using RR intervals.pdf:pdf},
issn = {00029149},
journal = {American Journal of Cardiology},
number = {10},
pages = {1494--1497},
publisher = {Elsevier Inc.},
title = {{A simple method to detect atrial fibrillation using RR intervals}},
url = {http://dx.doi.org/10.1016/j.amjcard.2011.01.028},
volume = {107},
year = {2011}
}
@article{Thijs2017,
abstract = {Atrial fibrillation is detected in an electrical signal representative of a beating heart by measuring atrial activity over a time window of three or more beats, measuring beat interval variation over the time window and combining the measures of atrial activity and beat interval variation to produce an indication of an atrial fibrillation condition in the electrical signal.},
author = {Thijs, Vincent},
doi = {10.1161/strokeaha.117.017083},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Thijs - 2017 - Atrial Fibrillation Detection.pdf:pdf},
issn = {0039-2499},
journal = {Stroke},
number = {10},
pages = {2671--2677},
title = {{Atrial Fibrillation Detection}},
volume = {48},
year = {2017}
}
@article{Chong2015,
abstract = {We hypothesize that our smartphone-based arrhythmia discrimination algorithm with data acquisition approach reliably differentiates between normal sinus rhythm (NSR), atrial fibrillation (AF), premature ventricular contractions (PVCs) and premature atrial contraction (PACs) in a diverse group of patients having these common arrhythmias. We combine root mean square of successive RR differences and Shannon entropy with Poincare plot (or turning point ratio method) and pulse rise and fall times to increase the sensitivity of AF discrimination and add new capabilities of PVC and PAC identification. To investigate the capability of the smartphone-based algorithm for arrhythmia discrimination, 99 subjects, including 88 study participants with AF at baseline and in NSR after electrical cardioversion, as well as seven participants with PACs and four with PVCs were recruited. Using a smartphone, we collected 2-min pulsatile time series from each recruited subject. This clinical application results show that the proposed method detects NSR with specificity of 0.9886, and discriminates PVCs and PACs from AF with sensitivities of 0.9684 and 0.9783, respectively.},
author = {Chong, Jo Woon and Esa, Nada and McManus, David D. and Chon, Ki H.},
doi = {10.1109/JBHI.2015.2418195},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chong et al. - 2015 - Arrhythmia discrimination Using a smart phone.pdf:pdf},
issn = {21682194},
journal = {IEEE Journal of Biomedical and Health Informatics},
keywords = {Arrhythmia,Atrial fibrillation,Poincare plot,Premature atrial contraction,Premature ventricular contraction,Root mean square of successive RR differences (RMS,Shannon entropy,Turning point ratio},
number = {3},
pages = {815--824},
publisher = {IEEE},
title = {{Arrhythmia discrimination Using a smart phone}},
volume = {19},
year = {2015}
}
@article{Akhbari2016,
abstract = {In this paper, we propose a novel method for extracting fiducial points (FPs) of electrocardiogram (ECG) signals. We propose the use of multi hidden Markov model (MultiHMM) as opposed to the traditional use of Classic HMM. In the MultiHMM method, each segment of an ECG beat is represented by a separate ergodic continuous density HMM. Each HMM has different state number and is trained separately. In the test step, the log-likelihood of two consecutive HMMs is compared and a path is estimated, which shows the correspondence of each part of the ECG signal to the HMM with the maximum log-likelihood. Fiducial points are estimated from the obtained path. For performance evaluation, the Physionet QT database and a Swine ECG database are used and the proposed method is compared with the Classic HMM and a method based on partially collapsed Gibbs sampler (PCGS). In our evaluation using the QT database, we also compare the results with low-pass differentiation, hybrid feature extraction algorithm, a method based on the wavelet transform and three HMM-based approaches. For the Swine database, the root mean square error (RMSE) values, across all FPs for MultiHMM, Classic HMM and PCGS methods are 13, 21 and 40 ms, respectively and the MultiHMM exhibits smaller error variability than other methods. For the QT database, RMSE values for MultiHMM, Classic HMM, Wavelet and PCGS methods are 10, 17, 26 and 38 ms, respectively. Our results demonstrate that our proposed MultiHMM approach outperforms other benchmark methods that exist in the literature; therefore can be used in practical ECG fiducial point extraction.},
author = {Akhbari, Mahsa and Shamsollahi, Mohammad B. and Sayadi, Omid and Armoundas, Antonis A. and Jutten, Christian},
doi = {10.1016/j.compbiomed.2016.09.004},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Akhbari et al. - 2016 - ECG segmentation and fiducial point extraction using multi hidden Markov model.pdf:pdf},
issn = {18790534},
journal = {Computers in Biology and Medicine},
keywords = {Electrocardiogram (ECG),Fiducial point (FP) extraction,Hidden Markov model (HMM),MultiHMM,Segmentation},
pages = {21--29},
title = {{ECG segmentation and fiducial point extraction using multi hidden Markov model}},
volume = {79},
year = {2016}
}
@article{MAGillentineLNBerryRPGoin-KochelMAAliJGeDGuffeyJARosenfeldVHannigPBaderMProudMShinawiBHGraham1ALinSRLalaniJReynoldsMChenTGrebeCGMinardPStankiewiczALBeaudet2017,
abstract = {Chromosome 15q11q13 is among the least stable regions in the genome due to its highly complex genomic architecture. Low copy repeat elements at 15q13.3 facilitate recurrent copy number variants (CNVs), with deletions established as pathogenic and CHRN CHRN A7 implicated as a candidate gene. However, the pathogenicity of duplications of A7 is unclear, as they are also found in reportedly healthy parents and unaffected control individuals. We evaluated 18 children with microduplications involving CHRN A7 identified by clinical chromosome microarray analysis (CMA). Comprehensive phenotyping revealed high prevalence of developmental delay/intellectual disability, autism spectrum disorder, and attention deficit/hyperactivity disorder. As duplications are the most common CNVs identified by clinical CMA, this study provides CHRN A7 anticipatory guidance for those involved with care of affected individuals. Keywords},
author = {{MA Gillentine, LN Berry, RP Goin-Kochel, MA Ali, J Ge, D Guffey, JA Rosenfeld, V Hannig, P Bader, M Proud, M Shinawi, BH Graham1, A Lin, SR Lalani, J Reynolds, M Chen, T Grebe, CG Minard, P Stankiewicz, AL Beaudet}, and CP and Schaaf},
doi = {10.1097/CCM.0b013e31823da96d.Hydrogen},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/MA Gillentine, LN Berry, RP Goin-Kochel, MA Ali, J Ge, D Guffey, JA Rosenfeld, V Hannig, P Bader, M Proud, M Shinawi, BH Graham1, A Lin,.pdf:pdf},
journal = {J Autism Dev Disord},
keywords = {free radicals,hydrogen,oxidative stress,subarachnoid hemorrhage},
number = {3},
pages = {549--562},
title = {{氢气和蛛网膜下腔出血HHS Public Access}},
volume = {47},
year = {2017}
}
@article{Andreao2006,
author = {Andre{\~{a}}o, Rodrigo V and Dorizzi, Bernadette and Boudy, J{\'{e}}r{\^{o}}me},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Andre{\~{a}}o, Dorizzi, Boudy - 2006 - ECG Signal Analysis Through Hidden Markov Models.pdf:pdf},
number = {8},
pages = {1541--1549},
title = {{ECG Signal Analysis Through Hidden Markov Models}},
volume = {53},
year = {2006}
}
@article{I.2014,
abstract = {Late onset neonatal sepsis is one of the major clinical concerns when premature babies receive intensive care. Current practice relies on slow laboratory testing of blood cultures for diagnosis. A valuable research question is whether sepsis can be reliably detected before the blood sample is taken. This paper investigates the extent to which physiological events observed in the patient's monitoring traces could be used for the early detection of neonatal sepsis. We model the distribution of these events with an autoregressive hidden Markov model (AR-HMM). Both learning and inference carefully use domain knowledge to extract the baby's true physiology from the monitoring data. Our model can produce real-time predictions about the onset of the infection and also handles missing data. We evaluate the effectiveness of the AR-HMM for sepsis detection on a dataset collected from the Neonatal Intensive Care Unit at the Royal Infirmary of Edinburgh.},
author = {I., Stanculescu and C.K., Williams and Y., Freer},
doi = {10.1109/JBHI.2013.2294692},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/I., C.K., Y. - 2014 - Autoregressive hidden Markov models for the early detection of neonatal sepsis.pdf:pdf},
issn = {2168-2208},
journal = {IEEE journal of biomedical and health informatics},
keywords = {blood,bradycardia,heart rate,human,newborn,newborn disease,oxygen,physiologic monitoring,probability,procedures,receiver operating characteristic,sepsis,statistical model},
number = {5},
pages = {1560--1570},
title = {{Autoregressive hidden Markov models for the early detection of neonatal sepsis}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L603633946{\%}0Ahttp://dx.doi.org/10.1109/JBHI.2013.2294692{\%}0Ahttp://sfx.library.uu.nl/utrecht?sid=EMBASE{\&}issn=21682208{\&}id=doi:10.1109{\%}2FJBHI.2013.2294692{\&}atitle=Autoregressive+hidden+M},
volume = {18},
year = {2014}
}
@article{Gilani2016,
abstract = {{\textcopyright} 2016 IEEE. Atrial fibrillation (AF) is one of the most common life-threatening arrhythmia affecting around six million adults in the US. Typical detection of AF requires tedious and manual analysis of ECG which can often delay medical intervention. With the advent of wearable devices that can accurately record the time interval between two heartbeats (RR interval), automated and timely detection of AF is now possible. In this paper, we engineer novel heart rate variability features based on linear and non-linear dynamics of RR intervals. Unlike complex features extracted from ECG signals, these features can be easily obtained using wearable sensors. We propose automated classifiers to detect AF episodes and also compare the performance of different classifiers. Our proposed classifier has a very high sensitivity (98{\%}) and specificity (95{\%}) and outperforms prior published works.},
author = {Gilani, Mehrin and Eklund, J. Mikael and Makrehchi, Masoud},
doi = {10.1109/EMBC.2016.7591473},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilani, Eklund, Makrehchi - 2016 - Automated detection of atrial fibrillation episode using novel heart rate variability features.pdf:pdf},
isbn = {9781457702204},
issn = {1557170X},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
pages = {3461--3464},
publisher = {IEEE},
title = {{Automated detection of atrial fibrillation episode using novel heart rate variability features}},
volume = {2016-Octob},
year = {2016}
}
@article{Hampton2017,
abstract = {The article discusses the use of handheld technologies to detect individuals who may have atrial fibrillation. Researchers are testing the effectiveness of smartphones and similar devices to diagnose atrial fibrillation. The results of the diagnosis are expected to help in identifying patients that will be referred to undergo electrocardiography.},
author = {Hampton, Tracy},
doi = {10.1161/CIRCULATIONAHA.116.026458},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hampton - 2017 - Handheld Technologies May Lead to Better Detection of Atrial Fibrillation.pdf:pdf},
issn = {15244539},
journal = {Circulation},
number = {1},
pages = {108--109},
title = {{Handheld Technologies May Lead to Better Detection of Atrial Fibrillation}},
volume = {135},
year = {2017}
}
@article{Karmakar2015,
abstract = {{\textcopyright} 2015 IEEE.Heart rate complexity analysis is a powerful non-invasive means to diagnose several cardiac ailments. Non-linear tools of complexity measurement are indispensable in order to bring out the complete non-linear behavior of Physiological signals. The most popularly used non-linear tools to measure signal complexity are the entropy measures like Approximate entropy (ApEn) and Sample entropy (SampEn). But, these methods become unreliable and inaccurate at times, in particular, for short length data. Recently, a novel method of complexity measurement called Distribution Entropy (DistEn) was introduced, which showed reliable performance to capture complexity of both short term synthetic and short term physiologic data. This study aims to i) examine the competence of DistEn in discriminating Arrhythmia from Normal sinus rhythm (NSR) subjects, using RR interval time series data; ii) explore the level of consistency of DistEn with data length N; and iii) compare the performance of DistEn with ApEn and SampEn. Sixty six RR interval time series data belonging to two groups of cardiac conditions namely 'Arrhythmia' and 'NSR' have been used for the analysis. The data length N was varied from 50 to 1000 beats with embedding dimension m = 2 for all entropy measurements. Maximum ROC area obtained using ApEn, SampEn and DistEn were 0.83, 0.86 and 0.94 for data length 1000, 1000 and 500 beats respectively. The results show that DistEn undoubtedly exhibits a consistently high performance as a classification feature in comparison with ApEn and SampEn. Therefore, DistEn shows a promising behavior as bio marker for detecting Arrhythmia from short length RR interval data.},
author = {Karmakar, Chandan and Udhayakumar, Radhagayathri K. and Palaniswami, Marimuthu},
doi = {10.1109/EMBC.2015.7319565},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Karmakar, Udhayakumar, Palaniswami - 2015 - Distribution Entropy (DistEn) A complexity measure to detect arrhythmia from short length RR.pdf:pdf},
isbn = {9781424492718},
issn = {1557170X},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
keywords = {Nonlinear dynamics in biomedical signals,Biomedica},
number = {0},
pages = {5207--5210},
title = {{Distribution Entropy (DistEn): A complexity measure to detect arrhythmia from short length RR interval time series}},
volume = {2015-Novem},
year = {2015}
}
@article{Ramakrishnan2017,
author = {Ramakrishnan, Sabitha and Akshaya, V. and Kishor, S. and Thyagarajan, T.},
doi = {10.1109/TIMA.2017.8064824},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramakrishnan et al. - 2017 - Real time implementation of arrhythmia classification algorithm using statistical methods.pdf:pdf},
isbn = {9781509030019},
journal = {Proceedings - TIMA 2017: 9th International Conference on Trends in Industrial Measurement and Automation},
keywords = {Automatic external defibrillator,frequency domain,time domain,ventricular fibrillation,ventricular tachycardia},
title = {{Real time implementation of arrhythmia classification algorithm using statistical methods}},
year = {2017}
}
@article{Nemati2016,
abstract = {{\textcopyright} 2016 IEEE. Atrial fibrillation (AFib) is diagnosed by analysis of the morphological and rhythmic properties of the electrocardiogram. It was recently shown that accurate detection of AFib is possible using beat-to-beat interval variations. This raises the question of whether AFib detection can be performed using a pulsatile waveform such as the Photoplethysmogram (PPG). The recent explosion in use of recreational and professional ambulatory wrist-based pulse monitoring devices means that an accurate pulse-based AFib screening algorithm would enable large scale screening for silent or undiagnosed AFib, a significant risk factor for multiple diseases. We propose a noise-resistant machine learning approach to detecting AFib from noisy ambulatory PPG recorded from the wrist using a modern research watch-based wearable device (the Samsung Simband). Ambulatory pulsatile and movement data were recorded from 46 subjects, 15 with AFib and 31 non symptomatic. Single channel electrocardiogram (ECG), multi-wavelength PPG and tri-axial accelerometry were recorded simultaneously at 128 Hz from the non-dominant wrist using the Simband. Recording lengths varied from 3.5 to 8.5 minutes. Pulse (beat) detection was performed on the PPG waveforms, and eleven features were extracted based on beat-to-beat variability and waveform signal quality. Using 10-fold cross validation, an accuracy of 95 {\%} on out-of-sample data was achieved, with a sensitivity of 97{\%}, specificity of 94{\%}, and an area under the receiver operating curve (AUROC) of 0.99. The described approach provides a noise-resistant, accurate screening tool for AFib from PPG sensors located in an ambulatory wrist watch. To our knowledge this is the first study to demonstrate an algorithm with a high enough accuracy to be used in general population studies that does not require an ambulatory Holter electrocardiographic monitor.},
author = {Nemati, Shamim and Ghassemi, Mohammad M. and Ambai, Vaidehi and Isakadze, Nino and Levantsevych, Oleksiy and Shah, Amit and Clifford, Gari D.},
doi = {10.1109/EMBC.2016.7591456},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nemati et al. - 2016 - Monitoring and detecting atrial fibrillation using wearable technology.pdf:pdf},
isbn = {9781457702204},
issn = {1557170X},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
pages = {3394--3397},
publisher = {IEEE},
title = {{Monitoring and detecting atrial fibrillation using wearable technology}},
volume = {2016-Octob},
year = {2016}
}
@article{Novak2003,
abstract = {The processing of electrocardiogram signals (ECG) using Hidden Markov Models (HMM) methodology is presented. The proposed framework enables complex ECG signal processing with all the necessary steps resolved by HMM approach. Firstly, general description and comprehensive survey of actual HMM state of art is carried out. Secondly, the ECG processing methods as noise removal, characteristic points detection and baseline wandering are proposed. Next, further methods as ECG modelling, classification and clustering are carried out. The methods are applied both to artificial data and on MIT/BIH Arrhythmia ECG database. The results are particularly efficient promising that this new approach can be useful both for modelling, denoising, detection of important patterns, classification and clustering of biological signals. Finally in conclusions the up-to-now realized work is summarized and several future directions are suggested for further work. However, perhaps the main value of the thesis is its catholic presentation of Hidden Markov Models theory and its applications in the field of biological signal processing.},
author = {Novak, Daniel},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Novak - 2003 - Electrocardiogram Signal Processing using Hidden Markov Models.pdf:pdf},
title = {{Electrocardiogram Signal Processing using Hidden Markov Models}},
url = {https://www.researchgate.net/profile/Daniel{\_}Novak2/publication/255792118{\_}Electrocardiogram{\_}Signal{\_}Processing{\_}using{\_}Hidden{\_}Markov{\_}Models/links/02e7e520b3c785ef2e000000.pdf},
year = {2003}
}
@article{Marsili2016,
abstract = {{\textcopyright} 2016 IEEE. In this work we implemented and tested on a prototype tele-monitoring device an algorithmic framework for AF detection. The framework was an adaptation for device implementation of a previously developed QRS complex detector and two AF detectors based on RR irregularity features. Validation on MIT-BIH databases demonstrated the capability of the framework to provide accurate onboard AF detection with overall accuracy of 98{\%} and affordable computation burden. The developed Tele-Holter system may have significant impact on AF prevention and screening programs as well as on the improvement of patient follow-up after cardiac events or interventions.},
author = {Marsili, I. A. and Mas{\`{e}}, M. and Pisetta, V. and Ricciardi, E. and Andrighetti, A. O. and Ravelli, F. and Nollo, G.},
doi = {10.1109/ISC2.2016.7580863},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Marsili et al. - 2016 - Optimized algorithms for atrial fibrillation detection by wearable tele-holter devices.pdf:pdf},
isbn = {9781509018451},
journal = {IEEE 2nd International Smart Cities Conference: Improving the Citizens Quality of Life, ISC2 2016 - Proceedings},
keywords = {Atrial fibrillation,E-Cardiology,Event recorder,Prevention,Tele-holter monitoring,Wearable devices},
pages = {16--19},
title = {{Optimized algorithms for atrial fibrillation detection by wearable tele-holter devices}},
year = {2016}
}
@article{Abbasi2004,
author = {Abbasi, Wajid Arshad},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abbasi - 2004 - Time Series Analysis of Heart Rate Variability (HRV) Signals.pdf:pdf},
number = {14},
title = {{Time Series Analysis of Heart Rate Variability (HRV) Signals}},
volume = {286},
year = {2004}
}
@article{McManus2016,
abstract = {{\textcopyright} 2015 Wiley Periodicals, Inc. Automated Arrhythmia Discrimination Using a Smartphone Background Atrial fibrillation (AF) is a common and dangerous rhythm abnormality. Smartphones are increasingly used for mobile health applications by older patients at risk for AF and may be useful for AF screening. Objectives To test whether an enhanced smartphone app for AF detection can discriminate between sinus rhythm (SR), AF, premature atrial contractions (PACs), and premature ventricular contractions (PVCs). Methods We analyzed two hundred and nineteen 2-minute pulse recordings from 121 participants with AF (n = 98), PACs (n = 15), or PVCs (n = 15) using an iPhone 4S. We obtained pulsatile time series recordings in 91 participants after successful cardioversion to sinus rhythm from preexisting AF. The PULSE-SMART app conducted pulse analysis using 3 methods (Root Mean Square of Successive RR Differences; Shannon Entropy; Poincare plot). We examined the sensitivity, specificity, and predictive accuracy of the app for AF, PAC, and PVC discrimination from sinus rhythm using the 12-lead EKG or 3-lead telemetry as the gold standard. We also administered a brief usability questionnaire to a subgroup (n = 65) of app users. Results The smartphone-based app demonstrated excellent sensitivity (0.970), specificity (0.935), and accuracy (0.951) for real-time identification of an irregular pulse during AF. The app also showed good accuracy for PAC (0.955) and PVC discrimination (0.960). The vast majority of surveyed app users (83{\%}) reported that it was "useful" and "not complex" to use. Conclusion A smartphone app can accurately discriminate pulse recordings during AF from sinus rhythm, PACs, and PVCs.},
author = {McManus, David D. and Chong, Jo Woon and Soni, Apurv and Saczynski, Jane S. and Esa, Nada and Napolitano, Craig and Darling, Chad E. and Boyer, Edward and Rosen, Rochelle K. and Floyd, Kevin C. and Chon, Ki H.},
doi = {10.1111/jce.12842},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McManus et al. - 2016 - PULSE-SMART Pulse-based arrhythmia discrimination using a novel smartphone application.pdf:pdf},
issn = {15408167},
journal = {Journal of Cardiovascular Electrophysiology},
keywords = {atrial fibrillation,detection,premature beats,smartphone,technology},
number = {1},
pages = {51--57},
title = {{PULSE-SMART: Pulse-based arrhythmia discrimination using a novel smartphone application}},
volume = {27},
year = {2016}
}
@article{Freedman2016,
abstract = {Approximately 10{\%} of ischemic strokes are associated with atrial fibrillation (AF) first diagnosed at the time of stroke. Detecting asymptomatic AF would provide an opportunity to prevent these strokes by instituting appropriate anticoagulation. The AF-SCREEN international collaboration was formed in September 2015 to promote discussion and research about AF screening as a strategy to reduce stroke and death and to provide advocacy for implementation of country-specific AF screening programs. During 2016, 60 expert members of AF-SCREEN, including physicians, nurses, allied health professionals, health economists, and patient advocates, were invited to prepare sections of a draft document. In August 2016, 51 members met in Rome to discuss the draft document and consider the key points arising from it using a Delphi process. These key points emphasize that screen-detected AF found at a single timepoint or by intermittent ECG recordings over 2 weeks is not a benign condition and, with additional stroke factors, carries sufficient risk of stroke to justify consideration of anticoagulation. With regard to the methods of mass screening, handheld ECG devices have the advantage of providing a verifiable ECG trace that guidelines require for AF diagnosis and would therefore be preferred as screening tools. Certain patient groups, such as those with recent embolic stroke of uncertain source (ESUS), require more intensive monitoring for AF. Settings for screening include various venues in both the community and the clinic, but they must be linked to a pathway for appropriate diagnosis and management for screening to be effective. It is recognized that health resources vary widely between countries and health systems, so the setting for AF screening should be both country-and health system-specific. Based on current knowledge, this white paper provides a strong case for AF screening now while recognizing that large randomized outcomes studies would be helpful to strengthen the evidence base.},
author = {Freedman, Ben},
doi = {10.1161/JAHA.116.004000},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Freedman - 2016 - Screening for Atrial Fibrillation Using a Smartphone Is There an App for That.pdf:pdf},
issn = {20479980},
journal = {Journal of the American Heart Association},
keywords = {Editorials,atrial fibrillation,photoplethysmography,screening,smartphone},
number = {7},
pages = {1--4},
title = {{Screening for Atrial Fibrillation Using a Smartphone: Is There an App for That?}},
volume = {5},
year = {2016}
}
@article{Yau2017,
author = {Yau, X H and Liu, W W and Ooi, Z X and Teoh, Y P and Rahman, Universititunku Abdul},
doi = {10.3917/rai.052.0077},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/FORECASTING PHILIPPINE DAILY STOCK EXCHANGE INDEX.pdf:pdf},
isbn = {9782724633207},
issn = {1112-9867},
pages = {10629},
title = {{Special Issue}},
year = {2017}
}
@article{Peng2016,
author = {Peng, Hao and Liu, Rongke and Hou, Yi and Zhao, Ling},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Bioinformatics/A Gbs Parallel Block-based Viterbi Decoder for Convolutional Codes on GPU.pdf:pdf},
isbn = {9781509028603},
number = {1},
title = {{A Gb / s Parallel Block-based Viterbi Decoder for Convolutional Codes on GPU}},
year = {2016}
}
@article{Bruneau,
archivePrefix = {arXiv},
arxivId = {arXiv:1610.08227v1},
author = {Bruneau, Marine and Moulin, Serge},
eprint = {arXiv:1610.08227v1},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Bioinformatics/A clustering tool for nucleotide sequences.pdf:pdf},
pages = {1--17},
title = {{A clustering tool for nucleotide sequences using Laplacian Eigenmaps and Gaussian Mixture Models}}
}
@article{Kim,
archivePrefix = {arXiv},
arxivId = {arXiv:1708.04329v1},
author = {Kim, Jeremie S and Senol, Damla and Xin, Hongyi and Lee, Donghyuk and Ghose, Saugata and Alser, Mohammed},
eprint = {arXiv:1708.04329v1},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Bioinformatics/GRIM-Filter Fast Seed Filtering.pdf:pdf},
pages = {1--16},
title = {{GRIM-filter : fast seed filtering in read mapping using emerging memory technologies}}
}
@article{Malana,
author = {Malana, Mary Grace and Uy, Roger Luis},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Bioinformatics/Improving Smith-Waterman Local Alignment using Thread Parallelization in Java.pdf:pdf},
keywords = {dna sequences,local alignment,parallelization},
title = {{Improving Smith-Waterman Local Alignment Algorithm Using Thread Parallelization In Java}}
}
@article{Borovska2018,
author = {Borovska, Plamenka and Gancheva, Veska},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Bioinformatics/Parallelization and Optimization of Multiple Biological Sequence Alignment.pdf:pdf},
number = {December},
title = {{Parallelization and Optimization of Multiple Biological Sequence Alignment Software Based on Social Behavior Model Parallelization and Optimization of Multiple Biological Sequence Alignment Software Based on Social Behavior Model}},
year = {2018}
}
@article{Fonzo2014,
author = {Fonzo, Valeria De and Aluffi-pentini, Filippo and Parisi, Valerio},
doi = {10.2174/157489307779314348},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Bioinformatics/Hidden Markov Models in Bioinformatics.pdf:pdf},
keywords = {dynamical programming,hidden markov model,hmm,labeling,sequence profiling,structure prediction},
number = {January 2007},
title = {{Hidden Markov Models in Bioinformatics Hidden Markov Models in Bioinformatics}},
year = {2014}
}
@article{Mcvicar,
author = {Mcvicar, Nathaniel and Hoshino, Akina and Torre, Anna La and Reh, Thomas A and Ruzzo, Walter L and Hauck, Scott},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Bioinformatics/FPGA Acceleration of Short Read Alignment.pdf:pdf},
number = {C},
pages = {1--15},
title = {{FPGA Acceleration of Short Read Alignment}}
}
@article{Chowdhury2016,
author = {Chowdhury, Rezaul and B, Pramod Ganapathi and Pradhan, Vivek},
doi = {10.1007/978-3-319-43659-3},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Bioinformatics/An Efficient Cache-oblivious Parallel Viterbi Algorithm.pdf:pdf},
isbn = {9783319436593},
keywords = {cache-efficient,cache-oblivious,divide-and-conquer,multi-instance,parallel,rank,recursive,viterbi algorithm},
pages = {574--587},
title = {{An Efficient Cache-oblivious Parallel Viterbi Algorithm}},
year = {2016}
}
@article{RabinerLawrence1989,
author = {{Rabiner, Lawrence}, R.},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/MSS701M - Bioinformatics/tutorial on hmm and applications.pdf:pdf},
journal = {IEEE},
number = {2},
pages = {257--286},
title = {{A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition}},
volume = {77},
year = {1989}
}
@article{Schreiber2018,
author = {Schreiber, Jacob},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Bioinformatics/Pomegranate - Fast and Flexible Probabilistic Modeling in Python.pdf:pdf},
keywords = {big data,cython,machine learning,probabilistic modeling,python},
pages = {1--6},
title = {{pomegranate : Fast and Flexible Probabilistic Modeling in Python}},
volume = {18},
year = {2018}
}
@article{Gayo2016,
abstract = {Objectives: Patients with hereditary cancer syndromes are at high risk for a second primary cancer. Early identification of these patients after an initial cancer diagnosis is the key to implementing cancer risk-reducing strategies. Methods: A commercial laboratory database was searched for women with a history of both breast and ovarian or colorectal and endometrial cancer who underwent genetic testing for hereditary breast and ovarian cancer (HBOC) or Lynch syndrome (LS). Results: Among women with both breast and ovarian cancer, 22.4{\%} (2,237/9,982) had a BRCA1 or BRCA2 mutation. Among women with both colorectal and ovarian cancer, 28.1{\%} (264/941) had a mutation associated with LS. In 66.6{\%} of BRCA1 or BRCA2 mutation carriers and in 58.3{\%} of LS mutation carriers, {\textgreater}5 years passed between the cancer diagnoses. Of patients with HBOC and LS, 56 and 65.2{\%}, respectively, met the National Comprehensive Cancer Network guidelines for hereditary cancer testing after their initial diagnosis based on their personal cancer history alone. Conclusions: A substantial number of women tested for LS or HBOC after being diagnosed with two successive primary cancers were diagnosed with a hereditary cancer syndrome. In many cases, the time interval between the diagnoses was long enough to allow for the implementation of surveillance and/or prophylactic measures. {\textcopyright} 2014 S. Karger AG, Basel.},
author = {Gayo, W. and David, G.},
doi = {10.1159/000368836},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/Modeling Philippine Stock Exchange Composite Index Using Weighted.pdf:pdf},
issn = {1423-0232},
journal = {MATEC Web of Conferences},
pages = {6--10},
pmid = {25503195},
title = {{Modeling Philippine Stock Exchange Composite Index Using Weighted Geometric Brownian Motion Forecasts}},
volume = {68},
year = {2016}
}
@article{Science2018,
author = {Science, Nonlinear and Phenomena, Complex and Nie, Chun-xiao and Song, Fu-tie},
doi = {10.1016/j.chaos.2018.05.018},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/Analyzing the stock market based on the structure of kNN network.pdf:pdf},
issn = {0960-0779},
journal = {Chaos, Solitons and Fractals: the interdisciplinary journal of Nonlinear Science, and Nonequilibrium and Complex Phenomena},
keywords = {k nearest neighbors graph,k nearest neighbors graph,Financial market,Cluster},
pages = {148--159},
publisher = {Elsevier Ltd},
title = {{Chaos , Solitons and Fractals Analyzing the stock market based on the structure of kNN network R}},
url = {https://doi.org/10.1016/j.chaos.2018.05.018},
volume = {113},
year = {2018}
}
@article{Nobi2016,
author = {Nobi, Ashadun and Woo, Jae},
doi = {10.1016/j.physa.2015.12.144},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/State and group dynamics of world stock market by principal component analysis.pdf:pdf},
keywords = {principal component analysis},
pages = {85--94},
publisher = {Elsevier B.V.},
title = {{State and group dynamics of world stock market by principal component analysis}},
volume = {450},
year = {2016}
}
@article{Peachavanish2016,
author = {Peachavanish, Ratchata},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/Stock Selection and Trading Based on Cluster Analysis of Trend and Momentum Indicators.pdf:pdf},
isbn = {9789881925381},
pages = {16--20},
title = {{Stock Selection and Trading Based on Cluster Analysis of Trend and Momentum Indicators}},
volume = {I},
year = {2016}
}
@article{Shadman2017,
author = {Shadman, Arshiful Islam and Towqir, Sheikh Shadab and Akif, M Ahnaf},
doi = {10.1007/978-3-319-49073-1},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/Cluster Analysis, Classification and Forecasting Tool on DS30 for Better Investment Decision.pdf:pdf},
isbn = {9783319490731},
keywords = {classification,cluster analysis,data mining techniques,decision tree,dhaka stock exchange,ds30,stock sectors,weka},
title = {{Cluster Analysis , Classification and Forecasting Tool on DS30 for Better Investment Decision}},
year = {2017}
}
@article{France,
archivePrefix = {arXiv},
arxivId = {arXiv:1712.03152v2},
author = {France, Stephen L},
eprint = {arXiv:1712.03152v2},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/Aggregating Google Trends Multivariate Testing and Analysis.pdf:pdf},
keywords = {cluster analysis,forecasting,google trends,nowcasting,pca},
title = {{Aggregating Google Trends : Multivariate Testing and Analysis}}
}
@article{Sharma,
author = {Sharma, Charu and Habib, Amber and Bowry, Sunil},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/Cluster analysis of stocks using price movements of high frequency data from National.pdf:pdf},
keywords = {artificial,big data analytics,financial mathematics,high frequency trading,statistics},
title = {{Cluster analysis of stocks using price movements of high frequency data from National Stock Exchange}}
}
@article{Musmeci2015,
author = {Musmeci, Nicol{\'{o}} and Aste, Tomaso and Matteo, T Di},
doi = {10.1371/journal.pone.0116201},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/Relation between Financial Market Structure and the Real Economy Comparison between Clustering Methods.PDF:PDF},
pages = {1--24},
title = {{Relation between Financial Market Structure and the Real Economy : Comparison between Clustering Methods}},
year = {2015}
}
@article{Aghabozorgi2014,
author = {Aghabozorgi, Saeed and Teh, Ying Wah},
doi = {10.1016/j.eswa.2013.08.028},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/Stock market co-movement assessment using a three-phase clustering.pdf:pdf},
issn = {0957-4174},
journal = {Expert Systems With Applications},
number = {4},
pages = {1301--1314},
publisher = {Elsevier Ltd},
title = {{Expert Systems with Applications Stock market co-movement assessment using a three-phase clustering method}},
url = {http://dx.doi.org/10.1016/j.eswa.2013.08.028},
volume = {41},
year = {2014}
}
@article{Momeni,
author = {Momeni, Mansoor and Mohseni, Maryam and Soofi, Mansour},
file = {:D$\backslash$:/{\~{}}Masters/{\~{}} MS-STAT/Papers/Multivariate Techniques for Stock Market/CLUSTERING STOCK MARKET COMPANIES VIA K- MEANS ALGORITHM.pdf:pdf},
keywords = {ahp,clustering,k- means algorithm,validity},
number = {5},
title = {{CLUSTERING STOCK MARKET COMPANIES VIA K- MEANS}},
volume = {4}
}
@article{Dudas,
abstract = {The readability of networks how different visual design elements affect the understanding of network data has been central in network visualization research. However, existing studies have mainly focused on readability induced by topological mapping (based on different layouts) and overlooked the effect of visual aesthetics. Here is proposed a novel experimental framework to study how different network aesthetic choices affect users' abilities of understanding the network structures. The visual aesthetics are grouped in two forms: 1) visual encoding (where the aesthetic mapping depends on the underlying network data) and 2) visual styling (where the aesthetics are applied independent of underlying data). Users are given a simple task identifying most connected nodes in a network in a hybrid experimental setting where the visual aesthetic choices are tested in a within-subject manner while the network topologies are tested in a between-subject manner based on a randomized blocking design. This novel experimental design ensures an efficient decoupling of the influence of network topology on readability tests. The utility of different visual aesthetics is measured comprehensively based on task performance (accuracy and time), eye-tracking data, and user feedback (perceived affordance). The results show differential readability effects among choices of visual aesthetics. Particularly, node based visual encoding significantly enhances network readability, specifically glyphs based on their ability to be utilized as a means to allow participants to create more robust strategies in their utilization. The study contributes to both the understanding of the role of visual aesthetics in network visualization design and the experimental design for testing the network readability.},
author = {Dudas, Patrick},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dudas - Unknown - The Impact Of Visual Aesthetics On The Utility Affordance And Readability Of Network Graphs.pdf:pdf},
title = {{The Impact Of Visual Aesthetics On The Utility Affordance And Readability Of Network Graphs}}
}
@phdthesis{Bui2013,
abstract = {The purpose of this research was to examine the relationship between the underlying company culture of a textile company and the company's Six Sigma projects' success. The research on company culture and quality improvement is independently vast. In spite of this, little research has been done on company culture and the relationship it has with quality improvement projects. The culture of a company is one that affects how employees perform the tasks set before them. As a result this may affect the success of quality improvement projects, such as Six Sigma, that seek to reduce costs and improve the quality of the company's products or services. In order to further investigate this relationship, the culture of a North Carolina textile company was surveyed using an organizational culture survey developed by Dr. Carl Fey and Dr. Daniel Denison (2003). Fey and Denison identified involvement, consistency, adaptability and mission as factors that reveal themselves in a company's culture. The survey was administered to Six Sigma trained or certified employees within the textile company, and interviews were conducted with Six Sigma certified employees. The findings from the survey, interview, and personal observations indicated that the textile organization struggled with all aspects of company culture as identified by Fey and Denison. This textile company and others should focus on improving the values and goals of the company, the mission, and team involvement.},
author = {Bui, Kevin Daniel},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bui - 2013 - Examining the Relationship between Company Culture and Six Sigma Project Success.pdf:pdf},
school = {North Carolina State University},
title = {{Examining the Relationship between Company Culture and Six Sigma Project Success}},
year = {2013}
}
@article{Filtering2018,
author = {Filtering, Low Pass and Filtering, High Pass and Filter, Derivative and Integration, Moving Window},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Filtering et al. - 2018 - QRS Detection Using Pan-Tompkins algorithm Matlab implementation illustrates the application of Pan-Tompkins A.pdf:pdf},
pages = {1--8},
title = {{QRS Detection Using Pan-Tompkins algorithm Matlab implementation illustrates the application of Pan-Tompkins Algorithm to a short ECG data . This and T wave depending on the QRS detection . Cancellation DC drift and normalization Cancellation DC drift and}},
volume = {1},
year = {2018}
}
@article{Bharali2017,
author = {Bharali, Sumi and Sarma, Manash Pratim and Sarma, Kandarpa Kumar and Mastorakis, Nikos},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bharali et al. - 2017 - Statistical and Learning Aided Classifier for ECG Based Predictive Diagnostic Tool.pdf:pdf},
pages = {1--7},
title = {{Statistical and Learning Aided Classifier for ECG Based Predictive Diagnostic Tool}},
volume = {05008},
year = {2017}
}
@article{Oster2013,
abstract = {The development of mHealth applications could facilitate the decrease of the healthcare costs in both high income and low to middle income regions. However, it is essential that mHealth software is validated on public databases. Moreover, public scrutiny of the algorithms is likely to lead to faster and lower cost innovation. In this paper, we therefore present a novel Java-based Android application offering advanced Electrocardiogram (ECG) processing techniques, including signal quality analysis and Atrial Fibrillation (AF) screening.},
author = {Oster, Julien and Behar, Joachim and Colloca, Roberta and Li, Qiao},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Oster et al. - 2013 - Open source Java-based ECG analysis software and Android app for atrial fibrillation screening.pdf:pdf},
isbn = {9781479908844},
issn = {23258861},
journal = {Computing in Cardiology 2013},
pages = {731--734},
title = {{Open source Java-based ECG analysis software and Android app for atrial fibrillation screening}},
year = {2013}
}
@article{PatelAbhilashaM.;GakarePankajK.;Cheeran2012,
abstract = {Arrhythmia means abnormal rate of heart contraction which is dangerous as it may also cause death. The work proposed in this paper mainly deals with the development of an efficient arrhythmia detection algorithm using ECG signal so that detection of arrhythmia at initial stages is possible using a smart-phone which is readily available anywhere which makes complete system mobile. Subjects for experiments included normal patients, patients with Bradycardia, Tachycardia, atrial premature contraction (APC), patients with ventricular premature contraction (PVC) and patients with Sleep Apnea. Pan-Tompkins algorithm was used to find the locations of QRS complexes and R Peaks. The algorithm to detect different arrhythmia is based on position of P wave, QRS complex, R Peak and T wave and on interval between these waves on android smart-phone. The algorithm was tested using MIT-BIH arrhythmia database. Results revealed that the system is accurate and efficient to classify arrhythmias as high overall performance (97.3{\%}) for the classification of the different categories of arrhythmic beats was achieved. The proposed arrhythmia detection algorithm may therefore be helpful to the clinical diagnosis.},
author = {{Patel, Abhilasha M.; Gakare, Pankaj K.; Cheeran}, A. N.},
doi = {10.5120-6432-8840},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Patel, Abhilasha M. Gakare, Pankaj K. Cheeran - 2012 - Real Time ECG Feature Extraction and Arrhythmia Detection on a Mobile Platform.pdf:pdf},
journal = {International Journal of Computer Applications},
keywords = {Android smart-phone,ECG,PVC.,Tachycardia,Telemedicine,eHealth,mHealth},
number = {23},
pages = {40--45},
title = {{Real Time ECG Feature Extraction and Arrhythmia Detection on a Mobile Platform}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Real+Time+ECG+Feature+Extraction+and+Arrhythmia+Detection+on+a+Mobile+Platform{\#}0},
volume = {44},
year = {2012}
}
@article{PatelAbhilashaM.;GakarePankajK.;Cheeran2012a,
abstract = {Arrhythmia means abnormal rate of heart contraction which is dangerous as it may also cause death. The work proposed in this paper mainly deals with the development of an efficient arrhythmia detection algorithm using ECG signal so that detection of arrhythmia at initial stages is possible using a smart-phone which is readily available anywhere which makes complete system mobile. Subjects for experiments included normal patients, patients with Bradycardia, Tachycardia, atrial premature contraction (APC), patients with ventricular premature contraction (PVC) and patients with Sleep Apnea. Pan-Tompkins algorithm was used to find the locations of QRS complexes and R Peaks. The algorithm to detect different arrhythmia is based on position of P wave, QRS complex, R Peak and T wave and on interval between these waves on android smart-phone. The algorithm was tested using MIT-BIH arrhythmia database. Results revealed that the system is accurate and efficient to classify arrhythmias as high overall performance (97.3{\%}) for the classification of the different categories of arrhythmic beats was achieved. The proposed arrhythmia detection algorithm may therefore be helpful to the clinical diagnosis.},
author = {{Patel, Abhilasha M.; Gakare, Pankaj K.; Cheeran}, A. N.},
doi = {10.5120-6432-8840},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Patel, Abhilasha M. Gakare, Pankaj K. Cheeran - 2012 - Real Time ECG Feature Extraction and Arrhythmia Detection on a Mobile Platform.pdf:pdf},
journal = {International Journal of Computer Applications},
keywords = {Android smart-phone,ECG,PVC.,Tachycardia,Telemedicine,eHealth,mHealth},
number = {23},
pages = {40--45},
title = {{Real Time ECG Feature Extraction and Arrhythmia Detection on a Mobile Platform}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Real+Time+ECG+Feature+Extraction+and+Arrhythmia+Detection+on+a+Mobile+Platform{\#}0},
volume = {44},
year = {2012}
}
@article{Leutheuser,
author = {Leutheuser, Heike and Gottschalk, Tristan and Anneken, Lars},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Leutheuser, Gottschalk, Anneken - Unknown - Automatic ECG Arrhythmia Detection in Real-Time on Android-based Mobile Devices.pdf:pdf},
journal = {Mobmed.Org},
keywords = {electrocardiogram,hierarchical classification,pan-tompkins algorithm,pattern},
pages = {2--5},
title = {{Automatic ECG Arrhythmia Detection in Real-Time on Android-based Mobile Devices}},
url = {http://mobmed.org/download/proceedings2014/mobileMed2014{\_}paper{\_}34.pdf}
}
@article{Pan1985,
abstract = {We have developed a real-time algorithm for detection of the QRS complexes of ECG signals. It reliably recognizes QRS complexes based upon digital analyses of slope, amplitude, and width. A special digital bandpass filter reduces false detections caused by the various types of interference present in ECG signals. This filtering permits use of low thresholds, thereby increasing detection sensitivity. The algorithm automatically adjusts thresholds and parameters periodically to adapt to such ECG changes as QRS morphology and heart rate. For the standard 24 h MIT/BIH arrhythmia database, this algorithm correctly detects 99.3 percent of the QRS complexes.},
author = {Pan, Jiapu and Tompkins, Willis J.},
doi = {10.1109/TBME.1985.325532},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan, Tompkins - 1985 - A Real-Time QRS Detection Algorithm.pdf:pdf},
isbn = {0018-9294 VO  - BME-32},
issn = {0018-9294},
journal = {IEEE Transactions on Biomedical Engineering},
number = {3},
pages = {230--236},
pmid = {3997178},
title = {{A Real-Time QRS Detection Algorithm}},
url = {http://ieeexplore.ieee.org/document/4122029/},
volume = {BME-32},
year = {1985}
}
@article{Paikrao2011,
author = {Paikrao, Pavan D and Shinde, Deeplaxmi P and Engg, Telecommunication},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Paikrao, Shinde, Engg - 2011 - Peak Detection Algorithm for ECG wave.pdf:pdf},
isbn = {9781457702402},
keywords = {detection,ecg,ecg beat,electrocardiogram,hrv,qrs complex},
pages = {421--423},
title = {{Peak Detection Algorithm for ECG wave}},
year = {2011}
}
@article{Wang2014,
author = {Wang, Xinqi Louis and Smieee, J Mikael Eklund},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Smieee - 2014 - A real-time ECG feature detection algorithm.pdf:pdf},
journal = {Ieee},
pages = {5--7},
title = {{A real-time ECG feature detection algorithm}},
year = {2014}
}
@article{Eaglin2017,
author = {Eaglin, Todd},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Eaglin - 2017 - Scalable, Situationally Aware Visual Analytics and Applications.pdf:pdf},
title = {{Scalable, Situationally Aware Visual Analytics and Applications}},
year = {2017}
}
@article{,
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - The Raw ECG Signal Processing and the Detection of the QRS Complex.pdf:pdf},
title = {{The Raw ECG Signal Processing and the Detection of the QRS Complex}}
}
@article{,
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - A New Statistical Based Algorithm for Ecg Identification.pdf:pdf},
title = {{A New Statistical Based Algorithm for Ecg Identification}}
}
@article{Tan2009,
abstract = {This descriptive and correlational study examined the applicability of major U.S. college choice factors to Philippine high school seniors. A sample of 226 students from a private school in Manila completed the College Choice Survey for High School Seniors. Cronbach's alpha for the survey composite index was 0.933. The purposes of this nonexperimental, quantitative study were (1) to describe the relative importance of major college choice factors (as identified in U.S. research) to Philippine high school seniors, and (2) to determine whether there were statistically significant differences in the importance ascribed to these factors, according to students' demographic attributes. For all statistical analyses, SPSS 16.0 software was used. To address the first purpose, the mean and standard deviation were calculated for each college choice factor addressed in the survey. To address the second purpose, ANOVAs, Mann-Whitney U tests, and Kruskal-Wallis tests were run, in order to study the relationship between each of the major college choice factors and students' demographic attributes. This study found that all of the major U.S. college choice factors were important, to some degree, in the Philippine context. Other factors were added based on pilot studies. This study also found that some of the U.S.-literature-generated demographic choice attributes functioned similarly in the Philippine setting (e.g. academic ability, gender), while others did not (e.g. educational level of fathers and of mothers). Moreover, students' academic ability was the primary demographic attribute, accounting for statistically significant differences in assessment of the importance of college choice factors for most (12 out of 13) of the factors.},
author = {Tan, Christine Joy},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan - 2009 - College choice in the Philippines.pdf:pdf},
isbn = {9781109456509},
journal = {ProQuest Dissertations and Theses},
keywords = {0519:School counseling,0533:Secondary education,0745:Higher education,College choice,College selection,Decision making,Education,High school seniors,Higher education,Philippines,Private high schools,School choice,School counseling,Secondary education},
pages = {240},
title = {{College choice in the Philippines}},
url = {https://search.proquest.com/docview/304964531?accountid=14513},
year = {2009}
}
@article{SimonCharlesHall,
abstract = {Expansion of the beef industry in Brazil has propelled the nation to the forefront of both global production and international trade. Brazil now has the largest commercial cattle herd in the world. The growth of this industry has attracted significant controversy and concern. Expansion of cattle operations is associated with land use transformation in Brazil, including the intensification of existing ranches and controversial forest clearing for new pasture in Amazonia. Both of these processes are associated with potentially negative environmental impacts, including the degradation of local and regional soil and water quality and contributions to global climate change. There have been efforts to harness market pressure to discourage deforestation and encourage more sustainable production. First, partnerships between domestic beef producers and export oriented organizations have sought to create international market opportunities for environmentally responsible domestic producers. However, the overwhelming majority of Brazilian beef production, approximately 83.5{\%}, is consumed domestically. Second, beef can be certified organic, but currently only 1.67{\%} of domestic beef producers have such certification. Although organic producers represent a relatively small proportion of total Brazilian agricultural producers, 40{\%} of all organic production is consumed domestically, suggesting interest among Brazilian consumers. In this thesis, I assess the viability of promoting more sustainable beef production via the domestic market for beef in Brazil. Specifically, I estimate willingness to pay for environmentally differentiated beef in a case study in the city of Curitiba. We conducted a},
author = {{Simon Charles Hall}},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Simon Charles Hall - Unknown - Beef Consumption in Curitiba, Brazil Willingness to Pay for Sustainable Production.pdf:pdf},
title = {{Beef Consumption in Curitiba, Brazil: Willingness to Pay for Sustainable Production}}
}
@article{Acupan2014,
author = {Acupan, Angelito B},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Acupan - 2014 - MICROFINANCE AND POVERTY REDUCTION THE CASE OF NORTHEASTERN MINDANAO , THE PHILIPPINES.pdf:pdf},
number = {August},
title = {{MICROFINANCE AND POVERTY REDUCTION : THE CASE OF NORTHEASTERN MINDANAO , THE PHILIPPINES}},
year = {2014}
}
@article{Moreno2004,
abstract = {The study argues for the integration of good governance principles in developing financially viable, effective and social equity-laden microcredit strategy for the impoverished agrarian reform beneficiaries in Western Mindanao. It particularly examines the program design and implementation strategies of the Enterprise Development Credit (EDC) sub-component of the Western Mindanao Community Initiatives Project (WMCIP). The study aims to provide lessons and insights for the planning and implementation of comprehensive and integrated Official Development Assistance (ODA)-funded government programs for poverty reduction and rural development.$\backslash$n$\backslash$nThe data and information were generated from combined descriptive and field studies covering a sample survey, group discussions, interviews, field visits and observations, official documents and other secondary sources. The respondents were officials and field personnel of WMCIP, line agencies, local government units (LGUs), and non-government organizations (NGOs); officers and members of cooperatives and people?s organizations (POs); religious leaders and informal moneylenders; and WMCIP beneficiaries.$\backslash$n$\backslash$nOverall, microcredit is applicable only to the enterprising poor. The application of microcredit to other poverty groups who actually need subsidies and social safety nets would be a mistake. Thus, the EDC sub-component should be reformulated and revitalized following the program design of the Bangladesh Rural$\backslash$nAdvancement Committee (BRAC). Its graduated strategy for helping the poor should be applied to the poverty pyramid by categorizing the WMCIP beneficiaries into four poverty groups: (1) micro-enterprise operators or the less poor, (2) enterprising or moderately poor, (3) laboring or very poor, and (4) poorest of the poor and most vulnerable or the ultra-poor.$\backslash$n$\backslash$nThe results further reveal that based on the poverty pyramid, the credit program designs of the Credit Assistance Program for Program Beneficiaries Development (CAP-PBD) and Quedan Rural Credit and Finance Corporation (QUEDANCOR) are readily applicable to the credit needs and financial capabilities of the enterprising poor. Beyond QUEDANCOR?s microcredit facility, the non- enterprising poor may actually opt for financial assistance from cooperatives or CAP- PBD to help finance their agriculture-and fishery-related production activities. On the other hand, the beneficiaries and their ?not-so-strong? organizations that could not readily comply with the minimum credit standards should be provided with farm production subsidies, capability-building services and social safety nets under a special poverty alleviation project. This will enable them to pass minimum credit standards within a transition period of six months to one year.$\backslash$n$\backslash$nIn view of WMCIP?s EDC sub-component, the study further identifies the factors that enable or limit successful design and implementation of microcredit program and the provision of public support services. The enabling factors are vital to planning and decision-making that will eventually make the program effective and$\backslash$n$\backslash$nappropriate. The limiting factors, on the other hand, facilitate the identification of strategies to manage and control credit risks and other circumstances that may hinder participation and adversely affect the attainment of objectives and desired outcomes.$\backslash$n$\backslash$nOn the whole, the application of good governance will improve program design and will make the implementation strategies acceptable to all organized stakeholders and individual end-beneficiaries. This will also improve the administrative capabilities of partner organizations and enable them to be effective and responsive to the differentiated poverty conditions, credit needs, preferences and financial capabilities of the impoverished target beneficiaries. These are consequently geared towards the attainment of the long-term vision of sustainable human development for the impoverished WMCIP beneficiaries.$\backslash$n$\backslash$nThe integration of good governance into microcredit intends to improve its program design, implementation strategies and processes. However, support services are actually necessary so as to simultaneously attain the desired social equity and financial viability objectives. The program should be orchestrated within a comprehensive and integrated approach to poverty reduction and rural development. The good governance of microcredit requires multiple organizational partnerships among the different government agencies, business sector and the civil society. Most importantly, the financial and technical support programs of the international donor community are absolutely necessary in the light of Philippine economic and fiscal challenges.},
author = {Moreno, Frede},
doi = {10.2139/ssrn.1499495},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moreno - 2004 - Good Governance in Microcredit Strategy for Poverty Reduction Focus on Western Mindanao, Philippines.pdf:pdf},
issn = {1556-5068},
keywords = {Za,governance,microcredit,microfinance,poverty},
number = {November 2004},
pages = {464},
title = {{Good Governance in Microcredit Strategy for Poverty Reduction: Focus on Western Mindanao, Philippines}},
url = {http://mpra.ub.uni-muenchen.de/34273/},
year = {2004}
}
@article{Cantila2016,
author = {Cantila, Aldrin Y and Abdula, Sailila E and Candalia, Haziel Jane C and Balleras, Gina D},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cantila et al. - 2016 - Multiple Statistical Tools for Divergence Analysis of Rice ( Oryza sativa L .) Released Varieties.pdf:pdf},
keywords = {121-134,2,2016,65,clustering statistics,correlation statistics,descriptive,no,pp,principal component analysis,rice released,shannon-weaver index,statistics,the philippine statistician vol,varieties},
number = {2},
pages = {121--134},
title = {{Multiple Statistical Tools for Divergence Analysis of Rice ( Oryza sativa L .) Released Varieties}},
volume = {65},
year = {2016}
}
@article{Asaad2015,
author = {Asaad, Abubakar S},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Asaad - 2015 - Nonparametric Bootstrap Test in a Multivariate Spatial-Temporal Model A Simulation Study.pdf:pdf},
keywords = {coverage probability,robustness,spatial-temporal},
number = {1},
pages = {1--16},
title = {{Nonparametric Bootstrap Test in a Multivariate Spatial-Temporal Model : A Simulation Study}},
volume = {64},
year = {2015}
}
@article{Nalica2014,
author = {Nalica, Angela D and Lansangan, Joseph Ryan G},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nalica, Lansangan - 2014 - Identifying Influencers of Consumer Activity A Case Study in Predictive Modeling.pdf:pdf},
keywords = {behaviour,consumer,customer relationship management,influencers,logistic regression,segmentation},
number = {1},
pages = {93--101},
title = {{Identifying Influencers of Consumer Activity : A Case Study in Predictive Modeling}},
volume = {63},
year = {2014}
}
@article{Dharma2016,
author = {Dharma, Divo and Rean, Consorcia E and Lansigan, Felino P and Panopio, Rolando G and Bantayan, Nathaniel C},
doi = {10.1016/j.inpa.2016.10.001},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dharma et al. - 2016 - Using Genetic Algorithm Neural Network on Near Infrared Spectral Data for Ripeness Grading of Oil Palm ( Elaeis g.pdf:pdf},
keywords = {near infrared spectroscopy,principal component analysis},
number = {2},
pages = {252--261},
title = {{Using Genetic Algorithm Neural Network on Near Infrared Spectral Data for Ripeness Grading of Oil Palm ( Elaeis guineensis Jacq .) Fresh Fruit}},
volume = {3},
year = {2016}
}
@article{Campano2012,
author = {Campano, Wendell Q},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Campano - 2012 - Robust Methods in Time Series Models with Volatility.pdf:pdf},
keywords = {ar-sieve,block bootstrap,forward search algorithm,nonparametric test,volatility},
number = {2},
pages = {83--101},
title = {{Robust Methods in Time Series Models with Volatility}},
volume = {61},
year = {2012}
}
@article{Eustaquio2016,
author = {Eustaquio, John D},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Eustaquio - 2016 - Nonparametric Hypothesis Testing for Isotonic Survival Models with Clustering.pdf:pdf},
keywords = {additive models,backfitting algorithm,bootstrap confidence interval,clustered data,generalized,nonparametric bootstrap,survival analysis},
number = {2},
pages = {77--92},
title = {{Nonparametric Hypothesis Testing for Isotonic Survival Models with Clustering}},
volume = {65},
year = {2016}
}
@article{Reyes2015,
abstract = {{\textcopyright} 2015, Philippine Statistical Association, Inc. All rights reserved.This paper presents an alternative method apart from the current online or electronic approach, which is currently being used by some higher education institutions (HEIs), in administering student ratings for teachers. The developed method still employed the traditional paper approach but has been improved through the use of sampling application which includes sampling design, sample size, estimation technique, and strategic implementation. Three basic sampling designs such as simple random, stratified random, and cluster sampling were applied at three different sampling rates such as 25{\%}, 50{\%}, and 75{\%}. For the empirical evaluation of the developed method, the Student Evaluation of Teachers (SET) of the University of the Philippines Los Banos (UPLB) was utilized using bootstrap resampling technique. Based on findings, stratified random sampling is the most appropriate sampling design to use with 50{\%} of the students for each class section serving as SET evaluators. Results also revealed that bootstrap estimates of standard error are lower than that of the standard error using jackknife resampling procedure. Generally, the improved traditional paper approach same with the electronic approach could reduce the cost of administering student ratings. However, the electronic approach has a dilemma with regards to high non-response bias leading to invalid results. Thus, to minimize non-response error of the developed method, its standard protocol to administer the student ratings has been formulated.},
author = {Reyes, J.R.S. and Albacea, Z.V.J.},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Reyes, Albacea - 2015 - Sampling strategy in evaluating teaching performance through student ratings.pdf:pdf},
issn = {20940343},
journal = {Philippine Statistician},
keywords = {1 major results presented,ackknife resampling,bootstrap resampling,in this paper were,master,nonresponse error,s thesis of jrs,sampling application,student ratings,taken from the unpublished,traditional paper approach},
number = {1},
pages = {75--88},
title = {{Sampling strategy in evaluating teaching performance through student ratings}},
volume = {64},
year = {2015}
}
@article{Banez2012,
author = {Ba{\~{n}}ez, John Erwin},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ba{\~{n}}ez - 2012 - Poisson Spatial Autoregression Modelling of Poverty Count Data in the Philippines.pdf:pdf},
keywords = {back fi tting algorithm,spatial autoregression},
number = {2},
pages = {67--82},
title = {{Poisson Spatial Autoregression Modelling of Poverty Count Data in the Philippines}},
volume = {61},
year = {2012}
}
@article{Nalica2010,
author = {Nalica, Angela D},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nalica - 2010 - Spatial-Temporal Modeling of Growth in Rice Production in the Philippines.pdf:pdf},
journal = {The Philippine Statistician},
keywords = {agricultural growth,autoregression,backfitting,convergence,hypothesis,spatio-temporal model},
number = {59},
pages = {15--25},
title = {{Spatial-Temporal Modeling of Growth in Rice Production in the Philippines}},
volume = {59},
year = {2010}
}
@article{Lansangan2011,
author = {Lansangan, Joseph Ryan G},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lansangan - 2011 - A Dose of Business Intelligence Data Mining.pdf:pdf},
pages = {125--128},
title = {{A Dose of Business Intelligence : Data Mining}},
volume = {60},
year = {2011}
}
@article{Coles1999,
author = {Coles, S G and Tawn, J A},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Coles, Tawn - 1999 - Statistical Methods for Extreme Values.pdf:pdf},
number = {1},
pages = {137--142},
title = {{Statistical Methods for Extreme Values}},
volume = {61},
year = {1999}
}
@article{World2013,
author = {World, I S I and Congress, Statistics and Kong, Hong and Cps, Session},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/World et al. - 2013 - Semiparametric Poisson Regression Model for Clustered.pdf:pdf},
keywords = {backfitting,generalized additive models,nonparametric regression,random},
number = {August},
pages = {25--30},
title = {{Semiparametric Poisson Regression Model for Clustered}},
volume = {3},
year = {2013}
}
@article{Leong2015,
abstract = {{\textcopyright} 2008 Philippine Statistical Association, Inc.One of the main areas of public health surveillance is infectious disease surveillance. With infectious disease backgrounds usually being more complex, appropriate surveillance schemes must be in order. One such procedure is through the use of control charts. However, with most background processes following a zero-inflated Poisson (ZIP) distribution as brought about by the extra variability due to excess zeros, the control charting procedures must be properly developed to address this issue. Hence in this paper, drawing inspiration from the development of combined control charting procedures for simultaneously monitoring each ZIP parameter individually in the context of statistical process control (SPC), several combined exponentially weighted moving average (EWMA) control charting procedures were proposed (Bernoulli-ZIP and CRL-ZTP EWMA charts). Through an extensive simulation study involving multiple parameter settings and outbreak model considerations (i.e., different shapes, magnitude, and duration), some key results were observed. These include the applicability of performing combined control charting procedures for disease surveillance with a ZIP background using EWMA techniques. For demonstration purposes, application with an actual data, using confirmed measles cases in the National Capital Region (NCR) from January 1, 2010 to January 14 2015, revealed the comparability of the Bernoulli-ZIP EWMA scheme to historical limits method currently in use.},
author = {Leong, R.N.F. and Co, F.F. and Tan, D.S.Y.},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Leong, Co, Tan - 2015 - Some zero inflated Poisson-Based combined exponentially weighted moving average control charts for disease surve.pdf:pdf},
issn = {20940343},
journal = {Philippine Statistician},
keywords = {[Disease surveillance, EWMA control charts, Measle},
number = {2},
pages = {17--42},
title = {{Some zero inflated Poisson-Based combined exponentially weighted moving average control charts for disease surveillance}},
volume = {64},
year = {2015}
}
@article{Pal2015,
author = {Pal, Nabendu and Unhapipat, Suntaree},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pal, Unhapipat - 2015 - Teacher's Corner.pdf:pdf},
keywords = {bootstrap,nonparametric,p-value,parametric bootstrap,sampling distribution,test statistic},
number = {1},
pages = {89--121},
title = {{Teacher's Corner}},
volume = {64},
year = {2015}
}
@article{Barrios,
author = {Barrios, Erniel B},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Barrios - Unknown - Teaching of Statistical Consulting in the Philippines.pdf:pdf},
keywords = {statistical consulting,statistics education},
number = {2010},
pages = {103--107},
title = {{Teaching of Statistical Consulting in the Philippines}},
volume = {59}
}
@article{Besana,
author = {Besana, Michelle and Mulvey, Edward P and Ph, D},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Besana, Mulvey, Ph - Unknown - Substance Use among Serious Adolescent Offenders Following Different Patterns of Antisocial Activity.pdf:pdf},
keywords = {2011,60,63-86,adolescent offenders,antisocial activity,delinquency,growth curve models,hierarchical generalized linear models,pp,serious,substance use,the philippine statistician vol},
number = {2011},
pages = {63--86},
title = {{Substance Use among Serious Adolescent Offenders Following Different Patterns of Antisocial Activity}},
volume = {60}
}
@article{Suaiso,
author = {Suaiso, Jose Oliver Q and Mapa, Dennis S},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Suaiso, Mapa - Unknown - JEL classification.pdf:pdf},
keywords = {extreme value theory,market risk,peaks-over-threshold,risk,value-at-risk},
title = {{JEL classification:}}
}
@article{Abuzaid2012,
abstract = {This paper, handles with much emphasis, Mother's Day celebration around the world — a day that is celebrated on various days in different countries. These days are marked in relation to certain historical, religious or mythical events for every nation. The celebration of mother's day by 152 nations is analyzed using a set of circular statistics procedures to study its characteristics. The frequencies of celebration days are modeled, possible clusters and outliers are defi ned to assess possible factors that may affect the celebration in a certain date. These factors are found to be culture, language, colonization and neighborhood with insignifi cant role of religion.},
author = {Abuzaid, Ali H},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abuzaid - 2012 - Analysis of Mother ' s Day Celebration Via Circular Statistics.pdf:pdf},
keywords = {boxplot,cluster,direction,outlier},
number = {2},
pages = {39--52},
title = {{Analysis of Mother ' s Day Celebration Via Circular Statistics}},
volume = {61},
year = {2012}
}
@article{Estiaga2007,
author = {Estiaga, Catherine E},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Estiaga - 2007 - Bootstrapping Penalty Analysis in Sensory Evaluation of Pizza.pdf:pdf},
issn = {20940343},
keywords = {bootstrap method,hedonic scale,just about right,mean drops,penalty analysis,scale},
number = {2},
pages = {1--28},
title = {{Bootstrapping Penalty Analysis in Sensory Evaluation of Pizza}},
volume = {64},
year = {2007}
}
@article{Raguindin2012,
author = {Raguindin, Daniel R and Vera, Eiffel A De},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Raguindin, Vera - 2012 - A Multivariate Probit Analysis on the Factors Influencing the Adoption of Water Saving Technologies by Rice Far.pdf:pdf},
journal = {The Philippine Statistician},
keywords = {multivariate probit model,univariate probit model,water saving technology},
number = {1},
pages = {109--121},
title = {{A Multivariate Probit Analysis on the Factors Influencing the Adoption of Water Saving Technologies by Rice Farmers in Sto . Domingo , Nueva Ecija}},
volume = {61},
year = {2012}
}
@article{Rey2016,
author = {Rey, Mia Pang and Suan, Ivy D C},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rey, Suan - 2016 - A Sustainability Model for Small Health Maintenance Programs.pdf:pdf},
keywords = {health maintenance programs,sustainability},
number = {2},
pages = {135--149},
title = {{A Sustainability Model for Small Health Maintenance Programs}},
volume = {65},
year = {2016}
}
@article{Hinkley2007,
author = {Hinkley, David V},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinkley - 2007 - Bootstrap Methods.pdf:pdf},
pages = {129--132},
title = {{Bootstrap Methods}},
volume = {60},
year = {2007}
}
@article{Gauran2012,
author = {Gauran, Iris Ivy M},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gauran - 2012 - Classification of Congenital Hypothyroidism in Newborn Screening using Self-Organizing Maps.pdf:pdf},
keywords = {algorithm,classi fi cation,newborn screening for congenital,outlier detection,self-organizing kohonen maps,som},
number = {1},
pages = {2012},
title = {{Classification of Congenital Hypothyroidism in Newborn Screening using Self-Organizing Maps}},
volume = {61},
year = {2012}
}
@article{Gauran2013,
author = {Gauran, Iris Ivy M},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gauran - 2013 - Classification of Congenital Hypothyroidism using Artificial Neural Networks.pdf:pdf},
keywords = {algorithm,classification,newborn screening for congenital,outlier detection,self-organizing kohonen maps,som},
number = {2},
pages = {1--11},
title = {{Classification of Congenital Hypothyroidism using Artificial Neural Networks}},
volume = {62},
year = {2013}
}
@article{Campano2013,
abstract = {In this paper, a data visualization framework for investigating and exploring climate time series data is introduced. This method utilizes the results obtained from performing series of cluster analysis based on a particular multivariate dataset for each defined subset in the time series. The said approach is implemented to the climate data in the Philippines. The data image results obtained from the procedure revealed the expected overall climate pattern in the Philippines as well as some localized segments of climate changes in the time series which deviate from the overall pattern. A wavelet analysis which is a well-established method in analyzing climate data is also done to validate the results shown by the proposed visualization method.},
author = {Campano, Wendell Q and Tadlas, Rona May U},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Campano, Tadlas - 2013 - Visual Exploration of Climate Variability in the Philippines.pdf:pdf},
journal = {The Philippine Statistician},
keywords = {climate change,climate variability,cluster analysis,data image,information visualization,time series,wavelet},
number = {2},
pages = {101--111},
title = {{Visual Exploration of Climate Variability in the Philippines}},
volume = {62},
year = {2013}
}
@article{Villejo2015,
author = {Villejo, Stephen Jun},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Villejo - 2015 - Classification and Prediction of Suicidal Tendencies of the Youth in the Philippines An Empirical Study.pdf:pdf},
issn = {20940343},
keywords = {classification,logistic regression,prediction,suicide},
number = {1},
pages = {31--52},
title = {{Classification and Prediction of Suicidal Tendencies of the Youth in the Philippines : An Empirical Study}},
volume = {64},
year = {2015}
}
@misc{,
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - PsyArXiv Preprints {\_} Redefine statistical significance.pdf.pdf:pdf},
title = {{PsyArXiv Preprints {\_} Redefine statistical significance.pdf}}
}
@article{Bersales2014,
author = {Bersales, Lisa Grace S and Lucagbo, Michael Daniel C},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bersales, Lucagbo - 2014 - Determinants of Regional Minimum Wages in the Philippines.pdf:pdf},
keywords = {boards,fixed effects model for,fixed effects models for,minimum,panel data,shocks,stage least squares,tripartite wage and productivity,two,wage},
number = {2},
pages = {71--85},
title = {{Determinants of Regional Minimum Wages in the Philippines}},
volume = {63},
year = {2014}
}
@article{Lucagbo2016,
author = {Lucagbo, Michael Daniel C},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lucagbo - 2016 - Comparison of Ordinal Logistic Regression with Tree-Based Methods in Predicting Socioeconomic Classes in the Philippine.pdf:pdf},
keywords = {bagging,boosting,ordinal logistic regression,random forests,socioeconomic classification},
number = {1},
pages = {1--14},
title = {{Comparison of Ordinal Logistic Regression with Tree-Based Methods in Predicting Socioeconomic Classes in the Philippines}},
volume = {65},
year = {2016}
}
@article{Supranes2014,
author = {Supranes, Michael Van},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Supranes - 2014 - Design Strategies in Fitting a Nonlinear Model.pdf:pdf},
keywords = {experimental designs,monte carlo simulation,spline regression,stratification},
number = {1},
pages = {43--58},
title = {{Design Strategies in Fitting a Nonlinear Model}},
volume = {63},
year = {2014}
}
@article{MartinezJr.2016,
abstract = {Using counterfactual simulations, we investigate the various factors that could explain the changes observed in poverty and inequality in the Philippines over the past decade. To do this, we decomposed per capita household income as a stochastic function of various forms of socio-economic capital and the socio-economic returns to capital. The results indicate that the higher levels of ownership of assets and higher economic returns to formal and non-agricultural employment have contributed to lower poverty while human capital and access to basic services remain stagnant and thus, had no impact on poverty and inequality. In general, we find that the impact of changes in socio-economic capital and changes in economic returns to capital as offsetting forces that contribute to slow poverty and inequality reduction despite the rapid economic growth that the Philippines has experienced over the past ten years. {\textcopyright} 2016, Philippine Statistical Association, Inc. All rights reserved.},
author = {{Martinez  Jr.}, A and Western, M and Tomaszewski, W and Haynes, M and Manalo, M K and Sebastian, I},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martinez Jr. et al. - 2016 - Drivers of household income distribution dynamics in the Philippines.pdf:pdf},
journal = {Philippine Statistician},
keywords = {Counterfactual simulation,Income decomposition,Inequality,Poverty},
number = {1},
pages = {53--84},
title = {{Drivers of household income distribution dynamics in the Philippines}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006323703{\&}partnerID=40{\&}md5=bd935c2d63962cf3c4f04eb0281146f7},
volume = {65},
year = {2016}
}
@article{Abitona2012,
author = {Abitona, Lara Paul D and Albacea, Zita V J},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abitona, Albacea - 2012 - Estimation of the Provincial Counts of Vitamin A Deficient Children Aged Six Months to Five Years.pdf:pdf},
keywords = {poisson regression model,small area estimation},
number = {1},
pages = {35--53},
title = {{Estimation of the Provincial Counts of Vitamin A Deficient Children Aged Six Months to Five Years}},
volume = {61},
year = {2012}
}
@article{Mapa2009,
author = {Mapa, Dennis S and Ph, D and Han, Fatima C and Estrada, Kristine Claire O},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mapa et al. - 2009 - Food Inflation , Underemployment and Hunger Incidence A Vector Autoregressive Analysis 1.pdf:pdf},
keywords = {2011,43-62,60,food inflation,hunger,pp,the philippine statistician vol,underemployment,vector autoregressive},
number = {2011},
pages = {43--62},
title = {{Food Inflation , Underemployment and Hunger Incidence : A Vector Autoregressive Analysis 1}},
volume = {60},
year = {2009}
}
@article{Alberto2012,
author = {Alberto, Angelo M and Bersales, Lisa Grace S},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alberto, Bersales - 2012 - Econometric Modeling of Panel Data on the Saving Patterns of Philippine Agricultural Households.pdf:pdf},
keywords = {agricultural,fi xed effects,panel data,saving rate},
number = {1},
pages = {69--85},
title = {{Econometric Modeling of Panel Data on the Saving Patterns of Philippine Agricultural Households}},
volume = {61},
year = {2012}
}
@article{Lucagbo2014,
author = {Lucagbo, Michael Daniel C},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lucagbo - 2014 - Effects of Household Use of Biomass Fuel and Kerosene on Birth Weight of Babies in the Philippines.pdf:pdf},
keywords = {biomass fuel,low birth weight,maternal smoking,ordinal logistic regression},
number = {1},
pages = {75--92},
title = {{Effects of Household Use of Biomass Fuel and Kerosene on Birth Weight of Babies in the Philippines}},
volume = {63},
year = {2014}
}
@article{Zhou2017,
author = {Zhou, Yang and Liu, Ling-Xi and Zhao, Fei and Tang, Shi-Hai and Peng, Hua-Li and Jiang, Yun-Han},
doi = {10.1038/s41598-017-12500-6},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2017 - Effects of transthoracic device closure on ventricular septal defects and reasons for conversion to open-heart surg.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {1},
pages = {12219},
pmid = {28939836},
publisher = {Springer US},
title = {{Effects of transthoracic device closure on ventricular septal defects and reasons for conversion to open-heart surgery: A meta-analysis}},
url = {http://www.nature.com/articles/s41598-017-12500-6},
volume = {7},
year = {2017}
}
@article{Alsallakh2014,
abstract = {A variety of data analysis problems can be modelled by defining multiple sets over a collection of elements and analyzing the relations between these sets. Despite their simple concept, visualizing sets is a non-trivial problem due to the large number of possible relations between them. We provide a systematic overview of state-of-the-art techniques for visualizing different kinds of set relations. We classify these techniques into 7 main categories according to the visual representations they use and the tasks they support. We compare the categories to provide guidance for choosing an appropriate technique for a given problem. Finally, we identify challenges in this area that need further research and propose possible directions to address these challenges.},
author = {Alsallakh, Bilal and Micallef, Luana and Aigner, Wolfgang and Hauser, Helwig and Miksch, Silvia and Rodgers, Peter},
doi = {10.2312/eurovisstar.20141170},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alsallakh et al. - 2014 - Visualizing Sets and Set-typed Data State-of-the-Art and Future Challenges.pdf:pdf},
isbn = {-},
journal = {Eurographics conference on Visualization (EuroVis)– State of The Art Reports},
pages = {1--21},
title = {{Visualizing Sets and Set-typed Data: State-of-the-Art and Future Challenges}},
url = {http://publik.tuwien.ac.at/files/PubDat{\_}228538.pdf{\%}5Cnhttp://diglib.eg.org/EG/DL/PE/EuroVisSTAR/EuroVisSTAR2014/001-021.pdf.abstract.pdf;internal{\&}action=action.digitallibrary.ShowPaperAbstract},
year = {2014}
}
@article{Kiranyaz2017,
abstract = {Each year more than 7 million people die from cardiac arrhythmias. Yet no robust solution exists today to detect such heart anomalies right at the moment they occur. The purpose of this study was to design a personalized health monitoring system that can detect early occurrences of arrhythmias from an individual's electrocardiogram (ECG) signal. We first modelled the common causes of arrhythmias in the signal domain as a degradation of normal ECG beats to abnormal beats. Using the degradation models, we performed abnormal beat synthesis which created potential abnormal beats from the average normal beat of the individual. Finally, a Convolutional Neural Network (CNN) was trained using real normal and synthesized abnormal beats. As a personalized classifier, the trained CNN can monitor ECG beats in real time for arrhythmia detection. Over 34 patients' ECG records with a total of 63,341 ECG beats from the MIT-BIH arrhythmia benchmark database, we have shown that the probability of detecting one or more abnormal ECG beats among the first three occurrences is higher than 99.4{\%} with a very low false-alarm rate.},
annote = {TO READ:
1. de Chazal, P. {\&} Reilly, R. B. A patient-adapting heartbeat classifier using ECG morphology and heartbeat interval features. IEEE Trans. Biomed. Eng. 53(12), 2535–2543 (2006).

2. de Chazal, P., O'Dwyer, M. {\&} Reilly, R. B. Automatic classification of heartbeats using ECG morphology and heartbeat interval features. IEEE Trans. Biomed. Eng. 51(7), 1196–1206 (2004).

3. Jiang, W. {\&} Kong, S. G. Block-based neural networks for personalized ECG signal classification. IEEE Trans. Neural Networks 18(6), 1750–1761 (2007).

4. Ince, T., Kiranyaz, S. {\&} Gabbouj, M. A Generic and Robust System for Automated Patient-specific Classification of Electrocardiogram Signals. IEEE Trans. on Biomedical Eng. 56(5), 1415–1426 (2009).

5. Kiranyaz, S., Ince, T. {\&} Gabbouj, M. Multi-dimensional Particle Swarm Optimization for Machine Learning and Pattern Recognition. Book: Springer, 383 pages, (2013).

6. Llamedo, M. {\&} Martinez, J. P. An Automatic Patient-Adapted ECG Heartbeat Classifier Allowing Expert Assistance. IEEE Transactions on Biomedical Engineering 59(8), 2312–2320 (2012).

7. Kiranyaz, S., Ince, T. {\&} Gabbouj, M. Real-Time Patient-Specific ECG Classification by 1D Convolutional Neural Networks. IEEE Trans. on Biomedical Engineering 63(3), 664–675 (2016).

8. Hu, Y., Palreddy, S. {\&} Tompkins, W. J. A patient-adaptable ECG beat classifier using a mixture of experts approach. IEEE Trans. Biomed. Eng. 44(9), 891–900 (1997).},
author = {Kiranyaz, Serkan and Ince, Turker and Gabbouj, Moncef},
doi = {10.1038/s41598-017-09544-z},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kiranyaz, Ince, Gabbouj - 2017 - Personalized Monitoring and Advance Warning System for Cardiac Arrhythmias.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {1},
pages = {9270},
pmid = {28839215},
publisher = {Springer US},
title = {{Personalized Monitoring and Advance Warning System for Cardiac Arrhythmias}},
url = {http://www.nature.com/articles/s41598-017-09544-z},
volume = {7},
year = {2017}
}
@article{Nattel2006,
abstract = {Normal cardiac function requires an appropriate and regular beating rate (cardiac rhythm). When the heart rhythm is too fast or too slow, cardiac function can be impaired, with derangements that vary from mild symptoms to life-threatening complications. Irregularities, particularly those involving excessively fast or slow rates, constitute cardiac 'arrhythmias'. In the past, drug treatment of cardiac arrhythmias has proven difficult, both because of inadequate effectiveness and a risk of serious complications. However, a variety of recent advances have opened up exciting possibilities for the development of novel and superior approaches to arrhythmia therapy. This article will review recent progress and future prospects for treating two particularly important cardiac arrhythmias: atrial fibrillation and ventricular fibrillation.},
author = {Nattel, Stanley and Carlsson, Leif},
doi = {10.1038/nrd2112},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nattel, Carlsson - 2006 - Innovative approaches to anti-arrhythmic drug therapy.pdf:pdf},
isbn = {1474-1776 (Print)$\backslash$r1474-1776 (Linking)},
issn = {1474-1776},
journal = {Nature Reviews Drug Discovery},
number = {12},
pages = {1034--1049},
pmid = {17139288},
title = {{Innovative approaches to anti-arrhythmic drug therapy}},
url = {http://www.nature.com/doifinder/10.1038/nrd2112},
volume = {5},
year = {2006}
}
@article{Knollmann2008,
abstract = {Abnormalities in heart rhythm continue to cause high rates of illness and death. Better treatment could be provided by solving two main challenges: the early identification of patients who are at risk, and the characterization of molecular pathways that culminate in arrhythmias. By analysing mechanisms that increase susceptibility to arrhythmia in individuals with genetic syndromes, it might be possible to improve current therapies and to develop new ways to treat and prevent common arrhythmias.},
author = {Knollmann, Bj{\"{o}}rn C. and Roden, Dan M.},
doi = {10.1038/nature06799},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Knollmann, Roden - 2008 - A genetic framework for improving arrhythmia therapy.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7181},
pages = {929--936},
pmid = {18288182},
title = {{A genetic framework for improving arrhythmia therapy}},
url = {http://www.nature.com/doifinder/10.1038/nature06799},
volume = {451},
year = {2008}
}
@article{Dominguez-Rodriguez2009,
abstract = {The intrinsic properties of the heart and the vascular tree exhibit marked oscillations over 24h. Diurnal variations in the response of the cardiovascular system to environmental stimuli are mediated by the complex interplay of extracellular (ie, neurohumoral factors) and intracellular (ie, circadian clock) influences. The intracellular circadian clock comprises a series of transcriptional modulators that together allow the cell to ‘‘perceive'' the time of day, thus enabling suitable responses to expected stimuli. These molecular timepieces have been identified and characterized within both vascular smooth muscle cells and cardiomyocytes, giving rise to a multitude of hypotheses regarding the potential role of the circadian clock as a modulator of physiological and pathophysiological cardiovascular events. This article summarizes the evidence available at present linking circadian rhythm disruption and cardiovascular disease.},
author = {Dominguez-Rodriguez, Alberto and Abreu-Gonzalez, Pedro and Kaski, Juan Carlos},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dominguez-Rodriguez, Abreu-Gonzalez, Kaski - 2009 - Disruption of normal circadian rhythms and cardiovascular events.pdf:pdf},
issn = {15660338},
journal = {Heart Metab.},
keywords = {cardiovascular disease,circadian clock,diurnal variations},
pages = {11--15},
title = {{Disruption of normal circadian rhythms and cardiovascular events}},
volume = {44},
year = {2009}
}
@article{Bondarenko2017,
abstract = {{\textcopyright} 2017 The Author(s). A failing heart differs from healthy hearts by an array of symptomatic characteristics, including impaired Ca 2+  transients, upregulation of Na + /Ca 2+  exchanger function, reduction of Ca 2+  uptake to sarcoplasmic reticulum, reduced K +  currents, and increased propensity to arrhythmias. While significant efforts have been made in both experimental studies and model development to display the causes of heart failure, the full process of deterioration from a healthy to a failing heart yet remains deficiently understood. In this paper, we analyze a highly detailed mathematical model of mouse ventricular myocytes to disclose the key mechanisms underlying the continual transition towards a state of heart failure. We argue that such a transition can be described in mathematical terms as a sequence of bifurcations that the healthy cells undergo while transforming into failing cells. They include normal action potentials and [Ca 2+ ] i  transients, action potential and [Ca 2+ ] i  alternans, and bursting behaviors. These behaviors where supported by experimental studies of heart failure. The analysis of this model allowed us to identify that the slow component of the fast Na +  current is a key determining factor for the onset of bursting activity in mouse ventricular myocytes.},
author = {Bondarenko, Vladimir E. and Shilnikov, Andrey L.},
doi = {10.1038/s41598-017-05198-z},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bondarenko, Shilnikov - 2017 - Bursting dynamics in the normal and failing hearts.pdf:pdf},
isbn = {4159801705198},
issn = {2045-2322},
journal = {Scientific Reports},
number = {1},
pages = {5927},
publisher = {Springer US},
title = {{Bursting dynamics in the normal and failing hearts}},
url = {http://www.nature.com/articles/s41598-017-05198-z},
volume = {7},
year = {2017}
}
@article{Arevalo2016,
abstract = {Sudden cardiac death (SCD) from arrhythmias is a leading cause of mortality. For patients at high SCD risk, prophylactic insertion of implantable cardioverter defibrillators (ICDs) reduces mortality. Current approaches to identify patients at risk for arrhythmia are, however, of low sensitivity and specificity, which results in a low rate of appropriate ICD therapy. Here, we develop a personalized approach to assess SCD risk in post-infarction patients based on cardiac imaging and computational modelling. We construct personalized three-dimensional computer models of post-infarction hearts from patients' clinical magnetic resonance imaging data and assess the propensity of each model to develop arrhythmia. In a proof-of-concept retrospective study, the virtual heart test significantly outperformed several existing clinical metrics in predicting future arrhythmic events. The robust and non-invasive personalized virtual heart risk assessment may have the potential to prevent SCD and avoid unnecessary ICD implantations.},
author = {Arevalo, Hermenegild J. and Vadakkumpadan, Fijoy and Guallar, Eliseo and Jebb, Alexander and Malamas, Peter and Wu, Katherine C. and Trayanova, Natalia A.},
doi = {10.1038/ncomms11437},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Arevalo et al. - 2016 - Arrhythmia risk stratification of patients after myocardial infarction using personalized heart models.pdf:pdf},
isbn = {2041-1723 (Electronic)$\backslash$r2041-1723 (Linking)},
issn = {2041-1723},
journal = {Nature Communications},
number = {May},
pages = {11437},
pmid = {27164184},
publisher = {Nature Publishing Group},
title = {{Arrhythmia risk stratification of patients after myocardial infarction using personalized heart models}},
url = {http://www.nature.com/doifinder/10.1038/ncomms11437},
volume = {7},
year = {2016}
}
@article{Kazbanov2016,
abstract = {Myocardial fibrosis is an important risk factor for cardiac arrhythmias. Previous experimental and numerical studies have shown that the texture and spatial distribution of fibrosis may play an important role in arrhythmia onset. Here, we investigate how spatial heterogeneity of fibrosis affects arrhythmia onset using numerical methods. We generate various tissue textures that differ by the mean amount of fibrosis, the degree of heterogeneity and the characteristic size of heterogeneity. We study the onset of arrhythmias using a burst pacing protocol. We confirm that spatial heterogeneity of fibrosis increases the probability of arrhythmia induction. This effect is more pronounced with the increase of both the spatial size and the degree of heterogeneity. The induced arrhythmias have a regular structure with the period being mostly determined by the maximal local fibrosis level. We perform ablations of the induced fibrillatory patterns to classify their type. We show that in fibrotic tissue fibrillation is usually of the mother rotor type but becomes of the multiple wavelet type with increase in tissue size. Overall, we conclude that the most important factor determining the formation and dynamics of arrhythmia in heterogeneous fibrotic tissue is the value of maximal local fibrosis.},
author = {Kazbanov, Ivan V. and ten Tusscher, Kirsten H. W. J. and Panfilov, Alexander V.},
doi = {10.1038/srep20835},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazbanov, ten Tusscher, Panfilov - 2016 - Effects of Heterogeneous Diffuse Fibrosis on Arrhythmia Dynamics and Mechanism.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
number = {1},
pages = {20835},
pmid = {26861111},
publisher = {Nature Publishing Group},
title = {{Effects of Heterogeneous Diffuse Fibrosis on Arrhythmia Dynamics and Mechanism}},
url = {http://www.nature.com/articles/srep20835},
volume = {6},
year = {2016}
}
@article{Lam2014,
author = {Lam, Alron Jan and Paner, Ivan and Macatangay, Jules Matthew and {Delos Santos}, Duke Danielle},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lam et al. - 2014 - Classifying Typhoon Related Tweets.pdf:pdf},
pages = {32--35},
title = {{Classifying Typhoon Related Tweets}},
year = {2014}
}
@article{Fu2016,
abstract = {We propose a Word-Topic Mixture(WTM) model to improve word representation and topic model simultaneously. Firstly, it introduces the initial external word embeddings into the Topical Word Embeddings(TWE) model based on Latent Dirichlet Allocation(LDA) model to learn word embeddings and topic vectors. Then the results learned from TWE are inte-grated in the LDA by defining the probability distribution of topic vectors-word embeddings according to the idea of latent feature model with LDA (LFLDA), meanwhile minimizing the KL divergence of the new topic-word distribution function and the original one. The experimental results prove that the WTM model performs better on word representation and topic detection compared with some state-of-the-art models.},
author = {Fu, Xianghua and Wang, Ting and Li, Jing and Yu, Chong and Liu, Wangwang and Durrant, Robert J and Kim, Kee-Eung},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fu et al. - 2016 - Improving Distributed Word Representation and Topic Model by Word-Topic Mixture Model.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Word-Topic Mixture model,distributed word representation,topic model,word embedding},
number = {2009},
pages = {190--205},
title = {{Improving Distributed Word Representation and Topic Model by Word-Topic Mixture Model}},
volume = {63},
year = {2016}
}
@article{Mehrotra2013,
abstract = {Twitter, or the world of 140 characters poses serious challenges to the efficacy of topic models on short, messy text. While topic models such as Latent Dirichlet Allocation (LDA) have a long history of successful application to news articles and academic abstracts, they are often less coherent when applied to microblog content like Twitter. In this paper, we investigate methods to improve topics learned from Twitter content without modifying the basic machinery of LDA; we achieve this through various pooling schemes that aggregate tweets in a data preprocessing step for LDA. We empirically establish that a novel method of tweet pooling by hashtags leads to a vast improvement in a variety of measures for topic coherence across three diverse Twitter datasets in comparison to an unmodified LDA baseline and a variety of pooling schemes. An additional contribution of automatic hashtag labeling further improves on the hashtag pooling results for a subset of metrics. Overall, these two novel schemes lead to significantly improved LDA topic models on Twitter content. Copyright {\textcopyright} 2013 ACM.},
author = {Mehrotra, Rishabh and Sanner, Scott and Buntine, Wray and Xie, Lexing},
doi = {10.1145/2484028.2484166},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mehrotra et al. - 2013 - Improving LDA topic models for microblogs via tweet pooling and automatic labeling.pdf:pdf},
isbn = {9781450320344},
journal = {Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval - SIGIR '13},
keywords = {lda,microblogs,topic modeling},
pages = {889},
title = {{Improving LDA topic models for microblogs via tweet pooling and automatic labeling}},
url = {http://dl.acm.org/citation.cfm?doid=2484028.2484166},
year = {2013}
}
@article{Syliongka2015,
abstract = {In this paper, we present a framework that combines automatic and manual approaches to discover themes in disaster-related tweets. As case study, we decided to focus on tweets related to typhoon Haiyan, which caused billions of dollars in damages. We collected tweets from November 2013 to March 2014 and used the local typhoon name " Yolanda " as filter. Data association was used to expand the tweet set and k-means clustering was then applied. Clusters with high number of instances were subjected to open coding for labeling. The Silhouette indices ranged from 0.27 to 0.50. Analyses reveal that the use of automated Natural Language Processing (NLP) approach has the potential to deal with huge volumes of tweets by clustering frequently occurring words and phrases. This complements the manual approach to surface themes from a more manageable set of tweet pool, allowing for a more nuanced analysis of tweets from a human expert. As application, the themes extracted were used as categories in a classifier system. Future work could explore on using topic models and focusing on specific content or issues, such as natural calamities and citizen's participation in addressing these.},
author = {Syliongka, Leif Romeritch and Oco, Nathaniel and Lam, Alron Jan and Soriano, Cheryll Ruth and Divina, Ma and Roldan, Gracia and Magno, Francisco and Cheng, Charibeth},
doi = {10.1145/2740908.2742125},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Syliongka et al. - 2015 - Combining Automatic and Manual Approaches Towards a Framework for Discovering Themes in Disaster-related Twee.pdf:pdf},
isbn = {9781450334730},
journal = {Proceedings of the 24th International Conference on World Wide Web},
keywords = {clustering,discovering themes,open coding,typhoon haiyan},
pages = {1239--1244},
title = {{Combining Automatic and Manual Approaches : Towards a Framework for Discovering Themes in Disaster-related Tweets}},
year = {2015}
}
@article{Kalampokis2011,
abstract = {In the last years, several research endeavors were launched aiming at involving popular social media platforms in electronic participation. These early endeavors seem to present some essential limitations related mainly to scalability and uptake. In order to avoid these limitations, we introduce a two-phased approach for supporting participatory decision-making based on the integration and analysis of social and government open data. The proposed approach is based on the literature related to the analysis of massive amounts of social data for future events prediction. In this paper we also present a Web data driven architecture for the implementation of the proposed approach. The architecture is based on the use of linked data paradigm as a layer that will enable integration of data from different sources. We anticipate that the proposed approach will (i) allow decision makers to understand and predict public opinion and reaction about specific decisions; and (ii) enable citizens to inadvertently contribute in decision-making. {\textcopyright} 2011 IFIP International Federation for Information Processing.},
author = {Kalampokis, Evangelos and Hausenblas, Michael and Tarabanis, Konstantinos},
doi = {10.1007/978-3-642-23333-3_4},
file = {:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalampokis, Hausenblas, Tarabanis - 2011 - Combining social and government open data for participatory decision-making.pdf:pdf;:C$\backslash$:/Users/Jeh/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalampokis, Hausenblas, Tarabanis - 2011 - Combining social and government open data for participatory decision-making(2).pdf:pdf},
isbn = {9783642233326},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Data driven architecture,Linked data,Open government data,Social data,eParticipation},
pages = {36--47},
title = {{Combining social and government open data for participatory decision-making}},
volume = {6847 LNCS},
year = {2011}
}
